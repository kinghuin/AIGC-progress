| Date | Repository | Stars | tags | Language |  Description  |
|------------|---------|-------|-------------|-------------|-------------|
| 2023-08-18 | [facebookresearch/meru](https://github.com/facebookresearch/meru) | 57 | 🖼️⛽🚌2️⃣ |   | Code for the paper "Hyperbolic Image-Text Representations", Desai et al, ICML 2023 |
| 2023-08-17 | [facefusion/facefusion](https://github.com/facefusion/facefusion) | 186 | 🖼️🔨 |  Python | Next generation face swapper and enhancer |
| 2023-08-16 | [tencent-ailab/IP-Adapter](https://github.com/tencent-ailab/IP-Adapter) | 158 | 🖼️🚌 |   | The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.  |
| 2023-08-14 | [opendatalab/WanJuan1.0](https://github.com/opendatalab/WanJuan1.0) | 206 | 🔠🖼️🎥⛽ |   | 万卷1.0多模态语料 |
| 2023-08-12 | [SpenserCai/sd-webui-go](https://github.com/SpenserCai/sd-webui-go) | 127 | 🖼️🔨 |  Go | This is a Go language version of the SDK based on stable-diffusion-webui. In your code, you can directly use the API interfaces of stable-diffusion-webui through object-oriented operations, instead of dealing with cumbersome JSON.  Support extensions API ! |
| 2023-08-10 | [modelscope/facechain](https://github.com/modelscope/facechain) | 3329 | 🖼️🔨 |  Python | FaceChain is a deep-learning toolchain for generating your Digital-Twin. |
| 2023-08-09 | [lllyasviel/Fooocus](https://github.com/lllyasviel/Fooocus) | 6391 | 🖼️🔌 |   | Focus on prompting and generating |
| 2023-08-03 | [OpenGVLab/all-seeing](https://github.com/OpenGVLab/all-seeing) | 213 | 🔠🖼️`🚌` |   | This is the official implementation of the paper "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World" |
| 2023-08-03 | [numz/sd-wav2lip-uhq](https://github.com/numz/sd-wav2lip-uhq) | 107 | 🖼️🔌 |   | Wav2Lip UHQ extension for Automatic1111 |
| 2023-08-01 | [dvlab-research/LISA](https://github.com/dvlab-research/LISA) | 802 | 🔠🖼️⛽🚌 |   | Project Page for "LISA: Reasoning Segmentation via Large Language Model" |
| 2023-07-30 | [LinkSoul-AI/Chinese-LLaVA](https://github.com/LinkSoul-AI/Chinese-LLaVA) | 140 | 🔠🖼️🔨💰🀄 |  Python | 支持中英文双语视觉-文本对话的开源可商用多模态模型。 |
| 2023-07-28 | [SpenserCai/sd-webui-deoldify](https://github.com/SpenserCai/sd-webui-deoldify) | 260 | 🖼️🔌 |   | DeOldify for Stable Diffusion WebUI：This is an extension for StableDiffusion's AUTOMATIC1111 web-ui that allows colorize of old photos and old video. It is based on deoldify. |
| 2023-07-26 | [rynmurdock/inanimate](https://github.com/rynmurdock/inanimate) | 35 | 🖼️🔌 |   | Generate images from an initial frame and text |
| 2023-07-24 | [glucauze/sd-webui-faceswaplab](https://github.com/glucauze/sd-webui-faceswaplab) | 135 | 🖼️🔌 |   |  Extended faceswap extension for StableDiffusion web-ui with multiple faceswaps, inpainting, checkpoints, ....  |
| 2023-07-21 | [Alpha-VLLM/LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory) | 1341 | 🔠🖼️⛽1️⃣2️⃣🔨 |  Python | An Open-source Toolkit for LLM Development |
| 2023-07-21 | [OPPO-Mente-Lab/Subject-Diffusion](https://github.com/OPPO-Mente-Lab/Subject-Diffusion) | 145 | 🖼️`⛽`🚌2️⃣ |   | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning |
| 2023-07-21 | [segmind/distill-sd](https://github.com/segmind/distill-sd) | 275 | 🖼️🚌2️⃣ |   | Segmind Distilled diffusion |
| 2023-07-20 | [ThisisBillhe/tiny-stable-diffusion](https://github.com/ThisisBillhe/tiny-stable-diffusion) | 91 | 🔠🖼️✂️ |   | Tiny optimized Stable-diffusion that can run on GPUs with just 1GB of VRAM. (Beta) |
| 2023-07-18 | [continue-revolution/sd-webui-animatediff](https://github.com/continue-revolution/sd-webui-animatediff) | 384 | 🖼️🔌 |   | AnimateDiff for AUTOMATIC1111 Stable Diffusion WebUI |
| 2023-07-16 | [caopulan/iKUNet](https://github.com/caopulan/iKUNet) | 137 | 🖼️🔨 |  None | 近年来，由于明星、企业频繁塌房，衍生出一个新的需求，即移除情节中的某个元素，如某个明星或某个赞助商，我们将这个任务命名为🎥元素移除。  |
| 2023-07-16 | [magic-research/bubogpt](https://github.com/magic-research/bubogpt) | 306 | 🔠🖼️⛽🚌 |   | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-15 | [AILab-CVC/SEED](https://github.com/AILab-CVC/SEED) | 147 | 🖼️`🚌` |   | Empowers LLMs with the ability to see and draw. |
| 2023-07-15 | [CodeAlchemyAI/ViLT-GPT](https://github.com/CodeAlchemyAI/ViLT-GPT) | 114 | 🔠🖼️🔨 |  Python | By integrating OpenAI's Language Models (LLM) and LangChain with Vision-and-Language models, this app can answer queries based on the content of images.  |
| 2023-07-15 | [RimoChan/emmmbedding](https://github.com/RimoChan/emmmbedding) | 138 | 🖼️🔨 |  Python | 【emmmbedding】不用存储的图床！ |
| 2023-07-14 | [vitoplantamura/OnnxStream](https://github.com/vitoplantamura/OnnxStream) | 707 | 🖼️💡 |   | Running Stable Diffusion on a RPI Zero 2 (or in 260MB of RAM) |
| 2023-07-13 | [ThioJoe/Full-Stack-AI-Meme-Generator](https://github.com/ThioJoe/Full-Stack-AI-Meme-Generator) | 206 | 🔠🖼️🔨 |  Python | Uses Various AI Service APIs to generate memes with text and images |
| 2023-07-13 | [bytedance/lynx-llm](https://github.com/bytedance/lynx-llm) | 163 | 🔠🖼️2️⃣❓ |   | paper: https://arxiv.org/abs/2307.02469 page: https://lynx-llm.github.io/ |
| 2023-07-12 | [SeargeDP/SeargeSDXL](https://github.com/SeargeDP/SeargeSDXL) | 274 | 🖼️🔨 |  Python | Custom nodes and workflows for SDXL in ComfyUI |
| 2023-07-12 | [yangyuke001/SD-inference](https://github.com/yangyuke001/SD-inference) | 177 | 🔠🖼️💡 |   | Stable Diffusion inference |
| 2023-07-11 | [baaivision/Emu](https://github.com/baaivision/Emu) | 487 | 🔠🖼️🚌 |   | Emu: An Open Multimodal Generalist |
| 2023-07-08 | [Yujun-Shi/DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 572 | 🖼️🚌2️⃣ |   | Official code for DragDiffusion |
| 2023-07-07 | [ringa-tech/asistente-virtual](https://github.com/ringa-tech/asistente-virtual) | 127 | 🔠🖼️🚕 |   | An attempt to extend PULSE to a biomedical multimodal conversational assistant. |
| 2023-07-06 | [camenduru/sdxl-colab](https://github.com/camenduru/sdxl-colab) | 225 | 🖼️🔨 |  Jupyter Notebook |  |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | 298 | 🔠🖼️⛽`🚌`2️⃣ |   | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [sd-fabric/fabric](https://github.com/sd-fabric/fabric) | 250 | 🖼️🔨 |  Python |  |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 431 | 🖼️⛽🚌2️⃣ |   | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-07-02 | [antfu/sd-webui-qrcode-toolkit](https://github.com/antfu/sd-webui-qrcode-toolkit) | 460 | 🖼️🔌 |   | Anthony's QR Toolkit for Stable Diffusion WebUI |
| 2023-07-01 | [TonyLianLong/stable-diffusion-xl-demo](https://github.com/TonyLianLong/stable-diffusion-xl-demo) | 173 | 🔠🖼️🔨 |  Jupyter Notebook | A gradio web UI demo for Stable Diffusion XL 1.0, with refiner and MultiGPU support |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | 763 | 🔠🖼️🚌`2️⃣`🀄 |   | Chinese and English Multimodal Large Model Series (Chat and Paint) \| 基于CPM基础模型的中英双语多模态大模型系列 |
| 2023-06-30 | [jtydhr88/sd-webui-3d-editor](https://github.com/jtydhr88/sd-webui-3d-editor) | 90 | 🖼️🔌 |   | A custom extension for sd-webui that with 3D modeling features (add/edit basic elements, load your custom model, modify scene and so on), then send screenshot to txt2img or img2img as your ControlNet's reference image, basing on ThreeJS editor |
| 2023-06-27 | [SALT-NLP/LLaVAR](https://github.com/SALT-NLP/LLaVAR) | 124 | 🔠🖼️⛽🚌2️⃣ |   | Code/Data for the paper: "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding" |
| 2023-06-27 | [painebenjamin/app.enfugue.ai](https://github.com/painebenjamin/app.enfugue.ai) | 184 | 🖼️🔨 |  JavaScript | ENFUGUE is a feature-rich self-hosted Stable Diffusion webapp |
| 2023-06-26 | [antfu/qrcode-toolkit](https://github.com/antfu/qrcode-toolkit) | 852 | 🖼️🔌 |   | Anthony's QR Code Toolkit for AI generated QR Codes |
| 2023-06-26 | [artyfacialintelagent/CloneCleaner](https://github.com/artyfacialintelagent/CloneCleaner) | 69 | 🖼️🔌 |   | An extension for Automatic1111 to work around Stable Diffusion's "clone problem". It automatically modifies your prompts with random names, nationalities, hair style and hair color to create more variations in generated people. |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | 8609 | 🖼️⛽🚌2️⃣ |   | Generative Models by Stability AI |
| 2023-06-17 | [e-johnstonn/FableForge](https://github.com/e-johnstonn/FableForge) | 304 | 🔠🖼️🔨 |  Python | Generate a picture book from a single prompt using OpenAI function calling, replicate, and Deep Lake |
| 2023-06-17 | [s0md3v/sd-webui-roop](https://github.com/s0md3v/sd-webui-roop) | 2087 | 🖼️🔌 |   | roop extension for StableDiffusion web-ui |
| 2023-06-14 | [life-exe/UnrealOpenAIPlugin](https://github.com/life-exe/UnrealOpenAIPlugin) | 73 | 🔠🖼️🎵🔨 |  C++ | This plugin is a comprehensive Unreal Engine wrapper for the OpenAI API. |
| 2023-06-13 | [SizheAn/PanoHead](https://github.com/SizheAn/PanoHead) | 1442 | 🖼️🚌2️⃣🧊 |   | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-06 | [autodistill/autodistill](https://github.com/autodistill/autodistill) | 555 | 🖼️🔨 |  Python | Images to inference with no labeling (use foundation models to train supervised models) |
| 2023-06-05 | [Licoy/ChatGPT-Midjourney](https://github.com/Licoy/ChatGPT-Midjourney) | 4473 | 🔠🖼️🔨 |  TypeScript | 🍭 一键拥有你自己的 ChatGPT+Midjourney 网页服务 \| Own your own ChatGPT+Midjourney web service with one click |
| 2023-06-05 | [Richasy/FantasyCopilot](https://github.com/Richasy/FantasyCopilot) | 351 | 🔠🖼️🎵🔨 |  C# | A new-age AI desktop tool |
| 2023-06-04 | [axodox/axodox-machinelearning](https://github.com/axodox/axodox-machinelearning) | 522 | 🖼️💡 |   | This repository contains a C++ ONNX implementation of StableDiffusion. |
| 2023-05-29 | [icoz69/StyleAvatar3D](https://github.com/icoz69/StyleAvatar3D) | 456 | 🖼️📝🧊 |   | Official repo for StyleAvatar3D |
| 2023-05-23 | [ShihaoZhaoZSH/Uni-ControlNet](https://github.com/ShihaoZhaoZSH/Uni-ControlNet) | 378 | 🖼️🔨 |  Python | Uni-ControlNet is a novel controllable diffusion model that allows for the simultaneous utilization of different local controls and global controls in a flexible and composable manner within one model. |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 534 | 🔠🖼️⛽🚌 |   | 🩺 首个会看胸部X光片的中文多模态医学大模型 \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1135 | 🔠🖼️🎵⛽🚌2️⃣ |   | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-20 | [OpenGVLab/DragGAN](https://github.com/OpenGVLab/DragGAN) | 4829 | 🖼️🔨 |  Python | Unofficial Implementation of DragGAN - "Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold" （DragGAN 全功能实现，在线Demo，本地部署试用，代码、模型已全部开源，支持Windows, macOS, Linux） |
| 2023-05-20 | [pkuliyi2015/sd-webui-stablesr](https://github.com/pkuliyi2015/sd-webui-stablesr) | 671 | 🖼️🔌 |   | StableSR for Stable Diffusion WebUI - Ultra High-quality Image Upscaler |
| 2023-05-19 | [SHI-Labs/Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | 588 | 🖼️🚌 |   | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 565 | 🖼️🚌1️⃣2️⃣ |   | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 434 | 🖼️`🚌``2️⃣` |   | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [drboog/ProFusion](https://github.com/drboog/ProFusion) | 415 | 🖼️🔨 |  Jupyter Notebook | Code for Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | 339 | 🔠🖼️⛽🚕2️⃣ |   | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-18 | [salesforce/UniControl](https://github.com/salesforce/UniControl) | 478 | 🖼️🚌 |   | Unified Controllable Visual Generation Model |
| 2023-05-18 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | 589 | 🔠🖼️🚌2️⃣ |   | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 455 | 🖼️`⛽`🚌`2️⃣` |   | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-17 | [simoninithomas/awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | 260 | 🔠🖼️🎵🎥📝 |   | A curated list of awesome AI tools for game developers |
| 2023-05-13 | [Zo3i/chatgptWithMidjourney](https://github.com/Zo3i/chatgptWithMidjourney) | 396 | 🔠🖼️🔨 |  TypeScript |  |
| 2023-05-12 | [Stability-AI/StableSwarmUI](https://github.com/Stability-AI/StableSwarmUI) | 667 | 🖼️🔨 |  C# | StableSwarmUI, A Modular Stable Diffusion Web-User-Interface, with an emphasis on making powertools easily accessible, high performance, and extensibility. |
| 2023-05-11 | [fiatrete/OpenDAN-Personal-AI-OS](https://github.com/fiatrete/OpenDAN-Personal-AI-OS) | 1236 | 🔠🖼️🎵🔨 |  Python | OpenDAN is an open source Personal AI OS , which consolidates various AI modules in one place for your personal use. |
| 2023-05-08 | [Physton/sd-webui-prompt-all-in-one](https://github.com/Physton/sd-webui-prompt-all-in-one) | 1467 | 🖼️🔌 |   | This is an extension based on sd-webui, aimed at improving the user experience of the prompt/negative prompt input box. It has a more intuitive and powerful input interface function, and provides automatic translation, history record, and bookmarking functions.    这是一个基于 sd-webui 的扩展，旨在提高提示词/反向提示词输入框的使用体验。它拥有更直观、强大的输入界面功能，它提供了自动翻译、历史记录和收藏等功能。 |
| 2023-05-06 | [yankooliveira/sd-webui-photopea-embed](https://github.com/yankooliveira/sd-webui-photopea-embed) | 628 | 🖼️🔌 |   | A simple Stable Diffusion WebUI extension that adds a Photopea tab and integration. |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2376 | 🔠🖼️🚌`1️⃣`2️⃣ |   | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1159 | 🖼️⛽🚌2️⃣ |   | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-02 | [Docta-ai/docta](https://github.com/Docta-ai/docta) | 1303 | 🔠🖼️⛽ |   | A Doctor for your data |
| 2023-05-01 | [FurkanGozukara/Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion) | 856 | 🖼️📝 |   | Stable Diffusion, SDXL, LoRA Training, DreamBooth Training, Automatic1111 Web UI, DeepFake, Deep Fakes, TTS, Animation, Text To Video, Tutorials, Guides, Lectures, Courses, ComfyUI, Google Colab, RunPod, NoteBooks, ControlNet, TTS, Voice Cloning, AI, AI News, ML, ML News, News, Tech, Tech News, Kohya LoRA, Kandinsky 2, DeepFloyd IF, Midjourney |
| 2023-04-29 | [mishalhossin/Discord-AI-Chatbot](https://github.com/mishalhossin/Discord-AI-Chatbot) | 1034 | 🖼️🔨 |  Python | This Discord chatbot is incredibly versatile, offering a wide range of customization options.  |
| 2023-04-28 | [mlfoundations/datacomp](https://github.com/mlfoundations/datacomp) | 381 | 🔠🖼️⛽ |   | DataComp: In search of the next generation of multimodal datasets |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 272 | 🖼️⛽🚌2️⃣ |   | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [Bing-su/adetailer](https://github.com/Bing-su/adetailer) | 1954 | 🖼️🔌 |   | Auto detecting, masking and inpainting with detection model. |
| 2023-04-26 | [mosaicml/diffusion](https://github.com/mosaicml/diffusion) | 442 | 🖼️2️⃣ |   | This repo contains code used to train your own Stable Diffusion model on your own data. |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1164 | 🔠🖼️⛽🚌 |   | Multimodal-GPT |
| 2023-04-26 | [vijishmadhavan/UnpromptedControl](https://github.com/vijishmadhavan/UnpromptedControl) | 349 | 🔠🖼️🔨 |  Jupyter Notebook | Remove unwanted objects and restore images without prompts, powered by ControlNet. |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1349 | 🔠🖼️⛽🚌2️⃣ |   | mPLUG-Owl🦉: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [erictik/midjourney-api](https://github.com/erictik/midjourney-api) | 1038 | 🖼️🔨 |  TypeScript | MidJourney client. Unofficial Node.js client |
| 2023-04-24 | [novicezk/midjourney-proxy](https://github.com/novicezk/midjourney-proxy) | 2682 | 🖼️🔨 |  Java | 代理 MidJourney 的discord频道，实现api形式调用AI绘图 |
| 2023-04-24 | [stassius/StableHoudini](https://github.com/stassius/StableHoudini) | 308 | 🖼️🔌 |   | Stable Diffusion Houdini Toolset |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 568 | 🔠🖼️⛽🚌2️⃣ |   | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-22 | [LemonQu-GIT/ChatGLM-6B-Engineering](https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering) | 534 | 🔠🖼️🔨 |  Python | ChatGLM-6B Prompt Engineering Project |
| 2023-04-20 | [SupaGruen/StableDiffusion-CheatSheet](https://github.com/SupaGruen/StableDiffusion-CheatSheet) | 1341 | 🖼️📝 |   | A list of StableDiffusion styles and some notes for offline use. Pure HTML, CSS and a bit of JS. |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 750 | 🔠🖼️🚌2️⃣✂️ |   | MiniGPT-4 中文部署翻译 完善部署细节 |
| 2023-04-19 | [lupantech/chameleon-llm](https://github.com/lupantech/chameleon-llm) | 859 | 🔠🖼️🔨 |  Jupyter Notebook | Codes for "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models". |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 4531 | 🔠🖼️⛽🚌1️⃣2️⃣ |   | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-17 | [houseofsecrets/SdPaint](https://github.com/houseofsecrets/SdPaint) | 1518 | 🖼️🔌 |   | Stable Diffusion Painting |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22143 | 🔠🖼️🚌1️⃣2️⃣ |   | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-13 | [Anything-of-anything/Anything-3D](https://github.com/Anything-of-anything/Anything-3D) | 1286 | 🖼️`🔨`🧊 |   | Segment-Anything + 3D. Let's lift anything to 3D. |
| 2023-04-12 | [CiaraStrawberry/TemporalKit](https://github.com/CiaraStrawberry/TemporalKit) | 1438 | 🖼️🔌 |   | An all in one solution for adding Temporal Stability to a Stable Diffusion Render via an automatic1111 extension |
| 2023-04-12 | [showlab/Image2Paragraph](https://github.com/showlab/Image2Paragraph) | 689 | 🖼️🔨 |  Python | [A toolbox for fun.] Transform Image into Unique Paragraph with ChatGPT, BLIP2, OFA, GRIT, Segment Anything, ControlNet. |
| 2023-04-10 | [continue-revolution/sd-webui-segment-anything](https://github.com/continue-revolution/sd-webui-segment-anything) | 2392 | 🖼️🔌 |   | Segment Anything for Stable Diffusion WebUI |
| 2023-04-09 | [KohakuBlueleaf/a1111-sd-webui-lycoris](https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris) | 736 | 🖼️🔌 |   | An extension for stable-diffusion-webui to load lycoris models.  |
| 2023-04-09 | [geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 3954 | 🖼️🎥🚌🧊 |   | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-09 | [sail-sg/EditAnything](https://github.com/sail-sg/EditAnything) | 2522 | 🖼️🔨 |  Python | Edit anything in images  powered by segment-anything, ControlNet, StableDiffusion, etc. |
| 2023-04-08 | [agiresearch/OpenAGI](https://github.com/agiresearch/OpenAGI) | 1336 | 🔠🖼️🔨 |  Python | OpenAGI: When LLM Meets Domain Experts |
| 2023-04-07 | [ttengwang/Caption-Anything](https://github.com/ttengwang/Caption-Anything) | 1346 | 🔠🖼️🔨 |  Python | Caption-Anything is a versatile tool combining image segmentation, visual captioning, and ChatGPT, generating tailored captions with diverse controls for user preferences. https://huggingface.co/spaces/TencentARC/Caption-Anything https://huggingface.co/spaces/VIPLab/Caption-Anything |
| 2023-04-06 | [IDEA-Research/Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) | 10465 | 🔠🖼️🔨 |  Jupyter Notebook | Grounded-SAM: Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | 2458 | 🖼️🚌2️⃣🧊 |   | A unified framework for 3D content generation. |
| 2023-04-04 | [carefree0910/carefree-drawboard](https://github.com/carefree0910/carefree-drawboard) | 907 | 🖼️🔨 |  TypeScript | 🎨 Infinite Drawboard in Python |
| 2023-04-04 | [soulteary/docker-prompt-generator](https://github.com/soulteary/docker-prompt-generator) | 1027 | 🔠🖼️🔨 |  Python | Using a Model to generate prompts for Model applications. / 使用模型来生成作图咒语的偷懒工具，支持 MidJourney、Stable Diffusion 等。 |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | 2286 | 🔠🖼️⛽🚌2️⃣ |   | 🦦 Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-04-01 | [THUDM/ImageReward](https://github.com/THUDM/ImageReward) | 596 | 🔠🖼️3️⃣🔌 |   | ImageReward: Learning and Evaluating Human Preferences for Text-to-image Generation |
| 2023-03-30 | [microsoft/JARVIS](https://github.com/microsoft/JARVIS) | 21632 | 🔠🖼️🎵🔨 |  Python | JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf |
| 2023-03-28 | [dbolya/tomesd](https://github.com/dbolya/tomesd) | 1014 | 🖼️🔌 |   | Speed up Stable Diffusion with this one simple trick! |
| 2023-03-26 | [visual-openllm/visual-openllm](https://github.com/visual-openllm/visual-openllm) | 1111 | 🔠🖼️🔨 |  Python | something like visual-chatgpt, 文心一言的开源版 |
| 2023-03-23 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1258 | 🖼️🚌`2️⃣`🧊 |   | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-21 | [lukasHoel/text2room](https://github.com/lukasHoel/text2room) | 834 | 🔠🖼️🚌🧊 |   | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models (ICCV2023). |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4669 | 🔠🖼️⛽🚌2️⃣ |   | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [hako-mikan/sd-webui-regional-prompter](https://github.com/hako-mikan/sd-webui-regional-prompter) | 817 | 🖼️🔌 |   | set prompt to divided region |
| 2023-03-19 | [kabachuha/sd-webui-text2video](https://github.com/kabachuha/sd-webui-text2video) | 1040 | 🖼️🎥🔌 |   | Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies |
| 2023-03-18 | [go-skynet/LocalAI](https://github.com/go-skynet/LocalAI) | 10065 | 🔠🖼️💡 |   | :robot: Self-hosted, community-driven, local OpenAI compatible API. Drop-in replacement for OpenAI running LLMs on consumer-grade hardware. Free Open Source OpenAI alternative. No GPU required. Runs ggml, GPTQ, onnx, TF compatible models: llama, gpt4all, rwkv, whisper, vicuna, koala, gpt4all-j, cerebras, falcon, dolly, starcoder, and many others |
| 2023-03-17 | [cvlab-columbia/zero123](https://github.com/cvlab-columbia/zero123) | 1674 | 🖼️2️⃣🧊 |   | Zero-1-to-3: Zero-shot One Image to 3D Object (ICCV 2023) |
| 2023-03-17 | [volotat/SD-CN-Animation](https://github.com/volotat/SD-CN-Animation) | 682 | 🖼️🔌 |   | This script allows to automate video stylization task using StableDiffusion and ControlNet. |
| 2023-03-16 | [Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) | 146836 | 🔠🖼️🎵🔨 |  Python | An experimental open-source attempt to make GPT-4 fully autonomous. |
| 2023-03-15 | [microsoft/MM-REACT](https://github.com/microsoft/MM-REACT) | 763 | 🔠🖼️🎥🔨 |  Python | Official repo for MM-REACT |
| 2023-03-14 | [lllyasviel/ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | 3315 | 🖼️🚌 |   | Nightly release of ControlNet 1.1 |
| 2023-03-13 | [KU-CVLAB/3DFuse](https://github.com/KU-CVLAB/3DFuse) | 636 | 🖼️🚌🧊 |   | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-11 | [hnmr293/sd-webui-cutoff](https://github.com/hnmr293/sd-webui-cutoff) | 953 | 🖼️🔌 |   | Cutoff - Cutting Off Prompt Effect |
| 2023-03-10 | [thu-ml/unidiffuser](https://github.com/thu-ml/unidiffuser) | 1054 | 🖼️🚌 |   | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2870 | 🔠🖼️🚌`2️⃣` |   | Official implementation of the paper "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-06 | [mlc-ai/web-stable-diffusion](https://github.com/mlc-ai/web-stable-diffusion) | 3023 | 🖼️💡 |   | Bringing stable diffusion models to web browsers. Everything runs inside the browser with no server support.  |
| 2023-03-02 | [jexom/sd-webui-depth-lib](https://github.com/jexom/sd-webui-depth-lib) | 1215 | 🖼️🔌 |   | Depth map library for use with the Control Net extension for Automatic1111/stable-diffusion-webui |
| 2023-03-02 | [microsoft/TaskMatrix](https://github.com/microsoft/TaskMatrix) | 33916 | 🔠🖼️🔨 |  Python | TaskMatrix connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting. |
| 2023-03-01 | [Shiriluz/Word-As-Image](https://github.com/Shiriluz/Word-As-Image) | 988 | 🖼️🔨 |  Python |  |
| 2023-02-27 | [KohakuBlueleaf/LyCORIS](https://github.com/KohakuBlueleaf/LyCORIS) | 1364 | 🖼️📝 |   | Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion. |
| 2023-02-27 | [Scholar01/sd-webui-mov2mov](https://github.com/Scholar01/sd-webui-mov2mov) | 1441 | 🖼️🔌 |   | 适用于Automatic1111/stable-diffusion-webui 的 Mov2mov 插件。 |
| 2023-02-27 | [pkuliyi2015/multidiffusion-upscaler-for-automatic1111](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111) | 3386 | 🖼️🔌 |   | Tiled Diffusion and VAE optimize, licensed under CC BY-NC-SA 4.0 |
| 2023-02-26 | [openai/consistency_models](https://github.com/openai/consistency_models) | 5381 | 🖼️🚌2️⃣✂️ |   | Official repo for consistency models. |
| 2023-02-25 | [hnmr293/sd-webui-llul](https://github.com/hnmr293/sd-webui-llul) | 662 | 🖼️🔌 |   | LLuL - Local Latent upscaLer |
| 2023-02-23 | [coolzilj/Blender-ControlNet](https://github.com/coolzilj/Blender-ControlNet) | 686 | 🖼️🔌 |   | Using ControlNet right in Blender. |
| 2023-02-23 | [kale5195/chilloutai](https://github.com/kale5195/chilloutai) | 753 | 🖼️📝 |   | AI 图片生成 |
| 2023-02-21 | [Nutlope/roomGPT](https://github.com/Nutlope/roomGPT) | 8259 | 🖼️🔨 |  TypeScript | Upload a photo of your room to generate your dream room with AI. |
| 2023-02-19 | [prompt-engineering/understand-prompt](https://github.com/prompt-engineering/understand-prompt) | 3314 | 🔠🖼️📝 |   | 【🔞🔞🔞 内含不适合未成年人阅读的图片】基于我擅长的编程、绘画、写作展开的 AI 探索和总结：StableDiffusion 是一种强大的图像生成模型，能够通过对一张图片进行演化来生成新的图片。ChatGPT 是一个基于 Transformer 的语言生成模型，它能够自动为输入的主题生成合适的文章。而 Github Copilot 是一个智能编程助手，能够加速日常编程活动。 |
| 2023-02-15 | [TencentARC/T2I-Adapter](https://github.com/TencentARC/T2I-Adapter) | 2245 | 🔠🖼️🚌 |   | T2I-Adapter |
| 2023-02-13 | [replicate/scribble-diffusion](https://github.com/replicate/scribble-diffusion) | 2578 | 🖼️🔨 |  JavaScript | Turn your rough sketch into a refined image using AI |
| 2023-02-12 | [Mikubill/sd-webui-controlnet](https://github.com/Mikubill/sd-webui-controlnet) | 12144 | 🖼️🔌 |   | WebUI extension for ControlNet |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | 22794 | 🖼️🚌2️⃣ |   | Let us control diffusion models! |
| 2023-01-20 | [deep-floyd/IF](https://github.com/deep-floyd/IF) | 7012 | 🖼️🚌 |   |  |
| 2023-01-17 | [comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 10815 | 🖼️🔨 |  Python | A powerful and modular stable diffusion GUI with a graph/nodes interface. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 5106 | 🖼️⛽🚌2️⃣ |   | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2023-01-08 | [dair-ai/ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | 4613 | 🔠🖼️🎵🎥📝 |   | 🔥Highlighting the top ML papers every week. |
| 2022-12-20 | [AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin](https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin) | 4967 | 🖼️🔌 |   | A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.  |
| 2022-12-15 | [godly-devotion/MochiDiffusion](https://github.com/godly-devotion/MochiDiffusion) | 6261 | 🖼️🔨 |  Swift | Run Stable Diffusion on Mac natively |
| 2022-12-08 | [cloneofsimo/lora](https://github.com/cloneofsimo/lora) | 5539 | 🖼️2️⃣ |   | Using Low-rank adaptation to quickly fine-tune diffusion models. |
| 2022-12-06 | [openai/point-e](https://github.com/openai/point-e) | 5758 | 🖼️🚌🧊 |   | Point cloud diffusion for 3D model synthesis |
| 2022-12-05 | [shinework/photoshot](https://github.com/shinework/photoshot) | 2322 | 🖼️🔨 |  TypeScript | An open-source AI avatar generator web app - https://photoshot.app |
| 2022-11-25 | [riffusion/riffusion](https://github.com/riffusion/riffusion) | 2445 | 🖼️🎵🔨 |  Python | Stable diffusion for real-time music generation |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | 6133 | 🖼️🎵🎥🚌`2️⃣` |   | [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-23 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | 28956 | 🖼️⛽🚌 |   | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-11-20 | [riffusion/riffusion-app](https://github.com/riffusion/riffusion-app) | 2419 | 🖼️🎵🔨 |  TypeScript | Stable diffusion for real-time music generation (web app) |
| 2022-11-16 | [apple/ml-stable-diffusion](https://github.com/apple/ml-stable-diffusion) | 14247 | 🖼️💡 |   | Stable Diffusion with Core ML on Apple Silicon |
| 2022-10-30 | [bmaltais/kohya_ss](https://github.com/bmaltais/kohya_ss) | 5304 | 🖼️🔨 |  Python | This repository provides a Windows-focused Gradio GUI for Kohya's Stable Diffusion trainers. The GUI allows you to set the training parameters and generate and run the required CLI commands to train the model. |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2752 | 🔠🖼️`🎥`⛽🚌2️⃣ |   | An open-source framework for training large multimodal models. |
| 2022-10-18 | [runwayml/stable-diffusion](https://github.com/runwayml/stable-diffusion) | 2908 | 🖼️🚌 |   | Latent Text-to-Image Diffusion |
| 2022-10-14 | [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2) | 2325 | 🖼️🔨 |  Jupyter Notebook | Kandinsky 2 — multilingual text2image latent diffusion model |
| 2022-10-14 | [deforum-art/sd-webui-deforum](https://github.com/deforum-art/sd-webui-deforum) | 2007 | 🖼️🔌 |   | Deforum extension for AUTOMATIC1111's Stable Diffusion webui |
| 2022-10-13 | [huggingface/diffusion-models-class](https://github.com/huggingface/diffusion-models-class) | 2522 | 🖼️📝 |   | Materials for the Hugging Face Diffusion Models Course |
| 2022-10-11 | [civitai/civitai](https://github.com/civitai/civitai) | 4425 | 🖼️🔌 |   | A repository of models, textual inversions, and more |
| 2022-10-08 | [hua1995116/awesome-ai-painting](https://github.com/hua1995116/awesome-ai-painting) | 9331 | 🖼️📝 |   | AI绘画资料合集（包含国内外可使用平台、使用教程、参数教程、部署教程、业界新闻等等） stable diffusion tutorial、disco diffusion tutorial、 AI Platform |
| 2022-10-06 | [ashawkey/stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | 6572 | 🖼️🚌🧊 |   | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-10-05 | [camenduru/stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab) | 13393 | 🖼️🔨 |  Jupyter Notebook | stable diffusion webui colab |
| 2022-10-03 | [google/prompt-to-prompt](https://github.com/google/prompt-to-prompt) | 2293 | 🖼️🔨 |  Jupyter Notebook | Null-text inversion enables intuitive text-based editing of real images with the Stable Diffusion model. |
| 2022-09-21 | [TheLastBen/fast-stable-diffusion](https://github.com/TheLastBen/fast-stable-diffusion) | 6450 | 🖼️🔨 |  Python | fast-stable-diffusion + DreamBooth |
| 2022-09-17 | [JoePenna/Dreambooth-Stable-Diffusion](https://github.com/JoePenna/Dreambooth-Stable-Diffusion) | 3026 | 🖼️🔨 |  Jupyter Notebook | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) by way of Textual Inversion (https://arxiv.org/abs/2208.01618) for Stable Diffusion (https://arxiv.org/abs/2112.10752). Tweaks focused on training faces, objects, and styles. |
| 2022-09-13 | [carefree0910/carefree-creator](https://github.com/carefree0910/carefree-creator) | 2050 | 🖼️🔨 |  Jupyter Notebook | AI magics meet Infinite draw board. |
| 2022-09-12 | [brycedrennan/imaginAIry](https://github.com/brycedrennan/imaginAIry) | 7275 | 🖼️🔨 |  Python | AI imagined images. Pythonic generation of images. |
| 2022-09-08 | [carson-katri/dream-textures](https://github.com/carson-katri/dream-textures) | 6971 | 🖼️🔨 |  Python | Stable Diffusion built-in to Blender |
| 2022-09-06 | [XavierXiao/Dreambooth-Stable-Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) | 6900 | 🖼️2️⃣ |   | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion |
| 2022-09-06 | [divamgupta/diffusionbee-stable-diffusion-ui](https://github.com/divamgupta/diffusionbee-stable-diffusion-ui) | 10755 | 🖼️🔨 |  JavaScript | Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed. |
| 2022-09-04 | [swyxio/ai-notes](https://github.com/swyxio/ai-notes) | 3626 | 🔠🖼️🎵🎥📝 |   | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
| 2022-09-02 | [lkwq007/stablediffusion-infinity](https://github.com/lkwq007/stablediffusion-infinity) | 3564 | 🖼️🔨 |  Python | Outpainting with Stable Diffusion on an infinite canvas |
| 2022-08-27 | [AbdBarho/stable-diffusion-webui-docker](https://github.com/AbdBarho/stable-diffusion-webui-docker) | 4520 | 🖼️🔨 |  Dockerfile | Easy Docker setup for Stable Diffusion with user-friendly UI |
| 2022-08-24 | [Sygil-Dev/sygil-webui](https://github.com/Sygil-Dev/sygil-webui) | 7574 | 🖼️🔨 |  Python | Stable Diffusion web UI |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 6372 | 🔠🖼️⛽🚌1️⃣2️⃣ |   | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-23 | [easydiffusion/easydiffusion](https://github.com/easydiffusion/easydiffusion) | 7477 | 🖼️🔨 |  JavaScript | Easiest 1-click way to install and use Stable Diffusion on your computer. Provides a browser UI for generating images from text prompts and images. Just enter your text prompt, and see the generated image. |
| 2022-08-22 | [AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) | 97867 | 🖼️🔨 |  Python | Stable Diffusion web UI |
| 2022-08-22 | [Stability-AI/stability-sdk](https://github.com/Stability-AI/stability-sdk) | 2326 | 🖼️🔨 |  Jupyter Notebook | SDK for interacting with stability.ai APIs (e.g. stable diffusion inference) |
| 2022-08-17 | [invoke-ai/InvokeAI](https://github.com/invoke-ai/InvokeAI) | 18289 | 🖼️🔌 |   | InvokeAI is a leading creative engine for Stable Diffusion models, empowering professionals, artists, and enthusiasts to generate and create visual media using the latest AI-driven technologies. The solution offers an industry leading WebUI, supports terminal use through a CLI, and serves as the foundation for multiple commercial products. |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | 59212 | 🖼️⛽🚌 |   | A latent text-to-image diffusion model |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | 2551 | 🖼️⛽🚌2️⃣ |   |  |
| 2022-07-25 | [modelscope/modelscope](https://github.com/modelscope/modelscope) | 3605 | 🔠🖼️🎵2️⃣ |   | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-07-15 | [facebookincubator/AITemplate](https://github.com/facebookincubator/AITemplate) | 4167 | 🖼️💡 |   | AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference. |
| 2022-07-03 | [willwulfken/MidJourney-Styles-and-Keywords-Reference](https://github.com/willwulfken/MidJourney-Styles-and-Keywords-Reference) | 10657 | 🖼️📝 |   | A reference containing Styles and Keywords that you can use with MidJourney AI. There are also pages showing resolution comparison, image weights, and much more! |
| 2022-06-30 | [jina-ai/discoart](https://github.com/jina-ai/discoart) | 3823 | 🖼️🔨 |  Python | 🪩 Create Disco Diffusion artworks in one line |
| 2022-05-30 | [huggingface/diffusers](https://github.com/huggingface/diffusers) | 17335 | 🖼️🎵2️⃣📝 |   | 🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
