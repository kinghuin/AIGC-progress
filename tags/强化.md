| Date | Repository | Stars | Description | tags |
|------------|---------|-------|-------------|-------------|
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | ![PKU-Alignment/safe-rlhf Stars](https://img.shields.io/github/stars/PKU-Alignment/safe-rlhf.svg?label=&style=flat-square) | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | ![hiyouga/ChatGLM-Efficient-Tuning Stars](https://img.shields.io/github/stars/hiyouga/ChatGLM-Efficient-Tuning.svg?label=&style=flat-square) | Fine-tuning ChatGLM-6B with PEFT \| åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ | `æ–‡æœ¬`,`æ•°æ®`,`è®­ç»ƒ`,`å¼ºåŒ–`,`ä¸­æ–‡` |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | ![OptimalScale/LMFlow Stars](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?label=&style=flat-square) | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All. | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`å¼ºåŒ–(TD)`,`å‹ç¼©`,`æ¨ç†`,`å¯å•†ç”¨`,`ä¸­æ–‡` |
| 2023-02-28 | [juncongmoo/chatllama](https://github.com/juncongmoo/chatllama) | ![juncongmoo/chatllama Stars](https://img.shields.io/github/stars/juncongmoo/chatllama.svg?label=&style=flat-square) | ChatLLaMA ğŸ“¢ Open source implementation for LLaMA-based ChatGPT runnable in a single GPU. 15x faster training process than ChatGPT | `æ–‡æœ¬`,`å¼ºåŒ–` |
