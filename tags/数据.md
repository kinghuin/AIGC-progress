| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | ![jshilong/GPT4RoI Stars](https://img.shields.io/github/stars/jshilong/GPT4RoI.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [SpongebBob/Finetune-ChatGLM2-6B](https://github.com/SpongebBob/Finetune-ChatGLM2-6B) | ![SpongebBob/Finetune-ChatGLM2-6B Stars](https://img.shields.io/github/stars/SpongebBob/Finetune-ChatGLM2-6B.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£âœ‚ï¸ | ChatGLM2-6B å…¨å‚æ•°å¾®è°ƒï¼Œæ”¯æŒå¤šè½®å¯¹è¯çš„é«˜æ•ˆå¾®è°ƒã€‚ |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | ![zideliu/StyleDrop-PyTorch Stars](https://img.shields.io/github/stars/zideliu/StyleDrop-PyTorch.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-29 | [IMOSR/Media-LLaMA](https://github.com/IMOSR/Media-LLaMA) | ![IMOSR/Media-LLaMA Stars](https://img.shields.io/github/stars/IMOSR/Media-LLaMA.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | ä¸­æ–‡çš„è‡ªåª’ä½“å¤§è¯­è¨€æ¨¡å‹ |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | ![Stability-AI/generative-models Stars](https://img.shields.io/github/stars/Stability-AI/generative-models.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Generative Models by Stability AI |
| 2023-06-14 | [baichuan-inc/baichuan-7B](https://github.com/baichuan-inc/baichuan-7B) | ![baichuan-inc/baichuan-7B Stars](https://img.shields.io/github/stars/baichuan-inc/baichuan-7B.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | ![lyogavin/Anima Stars](https://img.shields.io/github/stars/lyogavin/Anima.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ€„ | ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [allenai/open-instruct](https://github.com/allenai/open-instruct) | ![allenai/open-instruct Stars](https://img.shields.io/github/stars/allenai/open-instruct.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-07 | [PKU-YuanGroup/ChatLaw](https://github.com/PKU-YuanGroup/ChatLaw) | ![PKU-YuanGroup/ChatLaw Stars](https://img.shields.io/github/stars/PKU-YuanGroup/ChatLaw.svg?label=&style=flat-square) | ğŸ” â›½ğŸš• | ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹ |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | ![shibing624/MedicalGPT Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ğŸ€„ | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ |
| 2023-05-31 | [yuchenlin/LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | ![yuchenlin/LLM-Blender Stars](https://img.shields.io/github/stars/yuchenlin/LLM-Blender.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | ![THUDM/WebGLM Stars](https://img.shields.io/github/stars/THUDM/WebGLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ“±ğŸ€„ | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-25 | [imoneoi/openchat](https://github.com/imoneoi/openchat) | ![imoneoi/openchat Stars](https://img.shields.io/github/stars/imoneoi/openchat.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸš•2ï¸âƒ£ | OpenChat: Less is More for Open-source Models |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | ![luohongyin/SAIL Stars](https://img.shields.io/github/stars/luohongyin/SAIL.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | SAIL: Search Augmented Instruction Learning |
| 2023-05-24 | [wenge-research/YaYi](https://github.com/wenge-research/YaYi) | ![wenge-research/YaYi Stars](https://img.shields.io/github/stars/wenge-research/YaYi.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ | é›…æ„å¤§æ¨¡å‹ï¼šä¸ºæ¯ä¸€å®¶ä¼ä¸šæ‰“é€ å¤§æ¨¡å‹ |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | ![OFA-Sys/ExpertLLaMA Stars](https://img.shields.io/github/stars/OFA-Sys/ExpertLLaMA.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | ![WangRongsheng/XrayGLM Stars](https://img.shields.io/github/stars/WangRongsheng/XrayGLM.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | ğŸ©º é¦–ä¸ªä¼šçœ‹èƒ¸éƒ¨Xå…‰ç‰‡çš„ä¸­æ–‡å¤šæ¨¡æ€åŒ»å­¦å¤§æ¨¡å‹ \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | ![lyuchenyang/Macaw-LLM Stars](https://img.shields.io/github/stars/lyuchenyang/Macaw-LLM.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸµâ›½ğŸšŒ2ï¸âƒ£ | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-22 | [google-research-datasets/seahorse](https://github.com/google-research-datasets/seahorse) | ![google-research-datasets/seahorse Stars](https://img.shields.io/github/stars/google-research-datasets/seahorse.svg?label=&style=flat-square) | ğŸ” â›½ | Seahorse is a dataset for multilingual, multi-faceted summarization evaluation. It consists of 96K summaries with human ratings along 6 quality dimensions: comprehensibility, repetition, grammar, attribution, main idea(s), and conciseness, covering 6 languages, 9 systems and 4 datasets. |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | ![ShishirPatil/gorilla Stars](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ”¨âœ… | Gorilla: An API store for LLMs |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | ![mbzuai-oryx/Video-ChatGPT Stars](https://img.shields.io/github/stars/mbzuai-oryx/Video-ChatGPT.svg?label=&style=flat-square) | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Video-ChatGPT is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | ![mbzuai-oryx/XrayGPT Stars](https://img.shields.io/github/stars/mbzuai-oryx/XrayGPT.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸš•2ï¸âƒ£ | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | ![mit-han-lab/fastcomposer Stars](https://img.shields.io/github/stars/mit-han-lab/fastcomposer.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | ![0nutation/SpeechGPT Stars](https://img.shields.io/github/stars/0nutation/SpeechGPT.svg?label=&style=flat-square) | ğŸ” ğŸµâ›½ğŸšŒ2ï¸âƒ£ | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | ![sambanova/bloomchat Stars](https://img.shields.io/github/stars/sambanova/bloomchat.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | ![PKU-Alignment/safe-rlhf Stars](https://img.shields.io/github/stars/PKU-Alignment/safe-rlhf.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£3ï¸âƒ£ | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-12 | [SJTU-LIT/ceval](https://github.com/SJTU-LIT/ceval) | ![SJTU-LIT/ceval Stars](https://img.shields.io/github/stars/SJTU-LIT/ceval.svg?label=&style=flat-square) | ğŸ” â›½ | Official github repo for C-Eval, a Chinese evaluation suite for foundation models |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | ![TigerResearch/TigerBot Stars](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | ![Neutralzz/BiLLa Stars](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | ![ZrrSkywalker/Personalize-SAM Stars](https://img.shields.io/github/stars/ZrrSkywalker/Personalize-SAM.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | ![thunlp/WebCPM Stars](https://img.shields.io/github/stars/thunlp/WebCPM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | ![tatsu-lab/alpaca_farm Stars](https://img.shields.io/github/stars/tatsu-lab/alpaca_farm.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-05-02 | [Docta-ai/docta](https://github.com/Docta-ai/docta) | ![Docta-ai/docta Stars](https://img.shields.io/github/stars/Docta-ai/docta.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ | A Doctor for your data |
| 2023-05-02 | [salesforce/CodeTF](https://github.com/salesforce/CodeTF) | ![salesforce/CodeTF Stars](https://img.shields.io/github/stars/salesforce/CodeTF.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | ![dandelionsllm/pandallm Stars](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ |
| 2023-04-28 | [mlfoundations/datacomp](https://github.com/mlfoundations/datacomp) | ![mlfoundations/datacomp Stars](https://img.shields.io/github/stars/mlfoundations/datacomp.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ | DataComp: In search of the next generation of multimodal datasets |
| 2023-04-28 | [replit/ReplitLM](https://github.com/replit/ReplitLM) | ![replit/ReplitLM Stars](https://img.shields.io/github/stars/replit/ReplitLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ | Inference code and configs for the ReplitLM model family |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | ![Zhendong-Wang/Prompt-Diffusion Stars](https://img.shields.io/github/stars/Zhendong-Wang/Prompt-Diffusion.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | ![open-mmlab/Multimodal-GPT Stars](https://img.shields.io/github/stars/open-mmlab/Multimodal-GPT.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | Multimodal-GPT |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | ![X-PLUG/mPLUG-Owl Stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-Owl.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [bigcode-project/starcoder](https://github.com/bigcode-project/starcoder) | ![bigcode-project/starcoder Stars](https://img.shields.io/github/stars/bigcode-project/starcoder.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ | Home of StarCoder: fine-tuning & inference! |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | ![StevenGrove/GPT4Tools Stars](https://img.shields.io/github/stars/StevenGrove/GPT4Tools.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | ![THUDM/VisualGLM-6B Stars](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-23 | [mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | ![mbzuai-nlp/LaMini-LM Stars](https://img.shields.io/github/stars/mbzuai-nlp/LaMini-LM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | ![nlpxucan/WizardLM Stars](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder |
| 2023-04-21 | [lvwzhen/law-cn-ai](https://github.com/lvwzhen/law-cn-ai) | ![lvwzhen/law-cn-ai Stars](https://img.shields.io/github/stars/lvwzhen/law-cn-ai.svg?label=&style=flat-square) | ğŸ” â›½ğŸ“±ğŸ€„ | âš–ï¸ AI æ³•å¾‹åŠ©æ‰‹ |
| 2023-04-21 | [voidful/awesome-chatgpt-dataset](https://github.com/voidful/awesome-chatgpt-dataset) | ![voidful/awesome-chatgpt-dataset Stars](https://img.shields.io/github/stars/voidful/awesome-chatgpt-dataset.svg?label=&style=flat-square) | ğŸ” â›½ğŸ“ | Unlock the Power of LLM: Explore These Datasets to Train Your Own ChatGPT! |
| 2023-04-20 | [lamini-ai/lamini](https://github.com/lamini-ai/lamini) | ![lamini-ai/lamini Stars](https://img.shields.io/github/stars/lamini-ai/lamini.svg?label=&style=flat-square) | ğŸ” â›½ |  |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | ![pengxiao-song/LaWGPT Stars](https://img.shields.io/github/stars/pengxiao-song/LaWGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | ![h2oai/h2o-llmstudio Stars](https://img.shields.io/github/stars/h2oai/h2o-llmstudio.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ… | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | ![haotian-liu/LLaVA Stars](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | ![OpenLMLab/MOSS Stars](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒâœ‚ï¸âœ…ğŸ€„ | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-14 | [togethercomputer/RedPajama-Data](https://github.com/togethercomputer/RedPajama-Data) | ![togethercomputer/RedPajama-Data Stars](https://img.shields.io/github/stars/togethercomputer/RedPajama-Data.svg?label=&style=flat-square) | ğŸ” â›½ | The RedPajama-Data repository contains code for preparing large datasets for training large language models. |
| 2023-04-13 | [openai/prm800k](https://github.com/openai/prm800k) | ![openai/prm800k Stars](https://img.shields.io/github/stars/openai/prm800k.svg?label=&style=flat-square) | ğŸ” â›½ | 800,000 step-level correctness labels on LLM solutions to MATH problems |
| 2023-04-12 | [langgenius/dify](https://github.com/langgenius/dify) | ![langgenius/dify Stars](https://img.shields.io/github/stars/langgenius/dify.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ğŸ“± | One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications. |
| 2023-04-10 | [GanjinZero/RRHF](https://github.com/GanjinZero/RRHF) | ![GanjinZero/RRHF Stars](https://img.shields.io/github/stars/GanjinZero/RRHF.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ3ï¸âƒ£ | RRHF & Wombat |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | ![hiyouga/ChatGLM-Efficient-Tuning Stars](https://img.shields.io/github/stars/hiyouga/ChatGLM-Efficient-Tuning.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£3ï¸âƒ£ğŸ€„ | Fine-tuning ChatGLM-6B with PEFT \| åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ |
| 2023-04-06 | [Instruction-Tuning-with-GPT-4/GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | ![Instruction-Tuning-with-GPT-4/GPT-4-LLM Stars](https://img.shields.io/github/stars/Instruction-Tuning-with-GPT-4/GPT-4-LLM.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ | Instruction Tuning with GPT-4 |
| 2023-04-03 | [thunlp/UltraChat](https://github.com/thunlp/UltraChat) | ![thunlp/UltraChat Stars](https://img.shields.io/github/stars/thunlp/UltraChat.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ | Large-scale, Informative, and Diverse Multi-round Chat Data (and Models) |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | ![yangjianxin1/Firefly Stars](https://img.shields.io/github/stars/yangjianxin1/Firefly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹(å…¨é‡å¾®è°ƒ+QLoRA) |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | ![FreedomIntelligence/LLMZoo Stars](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ“ | âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | ![Luodian/Otter Stars](https://img.shields.io/github/stars/Luodian/Otter.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | ![LC1332/Chinese-alpaca-lora Stars](https://img.shields.io/github/stars/LC1332/Chinese-alpaca-lora.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | ![SCIR-HI/Huatuo-Llama-Med-Chinese Stars](https://img.shields.io/github/stars/SCIR-HI/Huatuo-Llama-Med-Chinese.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | Repo for BenTsao [original name: HuaTuo (åé©¼)], Llama-7B tuned with Chinese medical knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMAæ¨¡å‹æŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [SCIR-HI/Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM) | ![SCIR-HI/Med-ChatGLM Stars](https://img.shields.io/github/stars/SCIR-HI/Med-ChatGLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ | Repo for Chinese Medical ChatGLM åŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„ChatGLMæŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | ![project-baize/baize-chatbot Stars](https://img.shields.io/github/stars/project-baize/baize-chatbot.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | ![AGI-Edgerunners/LLM-Adapters Stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-29 | [yaodongC/awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset) | ![yaodongC/awesome-instruction-dataset Stars](https://img.shields.io/github/stars/yaodongC/awesome-instruction-dataset.svg?label=&style=flat-square) | ğŸ” â›½ | A collection of open-source dataset to train instruction-following LLMs (ChatGPT,LLaMA,Alpaca) |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | ![OptimalScale/LMFlow Stars](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£3ï¸âƒ£ | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [PhoebusSi/Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT) | ![PhoebusSi/Alpaca-CoT Stars](https://img.shields.io/github/stars/PhoebusSi/Alpaca-CoT.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ | We unified the interfaces of instruction-tuning data (e.g., CoT data), multiple LLMs and parameter-efficient methods (e.g., lora, p-tuning) together for easy use. Meanwhile, we created a new branch to build a Tabular LLM.ï¼ˆæˆ‘ä»¬åˆ†åˆ«ç»Ÿä¸€äº†ä¸°å¯Œçš„IFTæ•°æ®ï¼ˆå¦‚CoTæ•°æ®ï¼Œç›®å‰ä»ä¸æ–­æ‰©å……ï¼‰ã€å¤šç§è®­ç»ƒæ•ˆç‡æ–¹æ³•ï¼ˆå¦‚loraï¼Œp-tuningï¼‰ä»¥åŠå¤šç§LLMsï¼Œä¸‰ä¸ªå±‚é¢ä¸Šçš„æ¥å£ï¼Œæ‰“é€ æ–¹ä¾¿ç ”ç©¶äººå‘˜ä¸Šæ‰‹çš„LLM-IFTç ”ç©¶å¹³å°ã€‚åŒæ—¶tabular_llmåˆ†æ”¯æ„å»ºäº†é¢å‘è¡¨æ ¼æ™ºèƒ½ä»»åŠ¡çš„LLMã€‚ |
| 2023-03-24 | [databrickslabs/dolly](https://github.com/databrickslabs/dolly) | ![databrickslabs/dolly Stars](https://img.shields.io/github/stars/databrickslabs/dolly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ… | Databricksâ€™ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-23 | [yanqiangmiffy/InstructGLM](https://github.com/yanqiangmiffy/InstructGLM) | ![yanqiangmiffy/InstructGLM Stars](https://img.shields.io/github/stars/yanqiangmiffy/InstructGLM.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ | ChatGLM-6B æŒ‡ä»¤å­¦ä¹ \|æŒ‡ä»¤æ•°æ®\|Instruct |
| 2023-03-22 | [sahil280114/codealpaca](https://github.com/sahil280114/codealpaca) | ![sahil280114/codealpaca Stars](https://img.shields.io/github/stars/sahil280114/codealpaca.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ | This is the repo for the Code Alpaca project, which aims to build and share an instruction-following LLaMA model for code generation. This repo is fully based on Stanford Alpaca ,and only changes the data used for training. Training approach is the same. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£âœ‚ï¸ğŸ’¡âœ…ğŸ€„ | Chinese-LLaMA ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [Kent0n-Li/ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor) | ![Kent0n-Li/ChatDoctor Stars](https://img.shields.io/github/stars/Kent0n-Li/ChatDoctor.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ |  |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | ![LC1332/Luotuo-Chinese-LLM Stars](https://img.shields.io/github/stars/LC1332/Luotuo-Chinese-LLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [gururise/AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) | ![gururise/AlpacaDataCleaned Stars](https://img.shields.io/github/stars/gururise/AlpacaDataCleaned.svg?label=&style=flat-square) | ğŸ” â›½ | Alpaca dataset from Stanford, cleaned and curated |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | ![johannakarras/DreamPose Stars](https://img.shields.io/github/stars/johannakarras/DreamPose.svg?label=&style=flat-square) | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | ![OpenGVLab/LLaMA-Adapter Stars](https://img.shields.io/github/stars/OpenGVLab/LLaMA-Adapter.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | ![Beomi/KoAlpaca Stars](https://img.shields.io/github/stars/Beomi/KoAlpaca.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | KoAlpaca: í•œêµ­ì–´ ëª…ë ¹ì–´ë¥¼ ì´í•´í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ëª¨ë¸ |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | ![LianjiaTech/BELLE Stars](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | ![hikariming/alpaca_chinese_dataset Stars](https://img.shields.io/github/stars/hikariming/alpaca_chinese_dataset.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ğŸ€„ | äººå·¥ç²¾è°ƒçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›†å’Œä¸€æ®µchatglmçš„å¾®è°ƒä»£ç  |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | ![ChenyangQiQi/FateZero Stars](https://img.shields.io/github/stars/ChenyangQiQi/FateZero.svg?label=&style=flat-square) | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Pytorch Implementation for "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-10 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | ![tatsu-lab/stanford_alpaca Stars](https://img.shields.io/github/stars/tatsu-lab/stanford_alpaca.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-04 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | ![yxlllc/DDSP-SVC Stars](https://img.shields.io/github/stars/yxlllc/DDSP-SVC.svg?label=&style=flat-square) | ğŸµâ›½ğŸšŒ2ï¸âƒ£ | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | ![togethercomputer/OpenChatKit Stars](https://img.shields.io/github/stars/togethercomputer/OpenChatKit.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |  |
| 2023-02-11 | [AI4Finance-Foundation/FinGPT](https://github.com/AI4Finance-Foundation/FinGPT) | ![AI4Finance-Foundation/FinGPT Stars](https://img.shields.io/github/stars/AI4Finance-Foundation/FinGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•ğŸ€„ | Data-Centric FinGPT.  Open-source for open finance!  Revolutionize ğŸ”¥    We'll soon release the trained model. |
| 2023-01-23 | [openai/evals](https://github.com/openai/evals) | ![openai/evals Stars](https://img.shields.io/github/stars/openai/evals.svg?label=&style=flat-square) | ğŸ” â›½ | Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | ![timothybrooks/instruct-pix2pix Stars](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | ![karpathy/nanoGPT Stars](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-20 | [yizhongw/self-instruct](https://github.com/yizhongw/self-instruct) | ![yizhongw/self-instruct Stars](https://img.shields.io/github/stars/yizhongw/self-instruct.svg?label=&style=flat-square) | ğŸ” â›½ | Aligning pretrained language models with instruction data generated by themselves. |
| 2022-11-23 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | ![Stability-AI/stablediffusion Stars](https://img.shields.io/github/stars/Stability-AI/stablediffusion.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | ![mlfoundations/open_flamingo Stars](https://img.shields.io/github/stars/mlfoundations/open_flamingo.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | An open-source framework for training large multimodal models. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | ![GuyTevet/motion-diffusion-model Stars](https://img.shields.io/github/stars/GuyTevet/motion-diffusion-model.svg?label=&style=flat-square) | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | ![salesforce/LAVIS Stars](https://img.shields.io/github/stars/salesforce/LAVIS.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | ![CompVis/stable-diffusion Stars](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ | A latent text-to-image diffusion model |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | ![rinongal/textual_inversion Stars](https://img.shields.io/github/stars/rinongal/textual_inversion.svg?label=&style=flat-square) | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |  |
