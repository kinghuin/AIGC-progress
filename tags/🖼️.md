| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-08-25 | [awesome-ai-tools](https://github.com/mahseema/awesome-ai-tools) | 25 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | A curated list of Artificial Intelligence Top Tools |
| 2023-08-21 | [Qwen-VL](https://github.com/QwenLM/Qwen-VL) | 689 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | The official repo of Qwen-VL (é€šä¹‰åƒé—®-VL) chat & pretrained large vision language model proposed by Alibaba Cloud. |
| 2023-08-18 | [meru](https://github.com/facebookresearch/meru) | 69 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Code for the paper "Hyperbolic Image-Text Representations", Desai et al, ICML 2023 |
| 2023-08-18 | [Dataset_Quantization](https://github.com/magic-research/Dataset_Quantization) | 171 | ğŸ”  ğŸ–¼ï¸ â›½ â“  | [ICCV2023] Dataset Quantization |
| 2023-08-17 | [facefusion](https://github.com/facefusion/facefusion) | 5471 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Next generation face swapper and enhancer |
| 2023-08-16 | [IP-Adapter](https://github.com/tencent-ailab/IP-Adapter) | 414 | ğŸ–¼ï¸ ğŸšŒ  | The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.  |
| 2023-08-14 | [WanJuan1.0](https://github.com/opendatalab/WanJuan1.0) | 255 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ â›½  | ä¸‡å·1.0å¤šæ¨¡æ€è¯­æ–™ |
| 2023-08-12 | [sd-webui-go](https://github.com/SpenserCai/sd-webui-go) | 165 | ğŸ–¼ï¸ ğŸ”¨ `Go`  | This is a Go language version of the SDK based on stable-diffusion-webui. In your code, you can directly use the API interfaces of stable-diffusion-webui through object-oriented operations, instead of dealing with cumbersome JSON.  Support extensions API ! |
| 2023-08-10 | [facechain](https://github.com/modelscope/facechain) | 4106 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | FaceChain is a deep-learning toolchain for generating your Digital-Twin. |
| 2023-08-09 | [Fooocus](https://github.com/lllyasviel/Fooocus) | 8787 | ğŸ–¼ï¸ ğŸ”Œ  | Focus on prompting and generating |
| 2023-08-03 | [all-seeing](https://github.com/OpenGVLab/all-seeing) | 220 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | This is the official implementation of the paper "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World" |
| 2023-08-03 | [sd-wav2lip-uhq](https://github.com/numz/sd-wav2lip-uhq) | 162 | ğŸ–¼ï¸ ğŸ”Œ  | Wav2Lip UHQ extension for Automatic1111 |
| 2023-08-01 | [LISA](https://github.com/dvlab-research/LISA) | 856 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | Project Page for "LISA: Reasoning Segmentation via Large Language Model" |
| 2023-07-30 | [Chinese-LLaVA](https://github.com/LinkSoul-AI/Chinese-LLaVA) | 155 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ ğŸ’° ğŸ€„ `Python`  | æ”¯æŒä¸­è‹±æ–‡åŒè¯­è§†è§‰-æ–‡æœ¬å¯¹è¯çš„å¼€æºå¯å•†ç”¨å¤šæ¨¡æ€æ¨¡å‹ã€‚ |
| 2023-07-28 | [sd-webui-deoldify](https://github.com/SpenserCai/sd-webui-deoldify) | 289 | ğŸ–¼ï¸ ğŸ”Œ  | DeOldify for Stable Diffusion WebUIï¼šThis is an extension for StableDiffusion's AUTOMATIC1111 web-ui that allows colorize of old photos and old video. It is based on deoldify. |
| 2023-07-26 | [inanimate](https://github.com/rynmurdock/inanimate) | 36 | ğŸ–¼ï¸ ğŸ”Œ  | Generate images from an initial frame and text |
| 2023-07-24 | [sd-webui-faceswaplab](https://github.com/glucauze/sd-webui-faceswaplab) | 200 | ğŸ–¼ï¸ ğŸ”Œ  |  Extended faceswap extension for StableDiffusion web-ui with multiple faceswaps, inpainting, checkpoints, ....  |
| 2023-07-21 | [LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory) | 1424 | ğŸ”  ğŸ–¼ï¸ â›½ 1ï¸âƒ£ 2ï¸âƒ£ ğŸ”¨ `Python`  | An Open-source Toolkit for LLM Development |
| 2023-07-21 | [Subject-Diffusion](https://github.com/OPPO-Mente-Lab/Subject-Diffusion) | 157 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning |
| 2023-07-21 | [distill-sd](https://github.com/segmind/distill-sd) | 287 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Segmind Distilled diffusion |
| 2023-07-20 | [tiny-stable-diffusion](https://github.com/ThisisBillhe/tiny-stable-diffusion) | 93 | ğŸ”  ğŸ–¼ï¸ âœ‚ï¸  | Tiny optimized Stable-diffusion that can run on GPUs with just 1GB of VRAM. (Beta) |
| 2023-07-18 | [sd-webui-animatediff](https://github.com/continue-revolution/sd-webui-animatediff) | 423 | ğŸ–¼ï¸ ğŸ”Œ  | AnimateDiff for AUTOMATIC1111 Stable Diffusion WebUI |
| 2023-07-16 | [iKUNet](https://github.com/caopulan/iKUNet) | 138 | ğŸ–¼ï¸ ğŸ”¨  | è¿‘å¹´æ¥ï¼Œç”±äºæ˜æ˜Ÿã€ä¼ä¸šé¢‘ç¹å¡Œæˆ¿ï¼Œè¡ç”Ÿå‡ºä¸€ä¸ªæ–°çš„éœ€æ±‚ï¼Œå³ç§»é™¤æƒ…èŠ‚ä¸­çš„æŸä¸ªå…ƒç´ ï¼Œå¦‚æŸä¸ªæ˜æ˜Ÿæˆ–æŸä¸ªèµåŠ©å•†ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªä»»åŠ¡å‘½åä¸ºğŸ¥å…ƒç´ ç§»é™¤ã€‚  |
| 2023-07-16 | [bubogpt](https://github.com/magic-research/bubogpt) | 352 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-15 | [SEED](https://github.com/AILab-CVC/SEED) | 148 | ğŸ–¼ï¸ ğŸšŒ  | Empowers LLMs with the ability to see and draw. |
| 2023-07-15 | [ViLT-GPT](https://github.com/CodeAlchemyAI/ViLT-GPT) | 114 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | By integrating OpenAI's Language Models (LLM) and LangChain with Vision-and-Language models, this app can answer queries based on the content of images.  |
| 2023-07-15 | [emmmbedding](https://github.com/RimoChan/emmmbedding) | 140 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | ã€emmmbeddingã€‘ä¸ç”¨å­˜å‚¨çš„å›¾åºŠï¼ |
| 2023-07-14 | [OnnxStream](https://github.com/vitoplantamura/OnnxStream) | 717 | ğŸ–¼ï¸ ğŸ’¡  | Running Stable Diffusion on a RPI Zero 2 (or in 260MB of RAM) |
| 2023-07-13 | [Full-Stack-AI-Meme-Generator](https://github.com/ThioJoe/Full-Stack-AI-Meme-Generator) | 207 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | Uses Various AI Service APIs to generate memes with text and images |
| 2023-07-13 | [lynx-llm](https://github.com/bytedance/lynx-llm) | 172 | ğŸ”  ğŸ–¼ï¸ 2ï¸âƒ£ â“  | paper: https://arxiv.org/abs/2307.02469 page: https://lynx-llm.github.io/ |
| 2023-07-12 | [SeargeSDXL](https://github.com/SeargeDP/SeargeSDXL) | 319 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Custom nodes and workflows for SDXL in ComfyUI |
| 2023-07-12 | [SD-inference](https://github.com/yangyuke001/SD-inference) | 180 | ğŸ”  ğŸ–¼ï¸ ğŸ’¡  | Stable Diffusion inference |
| 2023-07-11 | [Emu](https://github.com/baaivision/Emu) | 499 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | Emu: An Open Multimodal Generalist |
| 2023-07-08 | [DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 589 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Official code for DragDiffusion |
| 2023-07-07 | [asistente-virtual](https://github.com/ringa-tech/asistente-virtual) | 128 | ğŸ”  ğŸ–¼ï¸ ğŸš•  | An attempt to extend PULSE to a biomedical multimodal conversational assistant. |
| 2023-07-06 | [sdxl-colab](https://github.com/camenduru/sdxl-colab) | 260 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  |  |
| 2023-07-06 | [GPT4RoI](https://github.com/jshilong/GPT4RoI) | 310 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [fabric](https://github.com/sd-fabric/fabric) | 253 | ğŸ–¼ï¸ ğŸ”¨ `Python`  |  |
| 2023-07-04 | [StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 439 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-07-02 | [sd-webui-qrcode-toolkit](https://github.com/antfu/sd-webui-qrcode-toolkit) | 470 | ğŸ–¼ï¸ ğŸ”Œ  | Anthony's QR Toolkit for Stable Diffusion WebUI |
| 2023-07-01 | [stable-diffusion-xl-demo](https://github.com/TonyLianLong/stable-diffusion-xl-demo) | 184 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | A gradio web UI demo for Stable Diffusion XL 1.0, with refiner and MultiGPU support |
| 2023-06-30 | [VisCPM](https://github.com/OpenBMB/VisCPM) | 781 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ€„  | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-30 | [sd-webui-3d-editor](https://github.com/jtydhr88/sd-webui-3d-editor) | 91 | ğŸ–¼ï¸ ğŸ”Œ  | A custom extension for sd-webui that with 3D modeling features (add/edit basic elements, load your custom model, modify scene and so on), then send screenshot to txt2img or img2img as your ControlNet's reference image, basing on ThreeJS editor |
| 2023-06-28 | [One-2-3-45](https://github.com/One-2-3-45/One-2-3-45) | 826 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | official code of "One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization" |
| 2023-06-27 | [LLaVAR](https://github.com/SALT-NLP/LLaVAR) | 126 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Code/Data for the paper: "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding" |
| 2023-06-27 | [app.enfugue.ai](https://github.com/painebenjamin/app.enfugue.ai) | 185 | ğŸ–¼ï¸ ğŸ”¨ `JavaScript`  | ENFUGUE is a feature-rich self-hosted Stable Diffusion webapp |
| 2023-06-26 | [qrcode-toolkit](https://github.com/antfu/qrcode-toolkit) | 865 | ğŸ–¼ï¸ ğŸ”Œ  | Anthony's QR Code Toolkit for AI generated QR Codes |
| 2023-06-26 | [CloneCleaner](https://github.com/artyfacialintelagent/CloneCleaner) | 71 | ğŸ–¼ï¸ ğŸ”Œ  | An extension for Automatic1111 to work around Stable Diffusion's "clone problem". It automatically modifies your prompts with random names, nationalities, hair style and hair color to create more variations in generated people. |
| 2023-06-22 | [generative-models](https://github.com/Stability-AI/generative-models) | 8809 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Generative Models by Stability AI |
| 2023-06-17 | [FableForge](https://github.com/e-johnstonn/FableForge) | 308 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | Generate a picture book from a single prompt using OpenAI function calling, replicate, and Deep Lake |
| 2023-06-17 | [sd-webui-roop](https://github.com/s0md3v/sd-webui-roop) | 2202 | ğŸ–¼ï¸ ğŸ”Œ  | roop extension for StableDiffusion web-ui |
| 2023-06-14 | [UnrealOpenAIPlugin](https://github.com/life-exe/UnrealOpenAIPlugin) | 73 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `C++`  | This plugin is a comprehensive Unreal Engine wrapper for the OpenAI API. |
| 2023-06-13 | [PanoHead](https://github.com/SizheAn/PanoHead) | 1454 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-06 | [autodistill](https://github.com/autodistill/autodistill) | 587 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Images to inference with no labeling (use foundation models to train supervised models) |
| 2023-06-05 | [ChatGPT-Midjourney](https://github.com/Licoy/ChatGPT-Midjourney) | 4560 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  | ğŸ­ ä¸€é”®æ‹¥æœ‰ä½ è‡ªå·±çš„ ChatGPT+Midjourney ç½‘é¡µæœåŠ¡ \| Own your own ChatGPT+Midjourney web service with one click |
| 2023-06-05 | [FantasyCopilot](https://github.com/Richasy/FantasyCopilot) | 359 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `C#`  | A new-age AI desktop tool |
| 2023-06-04 | [axodox-machinelearning](https://github.com/axodox/axodox-machinelearning) | 525 | ğŸ–¼ï¸ ğŸ’¡  | This repository contains a C++ ONNX implementation of StableDiffusion. |
| 2023-05-29 | [StyleAvatar3D](https://github.com/icoz69/StyleAvatar3D) | 458 | ğŸ–¼ï¸ ğŸ“ ğŸ§Š  | Official repo for StyleAvatar3D |
| 2023-05-23 | [Uni-ControlNet](https://github.com/ShihaoZhaoZSH/Uni-ControlNet) | 390 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Uni-ControlNet is a novel controllable diffusion model that allows for the simultaneous utilization of different local controls and global controls in a flexible and composable manner within one model. |
| 2023-05-23 | [XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 558 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | ğŸ©º é¦–ä¸ªä¼šçœ‹èƒ¸éƒ¨Xå…‰ç‰‡çš„ä¸­æ–‡å¤šæ¨¡æ€åŒ»å­¦å¤§æ¨¡å‹ \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1144 | ğŸ”  ğŸ–¼ï¸ ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-20 | [DragGAN](https://github.com/OpenGVLab/DragGAN) | 4838 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Unofficial Implementation of DragGAN - "Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold" ï¼ˆDragGAN å…¨åŠŸèƒ½å®ç°ï¼Œåœ¨çº¿Demoï¼Œæœ¬åœ°éƒ¨ç½²è¯•ç”¨ï¼Œä»£ç ã€æ¨¡å‹å·²å…¨éƒ¨å¼€æºï¼Œæ”¯æŒWindows, macOS, Linuxï¼‰ |
| 2023-05-20 | [sd-webui-stablesr](https://github.com/pkuliyi2015/sd-webui-stablesr) | 683 | ğŸ–¼ï¸ ğŸ”Œ  | StableSR for Stable Diffusion WebUI - Ultra High-quality Image Upscaler |
| 2023-05-19 | [Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | 593 | ğŸ–¼ï¸ ğŸšŒ  | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-18 | [ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 577 | ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 436 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [ProFusion](https://github.com/drboog/ProFusion) | 418 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Code for Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach |
| 2023-05-18 | [XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | 340 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸš• 2ï¸âƒ£  | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-18 | [UniControl](https://github.com/salesforce/UniControl) | 481 | ğŸ–¼ï¸ ğŸšŒ  | Unified Controllable Visual Generation Model |
| 2023-05-18 | [PandaGPT](https://github.com/yxuansu/PandaGPT) | 592 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 460 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-17 | [awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | 266 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | A curated list of awesome AI tools for game developers |
| 2023-05-13 | [chatgptWithMidjourney](https://github.com/Zo3i/chatgptWithMidjourney) | 397 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  |  |
| 2023-05-12 | [StableSwarmUI](https://github.com/Stability-AI/StableSwarmUI) | 942 | ğŸ–¼ï¸ ğŸ”¨ `C#`  | StableSwarmUI, A Modular Stable Diffusion Web-User-Interface, with an emphasis on making powertools easily accessible, high performance, and extensibility. |
| 2023-05-11 | [OpenDAN-Personal-AI-OS](https://github.com/fiatrete/OpenDAN-Personal-AI-OS) | 1250 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | OpenDAN is an open source Personal AI OS , which consolidates various AI modules in one place for your personal use. |
| 2023-05-08 | [sd-webui-prompt-all-in-one](https://github.com/Physton/sd-webui-prompt-all-in-one) | 1515 | ğŸ–¼ï¸ ğŸ”Œ  | This is an extension based on sd-webui, aimed at improving the user experience of the prompt/negative prompt input box. It has a more intuitive and powerful input interface function, and provides automatic translation, history record, and bookmarking functions.    è¿™æ˜¯ä¸€ä¸ªåŸºäº sd-webui çš„æ‰©å±•ï¼Œæ—¨åœ¨æé«˜æç¤ºè¯/åå‘æç¤ºè¯è¾“å…¥æ¡†çš„ä½¿ç”¨ä½“éªŒã€‚å®ƒæ‹¥æœ‰æ›´ç›´è§‚ã€å¼ºå¤§çš„è¾“å…¥ç•Œé¢åŠŸèƒ½ï¼Œå®ƒæä¾›äº†è‡ªåŠ¨ç¿»è¯‘ã€å†å²è®°å½•å’Œæ”¶è—ç­‰åŠŸèƒ½ã€‚ |
| 2023-05-06 | [sd-webui-photopea-embed](https://github.com/yankooliveira/sd-webui-photopea-embed) | 633 | ğŸ–¼ï¸ ğŸ”Œ  | A simple Stable Diffusion WebUI extension that adds a Photopea tab and integration. |
| 2023-05-04 | [lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2520 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1169 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-02 | [docta](https://github.com/Docta-ai/docta) | 1392 | ğŸ”  ğŸ–¼ï¸ â›½  | A Doctor for your data |
| 2023-05-01 | [Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion) | 901 | ğŸ–¼ï¸ ğŸ“  | Stable Diffusion, SDXL, LoRA Training, DreamBooth Training, Automatic1111 Web UI, DeepFake, Deep Fakes, TTS, Animation, Text To Video, Tutorials, Guides, Lectures, Courses, ComfyUI, Google Colab, RunPod, NoteBooks, ControlNet, TTS, Voice Cloning, AI, AI News, ML, ML News, News, Tech, Tech News, Kohya LoRA, Kandinsky 2, DeepFloyd IF, Midjourney |
| 2023-04-29 | [Discord-AI-Chatbot](https://github.com/mishalhossin/Discord-AI-Chatbot) | 1043 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | This Discord chatbot is incredibly versatile, offering a wide range of customization options.  |
| 2023-04-28 | [datacomp](https://github.com/mlfoundations/datacomp) | 386 | ğŸ”  ğŸ–¼ï¸ â›½  | DataComp: In search of the next generation of multimodal datasets |
| 2023-04-27 | [Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 274 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [adetailer](https://github.com/Bing-su/adetailer) | 2036 | ğŸ–¼ï¸ ğŸ”Œ  | Auto detecting, masking and inpainting with detection model. |
| 2023-04-26 | [diffusion](https://github.com/mosaicml/diffusion) | 445 | ğŸ–¼ï¸ 2ï¸âƒ£  | This repo contains code used to train your own Stable Diffusion model on your own data. |
| 2023-04-26 | [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1181 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | Multimodal-GPT |
| 2023-04-26 | [UnpromptedControl](https://github.com/vijishmadhavan/UnpromptedControl) | 354 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Remove unwanted objects and restore images without prompts, powered by ControlNet. |
| 2023-04-25 | [mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1370 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [midjourney-api](https://github.com/erictik/midjourney-api) | 1075 | ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  | MidJourney client. Unofficial Node.js client |
| 2023-04-24 | [midjourney-proxy](https://github.com/novicezk/midjourney-proxy) | 2749 | ğŸ–¼ï¸ ğŸ”¨ `Java`  | ä»£ç† MidJourney çš„discordé¢‘é“ï¼Œå®ç°apiå½¢å¼è°ƒç”¨AIç»˜å›¾ |
| 2023-04-24 | [StableHoudini](https://github.com/stassius/StableHoudini) | 309 | ğŸ–¼ï¸ ğŸ”Œ  | Stable Diffusion Houdini Toolset |
| 2023-04-23 | [GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 574 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3274 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-22 | [ChatGLM-6B-Engineering](https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering) | 535 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | ChatGLM-6B Prompt Engineering Project |
| 2023-04-20 | [StableDiffusion-CheatSheet](https://github.com/SupaGruen/StableDiffusion-CheatSheet) | 1351 | ğŸ–¼ï¸ ğŸ“  | A list of StableDiffusion styles and some notes for offline use. Pure HTML, CSS and a bit of JS. |
| 2023-04-19 | [MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 751 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-19 | [chameleon-llm](https://github.com/lupantech/chameleon-llm) | 867 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Codes for "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models". |
| 2023-04-17 | [LLaVA](https://github.com/haotian-liu/LLaVA) | 4775 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-17 | [SdPaint](https://github.com/houseofsecrets/SdPaint) | 1522 | ğŸ–¼ï¸ ğŸ”Œ  | Stable Diffusion Painting |
| 2023-04-15 | [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22238 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-13 | [Anything-3D](https://github.com/Anything-of-anything/Anything-3D) | 1292 | ğŸ–¼ï¸ ğŸ”¨ ğŸ§Š `Python`  | Segment-Anything + 3D. Let's lift anything to 3D. |
| 2023-04-12 | [TemporalKit](https://github.com/CiaraStrawberry/TemporalKit) | 1460 | ğŸ–¼ï¸ ğŸ”Œ  | An all in one solution for adding Temporal Stability to a Stable Diffusion Render via an automatic1111 extension |
| 2023-04-12 | [Image2Paragraph](https://github.com/showlab/Image2Paragraph) | 694 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | [A toolbox for fun.] Transform Image into Unique Paragraph with ChatGPT, BLIP2, OFA, GRIT, Segment Anything, ControlNet. |
| 2023-04-10 | [sd-webui-segment-anything](https://github.com/continue-revolution/sd-webui-segment-anything) | 2426 | ğŸ–¼ï¸ ğŸ”Œ  | Segment Anything for Stable Diffusion WebUI |
| 2023-04-09 | [a1111-sd-webui-lycoris](https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris) | 747 | ğŸ–¼ï¸ ğŸ”Œ  | An extension for stable-diffusion-webui to load lycoris models.  |
| 2023-04-09 | [Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 3991 | ğŸ–¼ï¸ ğŸ¥ ğŸšŒ ğŸ§Š  | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-09 | [EditAnything](https://github.com/sail-sg/EditAnything) | 2549 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Edit anything in images  powered by segment-anything, ControlNet, StableDiffusion, etc. |
| 2023-04-08 | [OpenAGI](https://github.com/agiresearch/OpenAGI) | 1350 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | OpenAGI: When LLM Meets Domain Experts |
| 2023-04-07 | [Caption-Anything](https://github.com/ttengwang/Caption-Anything) | 1370 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | Caption-Anything is a versatile tool combining image segmentation, visual captioning, and ChatGPT, generating tailored captions with diverse controls for user preferences. https://huggingface.co/spaces/TencentARC/Caption-Anything https://huggingface.co/spaces/VIPLab/Caption-Anything |
| 2023-04-06 | [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) | 10575 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Grounded-SAM: Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything |
| 2023-04-06 | [threestudio](https://github.com/threestudio-project/threestudio) | 2545 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | A unified framework for 3D content generation. |
| 2023-04-04 | [carefree-drawboard](https://github.com/carefree0910/carefree-drawboard) | 910 | ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  | ğŸ¨ Infinite Drawboard in Python |
| 2023-04-04 | [docker-prompt-generator](https://github.com/soulteary/docker-prompt-generator) | 1032 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | Using a Model to generate prompts for Model applications. / ä½¿ç”¨æ¨¡å‹æ¥ç”Ÿæˆä½œå›¾å’’è¯­çš„å·æ‡’å·¥å…·ï¼Œæ”¯æŒ MidJourneyã€Stable Diffusion ç­‰ã€‚ |
| 2023-04-01 | [Otter](https://github.com/Luodian/Otter) | 2316 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-04-01 | [ImageReward](https://github.com/THUDM/ImageReward) | 603 | ğŸ”  ğŸ–¼ï¸ 3ï¸âƒ£ ğŸ”Œ  | ImageReward: Learning and Evaluating Human Preferences for Text-to-image Generation |
| 2023-03-30 | [JARVIS](https://github.com/microsoft/JARVIS) | 21684 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf |
| 2023-03-28 | [tomesd](https://github.com/dbolya/tomesd) | 1020 | ğŸ–¼ï¸ ğŸ”Œ  | Speed up Stable Diffusion with this one simple trick! |
| 2023-03-26 | [visual-openllm](https://github.com/visual-openllm/visual-openllm) | 1119 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | something like visual-chatgpt, æ–‡å¿ƒä¸€è¨€çš„å¼€æºç‰ˆ |
| 2023-03-23 | [Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1309 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-21 | [text2room](https://github.com/lukasHoel/text2room) | 837 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models (ICCV2023). |
| 2023-03-19 | [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4705 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [sd-webui-regional-prompter](https://github.com/hako-mikan/sd-webui-regional-prompter) | 839 | ğŸ–¼ï¸ ğŸ”Œ  | set prompt to divided region |
| 2023-03-19 | [sd-webui-text2video](https://github.com/kabachuha/sd-webui-text2video) | 1061 | ğŸ–¼ï¸ ğŸ¥ ğŸ”Œ  | Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies |
| 2023-03-18 | [LocalAI](https://github.com/go-skynet/LocalAI) | 10342 | ğŸ”  ğŸ–¼ï¸ ğŸ’¡  | :robot: Self-hosted, community-driven, local OpenAI compatible API. Drop-in replacement for OpenAI running LLMs on consumer-grade hardware. Free Open Source OpenAI alternative. No GPU required. Runs ggml, gguf, GPTQ, onnx, TF compatible models: llama, llama2, gpt4all, rwkv, whisper, vicuna, koala, cerebras, falcon, dolly, starcoder, and many others |
| 2023-03-17 | [zero123](https://github.com/cvlab-columbia/zero123) | 1698 | ğŸ–¼ï¸ 2ï¸âƒ£ ğŸ§Š  | Zero-1-to-3: Zero-shot One Image to 3D Object (ICCV 2023) |
| 2023-03-17 | [SD-CN-Animation](https://github.com/volotat/SD-CN-Animation) | 690 | ğŸ–¼ï¸ ğŸ”Œ  | This script allows to automate video stylization task using StableDiffusion and ControlNet. |
| 2023-03-16 | [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) | 147395 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | An experimental open-source attempt to make GPT-4 fully autonomous. |
| 2023-03-15 | [MM-REACT](https://github.com/microsoft/MM-REACT) | 768 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ ğŸ”¨ `Python`  | Official repo for MM-REACT |
| 2023-03-14 | [ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | 3359 | ğŸ–¼ï¸ ğŸšŒ  | Nightly release of ControlNet 1.1 |
| 2023-03-13 | [3DFuse](https://github.com/KU-CVLAB/3DFuse) | 643 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-11 | [sd-webui-cutoff](https://github.com/hnmr293/sd-webui-cutoff) | 964 | ğŸ–¼ï¸ ğŸ”Œ  | Cutoff - Cutting Off Prompt Effect |
| 2023-03-10 | [unidiffuser](https://github.com/thu-ml/unidiffuser) | 1065 | ğŸ–¼ï¸ ğŸšŒ  | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2930 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Official implementation of the paper "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-06 | [web-stable-diffusion](https://github.com/mlc-ai/web-stable-diffusion) | 3049 | ğŸ–¼ï¸ ğŸ’¡  | Bringing stable diffusion models to web browsers. Everything runs inside the browser with no server support.  |
| 2023-03-02 | [sd-webui-depth-lib](https://github.com/jexom/sd-webui-depth-lib) | 1222 | ğŸ–¼ï¸ ğŸ”Œ  | Depth map library for use with the Control Net extension for Automatic1111/stable-diffusion-webui |
| 2023-03-02 | [TaskMatrix](https://github.com/microsoft/TaskMatrix) | 33963 | ğŸ”  ğŸ–¼ï¸ ğŸ”¨ `Python`  | TaskMatrix connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting. |
| 2023-03-01 | [Word-As-Image](https://github.com/Shiriluz/Word-As-Image) | 993 | ğŸ–¼ï¸ ğŸ”¨ `Python`  |  |
| 2023-02-27 | [LyCORIS](https://github.com/KohakuBlueleaf/LyCORIS) | 1385 | ğŸ–¼ï¸ ğŸ“  | Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion. |
| 2023-02-27 | [sd-webui-mov2mov](https://github.com/Scholar01/sd-webui-mov2mov) | 1455 | ğŸ–¼ï¸ ğŸ”Œ  | é€‚ç”¨äºAutomatic1111/stable-diffusion-webui çš„ Mov2mov æ’ä»¶ã€‚ |
| 2023-02-27 | [multidiffusion-upscaler-for-automatic1111](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111) | 3436 | ğŸ–¼ï¸ ğŸ”Œ  | Tiled Diffusion and VAE optimize, licensed under CC BY-NC-SA 4.0 |
| 2023-02-26 | [consistency_models](https://github.com/openai/consistency_models) | 5389 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Official repo for consistency models. |
| 2023-02-25 | [sd-webui-llul](https://github.com/hnmr293/sd-webui-llul) | 673 | ğŸ–¼ï¸ ğŸ”Œ  | LLuL - Local Latent upscaLer |
| 2023-02-23 | [Blender-ControlNet](https://github.com/coolzilj/Blender-ControlNet) | 686 | ğŸ–¼ï¸ ğŸ”Œ  | Using ControlNet right in Blender. |
| 2023-02-23 | [chilloutai](https://github.com/kale5195/chilloutai) | 757 | ğŸ–¼ï¸ ğŸ“  | AI å›¾ç‰‡ç”Ÿæˆ |
| 2023-02-21 | [roomGPT](https://github.com/Nutlope/roomGPT) | 8291 | ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  | Upload a photo of your room to generate your dream room with AI. |
| 2023-02-19 | [understand-prompt](https://github.com/prompt-engineering/understand-prompt) | 3349 | ğŸ”  ğŸ–¼ï¸ ğŸ“  | ã€ğŸ”ğŸ”ğŸ” å†…å«ä¸é€‚åˆæœªæˆå¹´äººé˜…è¯»çš„å›¾ç‰‡ã€‘åŸºäºæˆ‘æ“…é•¿çš„ç¼–ç¨‹ã€ç»˜ç”»ã€å†™ä½œå±•å¼€çš„ AI æ¢ç´¢å’Œæ€»ç»“ï¼šStableDiffusion æ˜¯ä¸€ç§å¼ºå¤§çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿé€šè¿‡å¯¹ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ¼”åŒ–æ¥ç”Ÿæˆæ–°çš„å›¾ç‰‡ã€‚ChatGPT æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„è¯­è¨€ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨ä¸ºè¾“å…¥çš„ä¸»é¢˜ç”Ÿæˆåˆé€‚çš„æ–‡ç« ã€‚è€Œ Github Copilot æ˜¯ä¸€ä¸ªæ™ºèƒ½ç¼–ç¨‹åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŠ é€Ÿæ—¥å¸¸ç¼–ç¨‹æ´»åŠ¨ã€‚ |
| 2023-02-15 | [T2I-Adapter](https://github.com/TencentARC/T2I-Adapter) | 2274 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | T2I-Adapter |
| 2023-02-13 | [scribble-diffusion](https://github.com/replicate/scribble-diffusion) | 2592 | ğŸ–¼ï¸ ğŸ”¨ `JavaScript`  | Turn your rough sketch into a refined image using AI |
| 2023-02-12 | [sd-webui-controlnet](https://github.com/Mikubill/sd-webui-controlnet) | 12294 | ğŸ–¼ï¸ ğŸ”Œ  | WebUI extension for ControlNet |
| 2023-02-01 | [ControlNet](https://github.com/lllyasviel/ControlNet) | 22992 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Let us control diffusion models! |
| 2023-01-20 | [IF](https://github.com/deep-floyd/IF) | 7039 | ğŸ–¼ï¸ ğŸšŒ  |  |
| 2023-01-17 | [ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 11308 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | A powerful and modular stable diffusion GUI with a graph/nodes interface. |
| 2023-01-09 | [instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 5145 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2023-01-08 | [ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | 4657 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | ğŸ”¥Highlighting the top ML papers every week. |
| 2022-12-20 | [Auto-Photoshop-StableDiffusion-Plugin](https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin) | 5001 | ğŸ–¼ï¸ ğŸ”Œ  | A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.  |
| 2022-12-15 | [MochiDiffusion](https://github.com/godly-devotion/MochiDiffusion) | 6295 | ğŸ–¼ï¸ ğŸ”¨ `Swift`  | Run Stable Diffusion on Mac natively |
| 2022-12-08 | [lora](https://github.com/cloneofsimo/lora) | 5602 | ğŸ–¼ï¸ 2ï¸âƒ£  | Using Low-rank adaptation to quickly fine-tune diffusion models. |
| 2022-12-06 | [point-e](https://github.com/openai/point-e) | 5781 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Point cloud diffusion for 3D model synthesis |
| 2022-12-05 | [photoshot](https://github.com/shinework/photoshot) | 2341 | ğŸ–¼ï¸ ğŸ”¨ `TypeScript`  | An open-source AI avatar generator web app - https://photoshot.app |
| 2022-11-25 | [riffusion](https://github.com/riffusion/riffusion) | 2465 | ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | Stable diffusion for real-time music generation |
| 2022-11-23 | [SadTalker](https://github.com/OpenTalker/SadTalker) | 6290 | ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-23 | [stablediffusion](https://github.com/Stability-AI/stablediffusion) | 29239 | ğŸ–¼ï¸ â›½ ğŸšŒ  | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-11-20 | [riffusion-app](https://github.com/riffusion/riffusion-app) | 2422 | ğŸ–¼ï¸ ğŸµ ğŸ”¨ `TypeScript`  | Stable diffusion for real-time music generation (web app) |
| 2022-11-16 | [ml-stable-diffusion](https://github.com/apple/ml-stable-diffusion) | 14314 | ğŸ–¼ï¸ ğŸ’¡  | Stable Diffusion with Core ML on Apple Silicon |
| 2022-10-30 | [kohya_ss](https://github.com/bmaltais/kohya_ss) | 5440 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | This repository provides a Windows-focused Gradio GUI for Kohya's Stable Diffusion trainers. The GUI allows you to set the training parameters and generate and run the required CLI commands to train the model. |
| 2022-10-20 | [open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2799 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | An open-source framework for training large multimodal models. |
| 2022-10-18 | [stable-diffusion](https://github.com/runwayml/stable-diffusion) | 2928 | ğŸ–¼ï¸ ğŸšŒ  | Latent Text-to-Image Diffusion |
| 2022-10-14 | [Kandinsky-2](https://github.com/ai-forever/Kandinsky-2) | 2347 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Kandinsky 2 â€” multilingual text2image latent diffusion model |
| 2022-10-14 | [sd-webui-deforum](https://github.com/deforum-art/sd-webui-deforum) | 2032 | ğŸ–¼ï¸ ğŸ”Œ  | Deforum extension for AUTOMATIC1111's Stable Diffusion webui |
| 2022-10-13 | [diffusion-models-class](https://github.com/huggingface/diffusion-models-class) | 2549 | ğŸ–¼ï¸ ğŸ“  | Materials for the Hugging Face Diffusion Models Course |
| 2022-10-11 | [civitai](https://github.com/civitai/civitai) | 4465 | ğŸ–¼ï¸ ğŸ”Œ  | A repository of models, textual inversions, and more |
| 2022-10-10 | [stable-diffusion-webui-chinese](https://github.com/VinsonLaro/stable-diffusion-webui-chinese) | 2022 | ğŸ–¼ï¸ ğŸ”Œ  | stable-diffusion-webui çš„æ±‰åŒ–æ‰©å±• |
| 2022-10-08 | [awesome-ai-painting](https://github.com/hua1995116/awesome-ai-painting) | 9376 | ğŸ–¼ï¸ ğŸ“  | AIç»˜ç”»èµ„æ–™åˆé›†ï¼ˆåŒ…å«å›½å†…å¤–å¯ä½¿ç”¨å¹³å°ã€ä½¿ç”¨æ•™ç¨‹ã€å‚æ•°æ•™ç¨‹ã€éƒ¨ç½²æ•™ç¨‹ã€ä¸šç•Œæ–°é—»ç­‰ç­‰ï¼‰ stable diffusion tutorialã€disco diffusion tutorialã€ AI Platform |
| 2022-10-06 | [stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | 6634 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-10-05 | [stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab) | 13498 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | stable diffusion webui colab |
| 2022-10-03 | [prompt-to-prompt](https://github.com/google/prompt-to-prompt) | 2313 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Null-text inversion enables intuitive text-based editing of real images with the Stable Diffusion model. |
| 2022-09-21 | [fast-stable-diffusion](https://github.com/TheLastBen/fast-stable-diffusion) | 6492 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | fast-stable-diffusion + DreamBooth |
| 2022-09-17 | [Dreambooth-Stable-Diffusion](https://github.com/JoePenna/Dreambooth-Stable-Diffusion) | 3030 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) by way of Textual Inversion (https://arxiv.org/abs/2208.01618) for Stable Diffusion (https://arxiv.org/abs/2112.10752). Tweaks focused on training faces, objects, and styles. |
| 2022-09-13 | [carefree-creator](https://github.com/carefree0910/carefree-creator) | 2054 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | AI magics meet Infinite draw board. |
| 2022-09-12 | [imaginAIry](https://github.com/brycedrennan/imaginAIry) | 7293 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | AI imagined images. Pythonic generation of images. |
| 2022-09-08 | [dream-textures](https://github.com/carson-katri/dream-textures) | 6994 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Stable Diffusion built-in to Blender |
| 2022-09-06 | [Dreambooth-Stable-Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) | 6936 | ğŸ–¼ï¸ 2ï¸âƒ£  | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion |
| 2022-09-06 | [diffusionbee-stable-diffusion-ui](https://github.com/divamgupta/diffusionbee-stable-diffusion-ui) | 10791 | ğŸ–¼ï¸ ğŸ”¨ `JavaScript`  | Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed. |
| 2022-09-04 | [ai-notes](https://github.com/swyxio/ai-notes) | 3696 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
| 2022-09-02 | [stablediffusion-infinity](https://github.com/lkwq007/stablediffusion-infinity) | 3582 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Outpainting with Stable Diffusion on an infinite canvas |
| 2022-08-27 | [stable-diffusion-webui-docker](https://github.com/AbdBarho/stable-diffusion-webui-docker) | 4566 | ğŸ–¼ï¸ ğŸ”¨ `Dockerfile`  | Easy Docker setup for Stable Diffusion with user-friendly UI |
| 2022-08-24 | [sygil-webui](https://github.com/Sygil-Dev/sygil-webui) | 7589 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Stable Diffusion web UI |
| 2022-08-24 | [LAVIS](https://github.com/salesforce/LAVIS) | 6457 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-23 | [easydiffusion](https://github.com/easydiffusion/easydiffusion) | 7533 | ğŸ–¼ï¸ ğŸ”¨ `JavaScript`  | Easiest 1-click way to create beautiful artwork on your PC using AI, with no tech knowledge. Provides a browser UI for generating images from text prompts and images. Just enter your text prompt, and see the generated image. |
| 2022-08-22 | [stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) | 99095 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | Stable Diffusion web UI |
| 2022-08-22 | [stability-sdk](https://github.com/Stability-AI/stability-sdk) | 2330 | ğŸ–¼ï¸ ğŸ”¨ `Jupyter`  | SDK for interacting with stability.ai APIs (e.g. stable diffusion inference) |
| 2022-08-17 | [InvokeAI](https://github.com/invoke-ai/InvokeAI) | 18422 | ğŸ–¼ï¸ ğŸ”Œ  | InvokeAI is a leading creative engine for Stable Diffusion models, empowering professionals, artists, and enthusiasts to generate and create visual media using the latest AI-driven technologies. The solution offers an industry leading WebUI, supports terminal use through a CLI, and serves as the foundation for multiple commercial products. |
| 2022-08-10 | [stable-diffusion](https://github.com/CompVis/stable-diffusion) | 59435 | ğŸ–¼ï¸ â›½ ğŸšŒ  | A latent text-to-image diffusion model |
| 2022-08-02 | [textual_inversion](https://github.com/rinongal/textual_inversion) | 2566 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  |  |
| 2022-07-25 | [modelscope](https://github.com/modelscope/modelscope) | 3772 | ğŸ”  ğŸ–¼ï¸ ğŸµ 2ï¸âƒ£  | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-07-15 | [AITemplate](https://github.com/facebookincubator/AITemplate) | 4192 | ğŸ–¼ï¸ ğŸ’¡  | AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference. |
| 2022-07-03 | [MidJourney-Styles-and-Keywords-Reference](https://github.com/willwulfken/MidJourney-Styles-and-Keywords-Reference) | 10680 | ğŸ–¼ï¸ ğŸ“  | A reference containing Styles and Keywords that you can use with MidJourney AI. There are also pages showing resolution comparison, image weights, and much more! |
| 2022-06-30 | [discoart](https://github.com/jina-ai/discoart) | 3825 | ğŸ–¼ï¸ ğŸ”¨ `Python`  | ğŸª© Create Disco Diffusion artworks in one line |
| 2022-05-30 | [diffusers](https://github.com/huggingface/diffusers) | 17495 | ğŸ–¼ï¸ ğŸµ 2ï¸âƒ£ ğŸ“  | ğŸ¤— Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
