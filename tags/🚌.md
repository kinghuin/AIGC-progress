| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-08-29 | [AnomalyGPT](https://github.com/CASIA-IVA-Lab/AnomalyGPT) | 65 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  |  |
| 2023-08-29 | [CoVR](https://github.com/lucas-ventura/CoVR) | 23 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | Official PyTorch implementation of the paper "CoVR: Learning Composed Video Retrieval from Web Video Captions". |
| 2023-08-28 | [DiffBIR](https://github.com/XPixelGroup/DiffBIR) | 24 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  |  |
| 2023-08-23 | [Lemur](https://github.com/OpenLemur/Lemur) | 164 | ğŸ”  ğŸšŒ  | Lemur: The State-of-the-art Open Pretrained Large Language Models Balancing Text and Code Capabilities |
| 2023-08-22 | [IT3D-text-to-3D](https://github.com/buaacyw/IT3D-text-to-3D) | 128 | ğŸšŒ ğŸ§Š  |  |
| 2023-08-21 | [Qwen-VL](https://github.com/QwenLM/Qwen-VL) | 833 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | The official repo of Qwen-VL (é€šä¹‰åƒé—®-VL) chat & pretrained large vision language model proposed by Alibaba Cloud. |
| 2023-08-18 | [meru](https://github.com/facebookresearch/meru) | 70 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Code for the paper "Hyperbolic Image-Text Representations", Desai et al, ICML 2023 |
| 2023-08-16 | [KwaiYii](https://github.com/kwai/KwaiYii) | 155 | ğŸ”  ğŸšŒ  | ã€Œå¿«æ„ã€å¤§æ¨¡å‹ï¼ˆKwaiYiiï¼‰ æ˜¯ç”±å¿«æ‰‹AIå›¢é˜Ÿä»é›¶åˆ°ä¸€ç‹¬ç«‹è‡ªä¸»ç ”å‘çš„ä¸€ç³»åˆ—å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ |
| 2023-08-16 | [IP-Adapter](https://github.com/tencent-ailab/IP-Adapter) | 451 | ğŸ–¼ï¸ ğŸšŒ  | The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.  |
| 2023-08-15 | [CoDeF](https://github.com/qiuyu96/CoDeF) | 3581 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | Official PyTorch implementation of CoDeF: Content Deformation Fields for Temporally Consistent Video Processing |
| 2023-08-10 | [Taiwan-LLaMa](https://github.com/MiuLab/Taiwan-LLaMa) | 513 | ğŸ”  â›½ ğŸšŒ ğŸ€„  | Traditional Mandarin LLMs for Taiwan |
| 2023-08-08 | [OpenMoE](https://github.com/XueFuzhao/OpenMoE) | 231 | ğŸ”  ğŸšŒ  | A family of open-sourced Mixture-of-Experts (MoE) Large Language Models |
| 2023-08-06 | [XVERSE-13B](https://github.com/xverse-ai/XVERSE-13B) | 454 | ğŸ”  ğŸšŒ ğŸ’° ğŸ€„  | XVERSE-13B: A multilingual large language model developed by XVERSE Technology Inc. |
| 2023-08-03 | [all-seeing](https://github.com/OpenGVLab/all-seeing) | 236 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | This is the official implementation of the paper "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World" |
| 2023-08-03 | [Qwen-7B](https://github.com/QwenLM/Qwen-7B) | 3643 | ğŸ”  ğŸšŒ  | The official repo of Qwen-7B (é€šä¹‰åƒé—®-7B) chat & pretrained large language model proposed by Alibaba Cloud. |
| 2023-08-01 | [LISA](https://github.com/dvlab-research/LISA) | 866 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | Project Page for "LISA: Reasoning Segmentation via Large Language Model" |
| 2023-07-31 | [LLaSM](https://github.com/LinkSoul-AI/LLaSM) | 145 | ğŸ”  ğŸµ ğŸšŒ ğŸ’° ğŸ€„  | ç¬¬ä¸€ä¸ªæ”¯æŒä¸­è‹±æ–‡åŒè¯­è¯­éŸ³-æ–‡æœ¬å¤šæ¨¡æ€å¯¹è¯çš„å¼€æºå¯å•†ç”¨å¯¹è¯æ¨¡å‹ã€‚ä¾¿æ·çš„è¯­éŸ³è¾“å…¥å°†å¤§å¹…æ”¹å–„ä»¥æ–‡æœ¬ä¸ºè¾“å…¥çš„å¤§æ¨¡å‹çš„ä½¿ç”¨ä½“éªŒï¼ŒåŒæ—¶é¿å…äº†åŸºäº ASR è§£å†³æ–¹æ¡ˆçš„ç¹çæµç¨‹ä»¥åŠå¯èƒ½å¼•å…¥çš„é”™è¯¯ã€‚ |
| 2023-07-29 | [VALL-E-X](https://github.com/Plachtaa/VALL-E-X) | 3180 | ğŸµ ğŸšŒ  | An open source implementation of Microsoft's VALL-E X zero-shot TTS model. Demo is available in https://plachtaa.github.io |
| 2023-07-26 | [DWPose](https://github.com/IDEA-Research/DWPose) | 1020 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | "Effective Whole-body Pose Estimation with Two-stages Distillation" (ICCV 2023, CV4Metaverse Workshop) |
| 2023-07-21 | [Subject-Diffusion](https://github.com/OPPO-Mente-Lab/Subject-Diffusion) | 158 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning |
| 2023-07-21 | [distill-sd](https://github.com/segmind/distill-sd) | 297 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Segmind Distilled diffusion |
| 2023-07-20 | [Chinese-Llama-2-7b](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b) | 1765 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ’° ğŸ€„  | å¼€æºç¤¾åŒºç¬¬ä¸€ä¸ªèƒ½ä¸‹è½½ã€èƒ½è¿è¡Œçš„ä¸­æ–‡ LLaMA2 æ¨¡å‹ï¼ |
| 2023-07-19 | [Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese) | 4631 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ’° ğŸ€„  | Llamaä¸­æ–‡ç¤¾åŒºï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨ |
| 2023-07-19 | [Chinese-LlaMA2](https://github.com/michael-wzhu/Chinese-LlaMA2) | 698 | ğŸ”  ğŸšŒ ğŸš• 1ï¸âƒ£ 2ï¸âƒ£ ğŸ’° ğŸ€„  | Repo for adapting Meta LlaMA2 in Chinese! METAæœ€æ–°å‘å¸ƒçš„LlaMA2çš„æ±‰åŒ–ç‰ˆï¼ ï¼ˆå®Œå…¨å¼€æºå¯å•†ç”¨ï¼‰ |
| 2023-07-19 | [Firefly-LLaMA2-Chinese](https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese) | 112 | ğŸ”  ğŸšŒ ğŸš• 1ï¸âƒ£ 2ï¸âƒ£ ğŸ€„  | ä¸­æ–‡LLaMA-2å¤§æ¨¡å‹ï¼Œå…¼å®¹å¯¹ä¸­æ–‡å¤§æ¨¡å‹è¿›è¡Œå¢é‡é¢„è®­ç»ƒ |
| 2023-07-18 | [Chinese-Llama-2](https://github.com/longyuewangdcu/Chinese-Llama-2) | 274 | ğŸ”  ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Chinese-Llama-2 is a project that aims to expand the impressive capabilities of the Llama-2 language model to the Chinese language. |
| 2023-07-18 | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 2863 | ğŸ”  ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£ ğŸ’° ğŸ€„  | ä¸­æ–‡LLaMA-2 & Alpaca-2å¤§æ¨¡å‹äºŒæœŸé¡¹ç›® + 16Kè¶…é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ (Chinese LLaMA-2 & Alpaca-2 LLMs, including 16K long context models) |
| 2023-07-17 | [ER-NeRF](https://github.com/Fictionarry/ER-NeRF) | 150 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | [ICCV'23] Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis |
| 2023-07-17 | [llama-recipes](https://github.com/facebookresearch/llama-recipes) | 3432 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | Examples and recipes for Llama 2 model |
| 2023-07-16 | [bubogpt](https://github.com/magic-research/bubogpt) | 358 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-15 | [SEED](https://github.com/AILab-CVC/SEED) | 148 | ğŸ–¼ï¸ ğŸšŒ  | Empowers LLMs with the ability to see and draw. |
| 2023-07-11 | [Emu](https://github.com/baaivision/Emu) | 505 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | Emu: An Open Multimodal Generalist |
| 2023-07-10 | [Baichuan-13B](https://github.com/baichuan-inc/Baichuan-13B) | 2432 | ğŸ”  ğŸšŒ âœ‚ï¸  | A 13B large language model developed by Baichuan Intelligent Technology |
| 2023-07-08 | [DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 591 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Official code for DragDiffusion |
| 2023-07-06 | [long_llama](https://github.com/CStanKonrad/long_llama) | 955 | ğŸ”  ğŸšŒ  | LongLLaMA is a large language model capable of handling long contexts. It is based on OpenLLaMA and fine-tuned with the Focused Transformer (FoT) method. |
| 2023-07-06 | [InternLM](https://github.com/InternLM/InternLM) | 2554 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-06 | [whisper-at](https://github.com/YuanGongND/whisper-at) | 136 | ğŸµ ğŸšŒ  | Code and Pretrained Models for Interspeech 2023 Paper "Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong Audio Event Taggers" |
| 2023-07-06 | [GPT4RoI](https://github.com/jshilong/GPT4RoI) | 313 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-05 | [MOSS-RLHF](https://github.com/OpenLMLab/MOSS-RLHF) | 766 | ğŸ”  ğŸšŒ 3ï¸âƒ£ ğŸ€„  | MOSS-RLHF |
| 2023-07-04 | [text2cinemagraph](https://github.com/text2cinemagraph/text2cinemagraph) | 263 | ğŸ”  ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Official Pytorch implementation of Text2Cinemagraph: Synthesizing Artistic Cinemagraphs from Text |
| 2023-07-04 | [StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 441 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-30 | [VisCPM](https://github.com/OpenBMB/VisCPM) | 788 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ€„  | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-28 | [One-2-3-45](https://github.com/One-2-3-45/One-2-3-45) | 833 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | official code of "One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization" |
| 2023-06-28 | [UnitSpeech](https://github.com/gmltmd789/UnitSpeech) | 88 | ğŸµ ğŸšŒ 2ï¸âƒ£  | An official implementation of "UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data" |
| 2023-06-27 | [LLaVAR](https://github.com/SALT-NLP/LLaVAR) | 129 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Code/Data for the paper: "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding" |
| 2023-06-24 | [ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B) | 12051 | ğŸ”  ğŸšŒ âœ‚ï¸ ğŸ€„  | ChatGLM2-6B: An Open Bilingual Chat LLM \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-06-23 | [xgen](https://github.com/salesforce/xgen) | 665 | ğŸ”  ğŸšŒ  | Salesforce open-source LLMs with 8k sequence length. |
| 2023-06-22 | [generative-models](https://github.com/Stability-AI/generative-models) | 8851 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Generative Models by Stability AI |
| 2023-06-17 | [AnimateDiff](https://github.com/guoyww/AnimateDiff) | 3005 | ğŸ”  ğŸ¥ ğŸšŒ  | Official implementation of AnimateDiff. |
| 2023-06-16 | [BayLing](https://github.com/ictnlp/BayLing) | 244 | ğŸ”  ğŸšŒ  |  â€œç™¾è†â€æ˜¯ä¸€ä¸ªåŸºäºLLaMAçš„è¯­è¨€å¯¹é½å¢å¼ºçš„è‹±è¯­/ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ä¼˜è¶Šçš„è‹±è¯­/ä¸­æ–‡èƒ½åŠ›ï¼Œåœ¨å¤šè¯­è¨€å’Œé€šç”¨ä»»åŠ¡ç­‰å¤šé¡¹æµ‹è¯•ä¸­å–å¾—ChatGPT 90%çš„æ€§èƒ½ã€‚BayLing is an English/Chinese LLM equipped with advanced language alignment, showing superior capability in English/Chinese generation, instruction following and multi-turn interaction. |
| 2023-06-14 | [Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 5022 | ğŸ”  â›½ ğŸšŒ ğŸ€„  | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-13 | [PanoHead](https://github.com/SizheAn/PanoHead) | 1460 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-12 | [Anima](https://github.com/lyogavin/Anima) | 1118 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ€„  | ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [open-instruct](https://github.com/allenai/open-instruct) | 407 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-08 | [audiocraft](https://github.com/facebookresearch/audiocraft) | 15671 | ğŸµ ğŸšŒ 2ï¸âƒ£  | Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
| 2023-06-05 | [YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat) | 277 | ğŸ”  ğŸšŒ âœ‚ï¸  | YuLan-Chat: An Open-Source Bilingual Chatbot |
| 2023-06-03 | [InternLM-techreport](https://github.com/InternLM/InternLM-techreport) | 840 | ğŸ”  ğŸšŒ  | We present InternLM, a multilingual foundational language model with 104B parameters. InternLM is pre-trained on a large corpora with 1.6T tokens with a multi-phase progressive process, and then fine-tuned to align with human preferences. |
| 2023-06-03 | [DisCo](https://github.com/Wangt-CN/DisCo) | 567 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | DisCo: Referring Human Dance Generation in Real World |
| 2023-06-01 | [videocomposer](https://github.com/damo-vilab/videocomposer) | 614 | ğŸ”  ğŸ¥ ğŸšŒ  | Official repo for VideoComposer: Compositional Video Synthesis with Motion Controllability |
| 2023-05-31 | [refacer](https://github.com/xaviviro/refacer) | 329 | ğŸ¥ ğŸšŒ  | Refacer: One-Click Deepfake Multi-Face Swap Tool |
| 2023-05-31 | [LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | 504 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [WebGLM](https://github.com/THUDM/WebGLM) | 1287 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ”¨ ğŸ€„ `Python`  | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-25 | [openchat](https://github.com/imoneoi/openchat) | 1579 | ğŸ”  â›½ ğŸšŒ ğŸš• 2ï¸âƒ£  | OpenChat: Advancing Open-source Language Models with Imperfect Data |
| 2023-05-24 | [SAIL](https://github.com/luohongyin/SAIL) | 138 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | SAIL: Search Augmented Instruction Learning |
| 2023-05-23 | [ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | 270 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 563 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | ğŸ©º é¦–ä¸ªä¼šçœ‹èƒ¸éƒ¨Xå…‰ç‰‡çš„ä¸­æ–‡å¤šæ¨¡æ€åŒ»å­¦å¤§æ¨¡å‹ \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1145 | ğŸ”  ğŸ–¼ï¸ ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | 596 | ğŸ–¼ï¸ ğŸšŒ  | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-19 | [gorilla](https://github.com/ShishirPatil/gorilla) | 7995 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ”¨ ğŸ’° `Python`  | Gorilla: An API store for LLMs |
| 2023-05-18 | [ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 581 | ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 436 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | 481 | ğŸ”  ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | "Video-ChatGPT" is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. We also introduce a rigorous 'Quantitative Evaluation Benchmarking' for video-based conversational models. |
| 2023-05-18 | [UniControl](https://github.com/salesforce/UniControl) | 483 | ğŸ–¼ï¸ ğŸšŒ  | Unified Controllable Visual Generation Model |
| 2023-05-18 | [PandaGPT](https://github.com/yxuansu/PandaGPT) | 594 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 462 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-16 | [SpeechGPT](https://github.com/0nutation/SpeechGPT) | 561 | ğŸ”  ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [bloomchat](https://github.com/sambanova/bloomchat) | 569 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | 789 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ 3ï¸âƒ£  | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-13 | [Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | 269 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-12 | [TigerBot](https://github.com/TigerResearch/TigerBot) | 1729 | ğŸ”  â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [BiLLa](https://github.com/Neutralzz/BiLLa) | 402 | ğŸ”  â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£ ğŸ€„  | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-07 | [PaLM](https://github.com/conceptofmind/PaLM) | 686 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | An open-source implementation of Google's PaLM models |
| 2023-05-06 | [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1504 | ğŸ”  ğŸ¥ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2540 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1173 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [WebCPM](https://github.com/thunlp/WebCPM) | 869 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [Dromedary](https://github.com/IBM/Dromedary) | 969 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-03 | [WizardVicunaLM](https://github.com/melodysdreamj/WizardVicunaLM) | 649 | ğŸ”  ğŸšŒ  | LLM that combines the principles of wizardLM and vicunaLM |
| 2023-05-03 | [alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | 520 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-04-28 | [pandallm](https://github.com/dandelionsllm/pandallm) | 867 | ğŸ”  â›½ ğŸšŒ ğŸ€„  | Pandaé¡¹ç›®æ˜¯äº2023å¹´5æœˆå¯åŠ¨çš„å¼€æºæµ·å¤–ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹é¡¹ç›®ï¼Œè‡´åŠ›äºå¤§æ¨¡å‹æ—¶ä»£æ¢ç´¢æ•´ä¸ªæŠ€æœ¯æ ˆï¼Œæ—¨åœ¨æ¨åŠ¨ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„åˆ›æ–°å’Œåˆä½œã€‚ |
| 2023-04-28 | [llm-foundry](https://github.com/mosaicml/llm-foundry) | 2977 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | LLM training code for MosaicML foundation models |
| 2023-04-28 | [open_llama](https://github.com/openlm-research/open_llama) | 6569 | ğŸ”  ğŸšŒ ğŸ’°  | In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. |
| 2023-04-28 | [ReplitLM](https://github.com/replit/ReplitLM) | 853 | ğŸ”  â›½ ğŸšŒ  | Inference code and configs for the ReplitLM model family |
| 2023-04-27 | [Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 275 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [OpenBuddy](https://github.com/OpenBuddy/OpenBuddy) | 876 | ğŸ”  ğŸšŒ ğŸ€„  | Open Multilingual Chatbot for Everyone |
| 2023-04-26 | [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1184 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ  | Multimodal-GPT |
| 2023-04-25 | [mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1377 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-23 | [GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 579 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3287 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-23 | [LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | 715 | ğŸ”  â›½ ğŸšŒ  | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [WizardLM](https://github.com/nlpxucan/WizardLM) | 6494 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder and WizardMath |
| 2023-04-19 | [MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 752 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-19 | [StableLM](https://github.com/Stability-AI/StableLM) | 15397 | ğŸ”  ğŸšŒ  | StableLM: Stability AI Language Models |
| 2023-04-17 | [h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 2588 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ’°  | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs. Documentation: https://h2oai.github.io/h2o-llmstudio/ |
| 2023-04-17 | [LLaVA](https://github.com/haotian-liu/LLaVA) | 4812 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [MOSS](https://github.com/OpenLMLab/MOSS) | 11417 | ğŸ”  â›½ ğŸšŒ âœ‚ï¸ ğŸ’° ğŸ€„  | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-15 | [MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22265 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-09 | [Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 4001 | ğŸ–¼ï¸ ğŸ¥ ğŸšŒ ğŸ§Š  | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-07 | [bark](https://github.com/suno-ai/bark) | 25901 | ğŸ”  ğŸµ ğŸšŒ ğŸ’°  | ğŸ”Š Text-Prompted Generative Audio Model |
| 2023-04-06 | [threestudio](https://github.com/threestudio-project/threestudio) | 2582 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | A unified framework for 3D content generation. |
| 2023-04-03 | [VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | 1993 | ğŸ”  ğŸ¥ ğŸšŒ 2ï¸âƒ£  | A Toolkit for Text-to-Video Generation and Editing |
| 2023-04-02 | [Firefly](https://github.com/yangjianxin1/Firefly) | 2275 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸ ğŸ€„  | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹(å…¨é‡å¾®è°ƒ+QLoRA)ï¼Œæ”¯æŒå¾®è°ƒLlma2ã€Llamaã€Qwenã€Baichuanã€ChatGLM2ã€InternLMã€Ziyaã€Bloomç­‰å¤§æ¨¡å‹ |
| 2023-04-01 | [LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | 2607 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸ ğŸ“  | âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ |
| 2023-04-01 | [Otter](https://github.com/Luodian/Otter) | 2360 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | 643 | ğŸ”  â›½ ğŸšŒ ğŸ€„  | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-31 | [baize-chatbot](https://github.com/project-baize/baize-chatbot) | 3015 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-30 | [Llama-X](https://github.com/AetherCortex/Llama-X) | 1414 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | Open Academic Research on Improving LLaMA to SOTA LLM |
| 2023-03-30 | [FollowYourPose](https://github.com/mayuelala/FollowYourPose) | 657 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-29 | [LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | 704 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-27 | [LMFlow](https://github.com/OptimalScale/LMFlow) | 7143 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ 3ï¸âƒ£  | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [dolly](https://github.com/databrickslabs/dolly) | 10556 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ ğŸ’°  | Databricksâ€™ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-24 | [h2ogpt](https://github.com/h2oai/h2ogpt) | 7121 | ğŸ”  ğŸšŒ 2ï¸âƒ£ ğŸ’°  | Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo: https://gpt.h2o.ai/ |
| 2023-03-23 | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 3975 | ğŸ”  ğŸšŒ 2ï¸âƒ£ âœ‚ï¸ ğŸ€„  | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-23 | [Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1320 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ ğŸ§Š  | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-22 | [lit-llama](https://github.com/Lightning-AI/lit-llama) | 5127 | ğŸ”  ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£ âœ‚ï¸ ğŸ’°  | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [Linly](https://github.com/CVI-SZU/Linly) | 2677 | ğŸ”  â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ âœ‚ï¸ ğŸ’¡ ğŸ’° ğŸ€„  | Chinese-LLaMA 1&2ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | 3339 | ğŸ”  ğŸšŒ ğŸ€„  | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [Text2Video-Zero](https://github.com/Picsart-AI-Research/Text2Video-Zero) | 3257 | ğŸ¥ ğŸšŒ  | [ICCV 2023 Oral] Text-to-Image Diffusion Models are Zero-Shot Video Generators |
| 2023-03-21 | [DreamPose](https://github.com/johannakarras/DreamPose) | 668 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-21 | [text2room](https://github.com/lukasHoel/text2room) | 839 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models (ICCV2023). |
| 2023-03-19 | [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4720 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [FastChat](https://github.com/lm-sys/FastChat) | 26859 | ğŸ”  ğŸšŒ 2ï¸âƒ£ ğŸ’°  | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena. |
| 2023-03-18 | [KoAlpaca](https://github.com/Beomi/KoAlpaca) | 1287 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | KoAlpaca: í•œêµ­ì–´ ëª…ë ¹ì–´ë¥¼ ì´í•´í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ëª¨ë¸ |
| 2023-03-17 | [BELLE](https://github.com/LianjiaTech/BELLE) | 6629 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸ ğŸ€„  | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-16 | [AudioGPT](https://github.com/AIGC-Audio/AudioGPT) | 9135 | ğŸ”  ğŸµ ğŸšŒ  | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head |
| 2023-03-16 | [FateZero](https://github.com/ChenyangQiQi/FateZero) | 844 | ğŸ”  ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | [ICCV 2023 Oral] "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-15 | [so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | 6749 | ğŸµ ğŸšŒ 2ï¸âƒ£  | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-14 | [ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | 3372 | ğŸ–¼ï¸ ğŸšŒ  | Nightly release of ControlNet 1.1 |
| 2023-03-13 | [3DFuse](https://github.com/KU-CVLAB/3DFuse) | 644 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-13 | [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | 33761 | ğŸ”  ğŸšŒ 2ï¸âƒ£ âœ‚ï¸ ğŸ€„  | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-03-13 | [alpaca-lora](https://github.com/tloen/alpaca-lora) | 16863 | ğŸ”  ğŸšŒ 2ï¸âƒ£  | Instruct-tune LLaMA on consumer hardware |
| 2023-03-10 | [so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | 18647 | ğŸµ ğŸšŒ 2ï¸âƒ£  | SoftVC VITS Singing Voice Conversion |
| 2023-03-10 | [stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | 26541 | ğŸ”  â›½ ğŸšŒ 2ï¸âƒ£  | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-10 | [unidiffuser](https://github.com/thu-ml/unidiffuser) | 1070 | ğŸ–¼ï¸ ğŸšŒ  | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2957 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Official implementation of the paper "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-04 | [DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | 1065 | ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8859 | ğŸ”  â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  |  |
| 2023-02-26 | [consistency_models](https://github.com/openai/consistency_models) | 5392 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Official repo for consistency models. |
| 2023-02-15 | [T2I-Adapter](https://github.com/TencentARC/T2I-Adapter) | 2286 | ğŸ”  ğŸ–¼ï¸ ğŸšŒ  | T2I-Adapter |
| 2023-02-14 | [llama](https://github.com/facebookresearch/llama) | 40416 | ğŸ”  ğŸšŒ  | Inference code for LLaMA models |
| 2023-02-01 | [ControlNet](https://github.com/lllyasviel/ControlNet) | 23055 | ğŸ–¼ï¸ ğŸšŒ 2ï¸âƒ£  | Let us control diffusion models! |
| 2023-01-27 | [musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | 2679 | ğŸµ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-20 | [IF](https://github.com/deep-floyd/IF) | 7051 | ğŸ–¼ï¸ ğŸšŒ  |  |
| 2023-01-13 | [ChatRWKV](https://github.com/BlinkDL/ChatRWKV) | 8679 | ğŸ”  ğŸšŒ  | ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source. |
| 2023-01-09 | [instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 5157 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [nanoGPT](https://github.com/karpathy/nanoGPT) | 24287 | ğŸ”  â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-25 | [Tune-A-Video](https://github.com/showlab/Tune-A-Video) | 3587 | ğŸ¥ ğŸšŒ  | [ICCV 2023] Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation |
| 2022-12-06 | [point-e](https://github.com/openai/point-e) | 5786 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Point cloud diffusion for 3D model synthesis |
| 2022-11-23 | [SadTalker](https://github.com/OpenTalker/SadTalker) | 6321 | ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-23 | [stablediffusion](https://github.com/Stability-AI/stablediffusion) | 29342 | ğŸ–¼ï¸ â›½ ğŸšŒ  | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-10-22 | [diff-svc](https://github.com/prophesier/diff-svc) | 2395 | ğŸµ ğŸšŒ 2ï¸âƒ£  | Singing Voice Conversion via diffusion model |
| 2022-10-20 | [open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2804 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | An open-source framework for training large multimodal models. |
| 2022-10-18 | [stable-diffusion](https://github.com/runwayml/stable-diffusion) | 2933 | ğŸ–¼ï¸ ğŸšŒ  | Latent Text-to-Image Diffusion |
| 2022-10-06 | [stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | 6648 | ğŸ–¼ï¸ ğŸšŒ ğŸ§Š  | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-09-29 | [motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | 2370 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-25 | [whisper.cpp](https://github.com/ggerganov/whisper.cpp) | 22551 | ğŸµ ğŸšŒ âœ‚ï¸  | Port of OpenAI's Whisper model in C/C++ |
| 2022-09-16 | [whisper](https://github.com/openai/whisper) | 43880 | ğŸ”  ğŸµ ğŸšŒ  | Robust Speech Recognition via Large-Scale Weak Supervision |
| 2022-09-09 | [VToonify](https://github.com/williamyang1991/VToonify) | 3283 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-08-24 | [LAVIS](https://github.com/salesforce/LAVIS) | 6494 | ğŸ”  ğŸ–¼ï¸ â›½ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-10 | [stable-diffusion](https://github.com/CompVis/stable-diffusion) | 59499 | ğŸ–¼ï¸ â›½ ğŸšŒ  | A latent text-to-image diffusion model |
| 2022-08-03 | [GLM-130B](https://github.com/THUDM/GLM-130B) | 7032 | ğŸ”  ğŸšŒ  | GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023) |
| 2022-08-02 | [textual_inversion](https://github.com/rinongal/textual_inversion) | 2569 | ğŸ–¼ï¸ â›½ ğŸšŒ 2ï¸âƒ£  |  |
