| Date | Repository | Stars | tags | Language |  Description  |
|------------|---------|-------|-------------|-------------|-------------|
| 2023-08-18 | [facebookresearch/meru](https://github.com/facebookresearch/meru) | 67 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Code for the paper "Hyperbolic Image-Text Representations", Desai et al, ICML 2023 |
| 2023-08-17 | [zhihaiLLM/wisdomInterrogatory](https://github.com/zhihaiLLM/wisdomInterrogatory) | 149 | ğŸ” ğŸš•2ï¸âƒ£ |   |  |
| 2023-08-16 | [mshumer/gpt-oracle-trainer](https://github.com/mshumer/gpt-oracle-trainer) | 284 | ğŸ” 2ï¸âƒ£ |   | Creating a chatbot that can accurately answer questions about a product or service's documentation |
| 2023-08-16 | [run-llama/modal_finetune_sql](https://github.com/run-llama/modal_finetune_sql) | 123 | ğŸ” 2ï¸âƒ£ |   |  |
| 2023-08-15 | [qiuyu96/CoDeF](https://github.com/qiuyu96/CoDeF) | 2999 | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | Official PyTorch implementation of CoDeF: Content Deformation Fields for Temporally Consistent Video Processing |
| 2023-08-12 | [DLLXW/baby-llama2-chinese](https://github.com/DLLXW/baby-llama2-chinese) | 306 | ğŸ” 2ï¸âƒ£ |   | ç”¨äºä»å¤´é¢„è®­ç»ƒ+SFTä¸€ä¸ªå°å‚æ•°é‡çš„ä¸­æ–‡LLaMa2çš„ä»“åº“ï¼›24Gå•å¡å³å¯è¿è¡Œå¾—åˆ°ä¸€ä¸ªå…·å¤‡ç®€å•ä¸­æ–‡é—®ç­”èƒ½åŠ›çš„chat-llama2. |
| 2023-08-09 | [mshumer/gpt-llm-trainer](https://github.com/mshumer/gpt-llm-trainer) | 1760 | ğŸ” 2ï¸âƒ£ |   |  |
| 2023-08-01 | [HIT-SCIR-SC/QiaoBan](https://github.com/HIT-SCIR-SC/QiaoBan) | 65 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | è¿™æ˜¯ä¸€ä¸ªå·§æ¿å¤§æ¨¡å‹çš„ä»“åº“ï¼Œæ—¨åœ¨æ„å»ºä¸€ä¸ªé¢å‘å„¿ç«¥æƒ…æ„Ÿé™ªä¼´çš„å¤§æ¨¡å‹ |
| 2023-07-30 | [OpenLLMAI/OpenLLaMA2](https://github.com/OpenLLMAI/OpenLLaMA2) | 75 | ğŸ” 2ï¸âƒ£3ï¸âƒ£ |   | DeepSpeed+Ray based LLaMA2 SFT/RLHF training framework |
| 2023-07-28 | [epfLLM/Megatron-LLM](https://github.com/epfLLM/Megatron-LLM) | 132 | ğŸ” 2ï¸âƒ£ |   | distributed trainer for LLMs |
| 2023-07-26 | [IDEA-Research/DWPose](https://github.com/IDEA-Research/DWPose) | 944 | ğŸ¥ğŸšŒ2ï¸âƒ£ |   | "Effective Whole-body Pose Estimation with Two-stages Distillation" (ICCV 2023, CV4Metaverse Workshop) |
| 2023-07-21 | [Alpha-VLLM/LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory) | 1371 | ğŸ” ğŸ–¼ï¸â›½1ï¸âƒ£2ï¸âƒ£ğŸ”¨ |  Python | An Open-source Toolkit for LLM Development |
| 2023-07-21 | [OPPO-Mente-Lab/Subject-Diffusion](https://github.com/OPPO-Mente-Lab/Subject-Diffusion) | 149 | ğŸ–¼ï¸`â›½`ğŸšŒ2ï¸âƒ£ |   | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning |
| 2023-07-21 | [segmind/distill-sd](https://github.com/segmind/distill-sd) | 282 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ |   | Segmind Distilled diffusion |
| 2023-07-20 | [LinkSoul-AI/Chinese-Llama-2-7b](https://github.com/LinkSoul-AI/Chinese-Llama-2-7b) | 1682 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ’°ğŸ€„ |   | å¼€æºç¤¾åŒºç¬¬ä¸€ä¸ªèƒ½ä¸‹è½½ã€èƒ½è¿è¡Œçš„ä¸­æ–‡ LLaMA2 æ¨¡å‹ï¼ |
| 2023-07-20 | [omerbt/TokenFlow](https://github.com/omerbt/TokenFlow) | 587 | ğŸ¥`2ï¸âƒ£` |   | Official Pytorch Implementation for "TokenFlow: Consistent Diffusion Features for Consistent Video Editing" presenting "TokenFlow" |
| 2023-07-19 | [FlagAlpha/Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese) | 4166 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ’°ğŸ€„ |   | Llamaä¸­æ–‡ç¤¾åŒºï¼Œæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨ |
| 2023-07-19 | [michael-wzhu/Chinese-LlaMA2](https://github.com/michael-wzhu/Chinese-LlaMA2) | 685 | ğŸ” `ğŸšŒ``ğŸš•``1ï¸âƒ£``2ï¸âƒ£`ğŸ’°ğŸ€„ |   | Repo for adapting Meta LlaMA2 in Chinese! METAæœ€æ–°å‘å¸ƒçš„LlaMA2çš„æ±‰åŒ–ç‰ˆï¼ ï¼ˆå®Œå…¨å¼€æºå¯å•†ç”¨ï¼‰ |
| 2023-07-19 | [yangjianxin1/Firefly-LLaMA2-Chinese](https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese) | 107 | ğŸ” `ğŸšŒ``ğŸš•``1ï¸âƒ£``2ï¸âƒ£`ğŸ€„ |   | ä¸­æ–‡LLaMA-2å¤§æ¨¡å‹ï¼Œå…¼å®¹å¯¹ä¸­æ–‡å¤§æ¨¡å‹è¿›è¡Œå¢é‡é¢„è®­ç»ƒ |
| 2023-07-18 | [longyuewangdcu/Chinese-Llama-2](https://github.com/longyuewangdcu/Chinese-Llama-2) | 264 | ğŸ” ğŸšŒ`1ï¸âƒ£`2ï¸âƒ£ |   | Chinese-Llama-2 is a project that aims to expand the impressive capabilities of the Llama-2 language model to the Chinese language. |
| 2023-07-18 | [ymcui/Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 2552 | ğŸ” `ğŸšŒ``1ï¸âƒ£``2ï¸âƒ£`ğŸ’°ğŸ€„ |   | ä¸­æ–‡ LLaMA-2 & Alpaca-2 å¤§æ¨¡å‹äºŒæœŸé¡¹ç›® + æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½²  (Chinese LLaMA-2 & Alpaca-2 LLMs) |
| 2023-07-17 | [DUOMO/TransGPT](https://github.com/DUOMO/TransGPT) | 430 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ’°ğŸ€„ |   | TransGPTæ˜¯å›½å†…é¦–æ¬¾å¼€æºäº¤é€šå¤§æ¨¡å‹ï¼Œä¸»è¦è‡´åŠ›äºåœ¨çœŸå®äº¤é€šè¡Œä¸šä¸­å‘æŒ¥å®é™…ä»·å€¼ã€‚ |
| 2023-07-17 | [Fictionarry/ER-NeRF](https://github.com/Fictionarry/ER-NeRF) | 132 | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | [ICCV'23] Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis |
| 2023-07-17 | [facebookresearch/llama-recipes](https://github.com/facebookresearch/llama-recipes) | 3183 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | Examples and recipes for Llama 2 model |
| 2023-07-13 | [bytedance/lynx-llm](https://github.com/bytedance/lynx-llm) | 170 | ğŸ” ğŸ–¼ï¸2ï¸âƒ£â“ |   | paper: https://arxiv.org/abs/2307.02469 page: https://lynx-llm.github.io/ |
| 2023-07-13 | [scaleapi/llm-engine](https://github.com/scaleapi/llm-engine) | 525 | ğŸ” 2ï¸âƒ£ |   | Scale LLM Engine public repository |
| 2023-07-08 | [Yujun-Shi/DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 580 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ |   | Official code for DragDiffusion |
| 2023-07-06 | [InternLM/InternLM](https://github.com/InternLM/InternLM) | 2493 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | 301 | ğŸ” ğŸ–¼ï¸â›½`ğŸšŒ`2ï¸âƒ£ |   | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [SpongebBob/Finetune-ChatGLM2-6B](https://github.com/SpongebBob/Finetune-ChatGLM2-6B) | 257 | ğŸ” â›½2ï¸âƒ£âœ‚ï¸ |   | ChatGLM2-6B å…¨å‚æ•°å¾®è°ƒï¼Œæ”¯æŒå¤šè½®å¯¹è¯çš„é«˜æ•ˆå¾®è°ƒã€‚ |
| 2023-07-04 | [text2cinemagraph/text2cinemagraph](https://github.com/text2cinemagraph/text2cinemagraph) | 249 | ğŸ” ğŸ¥ğŸšŒ2ï¸âƒ£ |   | Official Pytorch implementation of Text2Cinemagraph: Synthesizing Artistic Cinemagraphs from Text |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 436 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | 768 | ğŸ” ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£`ğŸ€„ |   | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-29 | [IMOSR/MediaGPT](https://github.com/IMOSR/MediaGPT) | 454 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ |   | ä¸­æ–‡çš„è‡ªåª’ä½“å¤§è¯­è¨€æ¨¡å‹MediaGPT(æ›¾ç”¨åMedia LLaMA) |
| 2023-06-28 | [gmltmd789/UnitSpeech](https://github.com/gmltmd789/UnitSpeech) | 86 | ğŸµğŸšŒ2ï¸âƒ£ |   | An official implementation of "UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data" |
| 2023-06-28 | [replicate/cog-llama-template](https://github.com/replicate/cog-llama-template) | 236 | ğŸ” 2ï¸âƒ£â“ |   | LLaMA Cog template |
| 2023-06-27 | [SALT-NLP/LLaVAR](https://github.com/SALT-NLP/LLaVAR) | 125 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Code/Data for the paper: "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding" |
| 2023-06-24 | [EvilPsyCHo/train_custom_LLM](https://github.com/EvilPsyCHo/train_custom_LLM) | 165 | ğŸ” 2ï¸âƒ£ |   | Train your custom LLMs like Llama, baichuan-7b, GPT |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | 8703 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Generative Models by Stability AI |
| 2023-06-22 | [eric-mitchell/direct-preference-optimization](https://github.com/eric-mitchell/direct-preference-optimization) | 397 | ğŸ” 2ï¸âƒ£3ï¸âƒ£ |   | Reference implementation for DPO (Direct Preference Optimization) |
| 2023-06-19 | [beyondguo/LLM-Tuning](https://github.com/beyondguo/LLM-Tuning) | 649 | ğŸ” 2ï¸âƒ£ |   | Tuning LLMs with no tearsğŸ’¦, sharing LLM-tools with loveâ¤ï¸. |
| 2023-06-16 | [SpeechifyInc/Meta-voicebox](https://github.com/SpeechifyInc/Meta-voicebox) | 440 | ğŸµ`2ï¸âƒ£` |   | Implementation of Meta-Voicebox : The first generative AI model for speech to generalize across tasks with state-of-the-art performance. |
| 2023-06-13 | [SizheAn/PanoHead](https://github.com/SizheAn/PanoHead) | 1447 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ğŸ§Š |   | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | 1108 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ€„ |   | ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [allenai/open-instruct](https://github.com/allenai/open-instruct) | 390 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-08 | [facebookresearch/audiocraft](https://github.com/facebookresearch/audiocraft) | 15308 | ğŸµğŸšŒ`2ï¸âƒ£` |   | Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
| 2023-06-05 | [BrandonHanx/HeadSculpt](https://github.com/BrandonHanx/HeadSculpt) | 90 | ğŸ” 2ï¸âƒ£ğŸ§Š |   | [arXiv 2023 WIP] HeadSculpt: Crafting 3D Head Avatars with Text |
| 2023-06-03 | [Wangt-CN/DisCo](https://github.com/Wangt-CN/DisCo) | 564 | ğŸ¥ğŸšŒ2ï¸âƒ£ |   | DisCo: Referring Human Dance Generation in Real World |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | 1309 | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ğŸ€„ |   | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ |
| 2023-05-31 | [yuchenlin/LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | 495 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | 1270 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ”¨ğŸ€„ |  Python | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-28 | [hiyouga/LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) | 3152 | ğŸ” 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ |   | Easy-to-use LLM fine-tuning framework (LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, ChatGLM2) |
| 2023-05-25 | [imoneoi/openchat](https://github.com/imoneoi/openchat) | 1565 | ğŸ” â›½ğŸšŒğŸš•2ï¸âƒ£ |   | OpenChat: Advancing Open-source Language Models with Imperfect Data |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | 134 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | SAIL: Search Augmented Instruction Learning |
| 2023-05-24 | [wenge-research/YaYi](https://github.com/wenge-research/YaYi) | 1465 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | é›…æ„å¤§æ¨¡å‹ï¼šä¸ºå®¢æˆ·æ‰“é€ å®‰å…¨å¯é çš„ä¸“å±å¤§æ¨¡å‹ï¼ŒåŸºäºå¤§è§„æ¨¡ä¸­è‹±æ–‡å¤šé¢†åŸŸæŒ‡ä»¤æ•°æ®è®­ç»ƒçš„ LlaMA 2 & BLOOM ç³»åˆ—æ¨¡å‹ï¼Œç”±ä¸­ç§‘é—»æ­Œç®—æ³•å›¢é˜Ÿç ”å‘ã€‚(Repo for YaYi Chinese LLMs based on LlaMA2 & BLOOM) |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | 269 | ğŸ” â›½`ğŸšŒ`2ï¸âƒ£ |   | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1136 | ğŸ” ğŸ–¼ï¸ğŸµâ›½ğŸšŒ2ï¸âƒ£ |   | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | 7835 | ğŸ” â›½ğŸšŒ`2ï¸âƒ£`ğŸ”¨ğŸ’° |  Python | Gorilla: An API store for LLMs |
| 2023-05-19 | [YuanGongND/ltu](https://github.com/YuanGongND/ltu) | 96 | ğŸ” ğŸµ`2ï¸âƒ£` |   | Github Repo for Paper "Listen, Think, and Understand". |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 566 | ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 435 | ğŸ–¼ï¸`ğŸšŒ``2ï¸âƒ£` |   | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | 474 | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | "Video-ChatGPT" is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. We also introduce a rigorous 'Quantitative Evaluation Benchmarking' for video-based conversational models. |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | 339 | ğŸ” ğŸ–¼ï¸â›½ğŸš•2ï¸âƒ£ |   | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-18 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | 589 | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ |   | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [lucidrains/soundstorm-pytorch](https://github.com/lucidrains/soundstorm-pytorch) | 982 | ğŸµ2ï¸âƒ£ |   | Implementation of SoundStorm, Efficient Parallel Audio Generation from Google Deepmind, in Pytorch |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 457 | ğŸ–¼ï¸`â›½`ğŸšŒ`2ï¸âƒ£` |   | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-17 | [princeton-nlp/tree-of-thought-llm](https://github.com/princeton-nlp/tree-of-thought-llm) | 3017 | ğŸ” `2ï¸âƒ£` |   | Official Implementation of "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | 544 | ğŸ” ğŸµ`â›½``ğŸšŒ``2ï¸âƒ£` |   | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | 567 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | 772 | ğŸ” â›½ğŸšŒ2ï¸âƒ£3ï¸âƒ£ |   | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-13 | [HeliosZhao/Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | 267 | ğŸ¥ğŸšŒ`2ï¸âƒ£` |   | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | 1706 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | TigerBot: A multi-language multi-task LLM |
| 2023-05-11 | [artidoro/qlora](https://github.com/artidoro/qlora) | 7257 | ğŸ” 2ï¸âƒ£âœ‚ï¸ |   | QLoRA: Efficient Finetuning of Quantized LLMs |
| 2023-05-11 | [kuleshov-group/llmtune](https://github.com/kuleshov-group/llmtune) | 523 | ğŸ” 2ï¸âƒ£ |   | 4-Bit Finetuning of Large Language Models on One Consumer GPU |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 400 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ |   | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-07 | [conceptofmind/PaLM](https://github.com/conceptofmind/PaLM) | 682 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | An open-source implementation of Google's PaLM models |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1477 | ğŸ” ğŸ¥ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2450 | ğŸ” ğŸ–¼ï¸ğŸšŒ`1ï¸âƒ£`2ï¸âƒ£ |   | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1166 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | 863 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [IBM/Dromedary](https://github.com/IBM/Dromedary) | 967 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-03 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | 513 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-05-02 | [salesforce/CodeTF](https://github.com/salesforce/CodeTF) | 1316 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM |
| 2023-04-28 | [mosaicml/llm-foundry](https://github.com/mosaicml/llm-foundry) | 2953 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | LLM training code for MosaicML foundation models |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 273 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [mosaicml/diffusion](https://github.com/mosaicml/diffusion) | 443 | ğŸ–¼ï¸2ï¸âƒ£ |   | This repo contains code used to train your own Stable Diffusion model on your own data. |
| 2023-04-25 | [HugAILab/HugNLP](https://github.com/HugAILab/HugNLP) | 314 | ğŸ” 2ï¸âƒ£ |   | HugNLP is a unified and comprehensive NLP library based on HuggingFace Transformer. Please hugging for NLP now!ğŸ˜Š |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1358 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [bigcode-project/starcoder](https://github.com/bigcode-project/starcoder) | 6155 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | Home of StarCoder: fine-tuning & inference! |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 571 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3248 | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£âœ‚ï¸ |   | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-23 | [minosvasilias/godot-dodo](https://github.com/minosvasilias/godot-dodo) | 441 | ğŸ” ğŸš•2ï¸âƒ£ |   | Finetuning large language models for GDScript generation. |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | 5317 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder and WizardMath |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 5098 | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£ |   |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 750 | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£âœ‚ï¸ |   | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-19 | [lucidrains/naturalspeech2-pytorch](https://github.com/lucidrains/naturalspeech2-pytorch) | 899 | ğŸµ2ï¸âƒ£ |   | Implementation of Natural Speech 2, Zero-shot Speech and Singing Synthesizer, in Pytorch |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 2546 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ’° |   | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs. Documentation: https://h2oai.github.io/h2o-llmstudio/ |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 4632 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22185 | ğŸ” ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-13 | [FreedomIntelligence/HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT) | 605 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | HuatuoGPT, Towards Taming Language Models To Be a Doctor. (An Open Medical GPT) |
| 2023-04-12 | [langgenius/dify](https://github.com/langgenius/dify) | 7638 | ğŸ” â›½2ï¸âƒ£ğŸ”¨ |  TypeScript | One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications. |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | 2918 | ğŸ” â›½2ï¸âƒ£3ï¸âƒ£ğŸ€„ |   | Fine-tuning ChatGLM-6B with PEFT \| åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ |
| 2023-04-06 | [Instruction-Tuning-with-GPT-4/GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | 3266 | ğŸ” â›½2ï¸âƒ£ |   | Instruction Tuning with GPT-4 |
| 2023-04-06 | [liucongg/ChatGLM-Finetuning](https://github.com/liucongg/ChatGLM-Finetuning) | 1385 | ğŸ” 2ï¸âƒ£ğŸ€„ |   | åŸºäºChatGLM-6Bã€ChatGLM2-6Bæ¨¡å‹ï¼Œè¿›è¡Œä¸‹æ¸¸å…·ä½“ä»»åŠ¡å¾®è°ƒï¼Œæ¶‰åŠFreezeã€Loraã€P-tuningã€å…¨å‚å¾®è°ƒç­‰ |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | 2474 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ğŸ§Š |   | A unified framework for 3D content generation. |
| 2023-04-03 | [VideoCrafter/VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | 1977 | ğŸ” ğŸ¥ğŸšŒ`2ï¸âƒ£` |   | A Toolkit for Text-to-Video Generation and Editing |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | 2110 | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ |   | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹(å…¨é‡å¾®è°ƒ+QLoRA)ï¼Œæ”¯æŒå¾®è°ƒLlma2ã€Llamaã€Qwenã€Baichuanã€ChatGLM2ã€InternLMã€Ziyaã€Bloomç­‰å¤§æ¨¡å‹ |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | 2585 | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ“ |   | âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | 2301 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 3566 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ |   | Repo for BenTsao [original name: HuaTuo (åé©¼)], Instruction-tuning Large Language Models with Chinese Medical Knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [SCIR-HI/Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM) | 749 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   | Repo for Chinese Medical ChatGLM åŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„ChatGLMæŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | 3003 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-30 | [AetherCortex/Llama-X](https://github.com/AetherCortex/Llama-X) | 1379 | ğŸ” `ğŸšŒ`2ï¸âƒ£ |   | Open Academic Research on Improving LLaMA to SOTA LLM |
| 2023-03-30 | [mayuelala/FollowYourPose](https://github.com/mayuelala/FollowYourPose) | 652 | ğŸ¥ğŸšŒ2ï¸âƒ£ |   | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | 694 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-28 | [WangRongsheng/ChatGenTitle](https://github.com/WangRongsheng/ChatGenTitle) | 746 | ğŸ” ğŸš•2ï¸âƒ£ |   | ğŸŒŸ ChatGenTitleï¼šä½¿ç”¨ç™¾ä¸‡arXivè®ºæ–‡ä¿¡æ¯åœ¨LLaMAæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒçš„è®ºæ–‡é¢˜ç›®ç”Ÿæˆæ¨¡å‹ |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | 7112 | ğŸ” â›½ğŸšŒ2ï¸âƒ£3ï¸âƒ£ |   | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [PhoebusSi/Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT) | 2019 | ğŸ” â›½2ï¸âƒ£ |   | We unified the interfaces of instruction-tuning data (e.g., CoT data), multiple LLMs and parameter-efficient methods (e.g., lora, p-tuning) together for easy use. Meanwhile, we created a new branch to build a Tabular LLM.ï¼ˆæˆ‘ä»¬åˆ†åˆ«ç»Ÿä¸€äº†ä¸°å¯Œçš„IFTæ•°æ®ï¼ˆå¦‚CoTæ•°æ®ï¼Œç›®å‰ä»ä¸æ–­æ‰©å……ï¼‰ã€å¤šç§è®­ç»ƒæ•ˆç‡æ–¹æ³•ï¼ˆå¦‚loraï¼Œp-tuningï¼‰ä»¥åŠå¤šç§LLMsï¼Œä¸‰ä¸ªå±‚é¢ä¸Šçš„æ¥å£ï¼Œæ‰“é€ æ–¹ä¾¿ç ”ç©¶äººå‘˜ä¸Šæ‰‹çš„LLM-IFTç ”ç©¶å¹³å°ã€‚åŒæ—¶tabular_llmåˆ†æ”¯æ„å»ºäº†é¢å‘è¡¨æ ¼æ™ºèƒ½ä»»åŠ¡çš„LLMã€‚ |
| 2023-03-24 | [databrickslabs/dolly](https://github.com/databrickslabs/dolly) | 10546 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ’° |   | Databricksâ€™ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-24 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | 6986 | ğŸ” ğŸšŒ2ï¸âƒ£ğŸ’° |   | Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo: https://gpt.h2o.ai/ |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 3963 | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ |   | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-23 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1276 | ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£`ğŸ§Š |   | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-23 | [yanqiangmiffy/InstructGLM](https://github.com/yanqiangmiffy/InstructGLM) | 603 | ğŸ” â›½2ï¸âƒ£ |   | ChatGLM-6B æŒ‡ä»¤å­¦ä¹ \|æŒ‡ä»¤æ•°æ®\|Instruct |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | 5093 | ğŸ” ğŸšŒ1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’° |   | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-22 | [sahil280114/codealpaca](https://github.com/sahil280114/codealpaca) | 1223 | ğŸ” â›½2ï¸âƒ£ |   | This is the repo for the Code Alpaca project, which aims to build and share an instruction-following LLaMA model for code generation. This repo is fully based on Stanford Alpaca ,and only changes the data used for training. Training approach is the same. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2647 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£`3ï¸âƒ£`âœ‚ï¸ğŸ’¡ğŸ’°ğŸ€„ |   | Chinese-LLaMA 1&2ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [Kent0n-Li/ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor) | 3066 | ğŸ” â›½ğŸš•2ï¸âƒ£ |   |  |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | 661 | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4687 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | 26655 | ğŸ” ğŸšŒ2ï¸âƒ£ğŸ’° |   | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena. |
| 2023-03-19 | [stochasticai/xTuring](https://github.com/stochasticai/xTuring) | 2210 | ğŸ” 2ï¸âƒ£ |   | Easily build, customize and control your own LLMs |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | 1275 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | KoAlpaca: í•œêµ­ì–´ ëª…ë ¹ì–´ë¥¼ ì´í•´í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ëª¨ë¸ |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | 6563 | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ |   | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-17 | [cvlab-columbia/zero123](https://github.com/cvlab-columbia/zero123) | 1684 | ğŸ–¼ï¸2ï¸âƒ£ğŸ§Š |   | Zero-1-to-3: Zero-shot One Image to 3D Object (ICCV 2023) |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | 930 | ğŸ” â›½2ï¸âƒ£ğŸ€„ |   | äººå·¥ç²¾è°ƒçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›†å’Œä¸€æ®µchatglmçš„å¾®è°ƒä»£ç  |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | 834 | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | [ICCV 2023 Oral] "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-16 | [lich99/ChatGLM-finetune-LoRA](https://github.com/lich99/ChatGLM-finetune-LoRA) | 598 | ğŸ” 2ï¸âƒ£ |   | Code for fintune ChatGLM-6b using low-rank adaptation (LoRA) |
| 2023-03-16 | [mymusise/ChatGLM-Tuning](https://github.com/mymusise/ChatGLM-Tuning) | 3264 | ğŸ” 2ï¸âƒ£ğŸ€„ |   | ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ,  åŸºäºChatGLM-6B + LoRA |
| 2023-03-15 | [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | 6680 | ğŸµğŸšŒ2ï¸âƒ£ |   | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 14076 | ğŸ” 1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’¡ğŸ€„ |   | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | 33578 | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ |   | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-03-13 | [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) | 16782 | ğŸ” ğŸšŒ2ï¸âƒ£ |   | Instruct-tune LLaMA on consumer hardware |
| 2023-03-10 | [svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | 18480 | ğŸµğŸšŒ2ï¸âƒ£ |   | SoftVC VITS Singing Voice Conversion |
| 2023-03-10 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | 26435 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ |   | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2906 | ğŸ” ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£` |   | Official implementation of the paper "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-04 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | 1042 | ğŸµâ›½ğŸšŒ2ï¸âƒ£ |   | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8851 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   |  |
| 2023-02-26 | [openai/consistency_models](https://github.com/openai/consistency_models) | 5387 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£âœ‚ï¸ |   | Official repo for consistency models. |
| 2023-02-11 | [Plachtaa/VITS-fast-fine-tuning](https://github.com/Plachtaa/VITS-fast-fine-tuning) | 2852 | ğŸµ2ï¸âƒ£ |   | This repo is a pipeline of VITS finetuning for fast speaker adaptation TTS, and many-to-many voice conversion |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | 22876 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ |   | Let us control diffusion models! |
| 2023-01-27 | [lucidrains/musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | 2675 | ğŸµğŸšŒ2ï¸âƒ£âœ‚ï¸ |   | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 5116 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 24159 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-08 | [cloneofsimo/lora](https://github.com/cloneofsimo/lora) | 5569 | ğŸ–¼ï¸2ï¸âƒ£ |   | Using Low-rank adaptation to quickly fine-tune diffusion models. |
| 2022-11-25 | [huggingface/peft](https://github.com/huggingface/peft) | 9115 | ğŸ” 2ï¸âƒ£ |   | ğŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning. |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | 6216 | ğŸ–¼ï¸ğŸµğŸ¥ğŸšŒ`2ï¸âƒ£` |   | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-10-22 | [prophesier/diff-svc](https://github.com/prophesier/diff-svc) | 2397 | ğŸµğŸšŒ2ï¸âƒ£ |   | Singing Voice Conversion via diffusion model |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2773 | ğŸ” ğŸ–¼ï¸`ğŸ¥`â›½ğŸšŒ2ï¸âƒ£ |   | An open-source framework for training large multimodal models. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | 2365 | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ |   | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-09 | [williamyang1991/VToonify](https://github.com/williamyang1991/VToonify) | 3272 | ğŸ¥ğŸšŒ2ï¸âƒ£ |   | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-09-06 | [XavierXiao/Dreambooth-Stable-Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) | 6918 | ğŸ–¼ï¸2ï¸âƒ£ |   | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 6408 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | 2557 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |   |  |
| 2022-07-25 | [modelscope/modelscope](https://github.com/modelscope/modelscope) | 3666 | ğŸ” ğŸ–¼ï¸ğŸµ2ï¸âƒ£ |   | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-05-30 | [huggingface/diffusers](https://github.com/huggingface/diffusers) | 17401 | ğŸ–¼ï¸ğŸµ2ï¸âƒ£ğŸ“ |   | ğŸ¤— Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
