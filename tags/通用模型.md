| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | ![OpenGVLab/VisionLLM Stars](https://img.shields.io/github/stars/OpenGVLab/VisionLLM.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹(TD)`,`è®­ç»ƒ(TD)` | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | ![OFA-Sys/ONE-PEACE Stars](https://img.shields.io/github/stars/OFA-Sys/ONE-PEACE.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | A general representation modal across vision, audio, language modalities. |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | ![mit-han-lab/fastcomposer Stars](https://img.shields.io/github/stars/mit-han-lab/fastcomposer.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®(TD)`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` |  |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | ![PKU-Alignment/safe-rlhf Stars](https://img.shields.io/github/stars/PKU-Alignment/safe-rlhf.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-07 | [conceptofmind/PaLM](https://github.com/conceptofmind/PaLM) | ![conceptofmind/PaLM Stars](https://img.shields.io/github/stars/conceptofmind/PaLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | An open-source implementation of Google's PaLM models |
| 2023-05-03 | [IBM/Dromedary](https://github.com/IBM/Dromedary) | ![IBM/Dromedary Stars](https://img.shields.io/github/stars/IBM/Dromedary.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-03 | [melodysdreamj/WizardVicunaLM](https://github.com/melodysdreamj/WizardVicunaLM) | ![melodysdreamj/WizardVicunaLM Stars](https://img.shields.io/github/stars/melodysdreamj/WizardVicunaLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | LLM that combines the principles of wizardLM and vicunaLM |
| 2023-04-28 | [openlm-research/open_llama](https://github.com/openlm-research/open_llama) | ![openlm-research/open_llama Stars](https://img.shields.io/github/stars/openlm-research/open_llama.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`å¯å•†ç”¨` | In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. |
| 2023-04-28 | [mosaicml/llm-foundry](https://github.com/mosaicml/llm-foundry) | ![mosaicml/llm-foundry Stars](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | LLM training code for MosaicML foundation models |
| 2023-04-28 | [replit/ReplitLM](https://github.com/replit/ReplitLM) | ![replit/ReplitLM Stars](https://img.shields.io/github/stars/replit/ReplitLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | Inference code and configs for the ReplitLM model family |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | ![dandelionsllm/pandallm Stars](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | ![open-mmlab/Multimodal-GPT Stars](https://img.shields.io/github/stars/open-mmlab/Multimodal-GPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | Multimodal-GPT |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | ![X-PLUG/mPLUG-Owl Stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-Owl.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | ![THUDM/VisualGLM-6B Stars](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | ![nlpxucan/WizardLM Stars](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions |
| 2023-04-23 | [mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | ![mbzuai-nlp/LaMini-LM Stars](https://img.shields.io/github/stars/mbzuai-nlp/LaMini-LM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | ![StevenGrove/GPT4Tools Stars](https://img.shields.io/github/stars/StevenGrove/GPT4Tools.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | ![RiseInRose/MiniGPT-4-ZH Stars](https://img.shields.io/github/stars/RiseInRose/MiniGPT-4-ZH.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©` | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | ![h2oai/h2o-llmstudio Stars](https://img.shields.io/github/stars/h2oai/h2o-llmstudio.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | ![Vision-CAIR/MiniGPT-4 Stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-10 | [declare-lab/tango](https://github.com/declare-lab/tango) | ![declare-lab/tango Stars](https://img.shields.io/github/stars/declare-lab/tango.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Codes and Model of the paper "Text-to-Audio Generation using Instruction Tuned LLM and Latent Diffusion Model" |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | ![FreedomIntelligence/LLMZoo Stars](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`æ–‡æ¡£` | âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | ![project-baize/baize-chatbot Stars](https://img.shields.io/github/stars/project-baize/baize-chatbot.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | ![LC1332/Chinese-alpaca-lora Stars](https://img.shields.io/github/stars/LC1332/Chinese-alpaca-lora.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | ![AGI-Edgerunners/LLM-Adapters Stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | ![OptimalScale/LMFlow Stars](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All. |
| 2023-03-24 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | ![h2oai/h2ogpt Stars](https://img.shields.io/github/stars/h2oai/h2ogpt.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | Come join the movement to make the world's best open source GPT led by H2O.ai - 100% private chat and document search, no data leaks, Apache 2.0 |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | ![Facico/Chinese-Vicuna Stars](https://img.shields.io/github/stars/Facico/Chinese-Vicuna.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | ![Lightning-AI/lit-llama Stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`å‹ç¼©`,`å¯å•†ç”¨` | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | ![LC1332/Luotuo-Chinese-LLM Stars](https://img.shields.io/github/stars/LC1332/Luotuo-Chinese-LLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`å¼ºåŒ–(TD)`,`å‹ç¼©`,`æ¨ç†`,`å¯å•†ç”¨`,`ä¸­æ–‡` | Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | ![lm-sys/FastChat Stars](https://img.shields.io/github/stars/lm-sys/FastChat.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | An open platform for training, serving, and evaluating large languages. Release repo for Vicuna and FastChat-T5. |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | ![LianjiaTech/BELLE Stars](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | ![THUDM/ChatGLM-6B Stars](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-03-13 | [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) | ![tloen/alpaca-lora Stars](https://img.shields.io/github/stars/tloen/alpaca-lora.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Instruct-tune LLaMA on consumer hardware |
| 2023-03-10 | [svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | ![svc-develop-team/so-vits-svc Stars](https://img.shields.io/github/stars/svc-develop-team/so-vits-svc.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | SoftVC VITS Singing Voice Conversion |
