| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-19 | [FlagAlpha/Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese) | 28 | 🔠⛽🚌2️⃣💰🀄 | 最好的中文Llama大模型，完全开源可商用 |
| 2023-07-16 | [magic-research/bubogpt](https://github.com/magic-research/bubogpt) | 58 | 🔠🖼️⛽🚌 | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-13 | [X-PLUG/CValues](https://github.com/X-PLUG/CValues) | 176 | 🔠⛽🀄❓ | 面向中文大模型价值观的评估与对齐研究 |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | 267 | 🔠🖼️⛽`🚌`2️⃣ | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [SpongebBob/Finetune-ChatGLM2-6B](https://github.com/SpongebBob/Finetune-ChatGLM2-6B) | 174 | 🔠⛽2️⃣✂️ | ChatGLM2-6B 全参数微调，支持多轮对话的高效微调。 |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 393 | 🖼️⛽🚌2️⃣ | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-29 | [IMOSR/MediaGPT](https://github.com/IMOSR/MediaGPT) | 406 | 🔠⛽🚕2️⃣🀄 | 中文的自媒体大语言模型MediaGPT(曾用名Media LLaMA) |
| 2023-06-26 | [icalk-nlp/EduChat](https://github.com/icalk-nlp/EduChat) | 164 | 🔠⛽🚕 | An open-source educational chat model from ICALK, East China Normal University. 开源中英教育对话大模型。(通用基座模型，GPU部署，数据清理) 致敬: LLaMA, MOSS, BELLE, Ziya |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | 3057 | 🖼️⛽🚌2️⃣ | Generative Models by Stability AI |
| 2023-06-16 | [haonan-li/CMMLU](https://github.com/haonan-li/CMMLU) | 132 | 🔠⛽🀄❓ | CMMLU是一个综合性的🀄评估基准，专门用于评估语言模型在🀄语境下的知识和💡能力。 |
| 2023-06-14 | [baichuan-inc/Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 4562 | 🔠⛽🚌🀄 | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | 1025 | 🔠⛽🚌2️⃣🀄 | 第一个开源的基于QLoRA的33B中文大语言模型First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [allenai/open-instruct](https://github.com/allenai/open-instruct) | 321 | 🔠⛽🚌2️⃣ | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-07 | [PKU-YuanGroup/ChatLaw](https://github.com/PKU-YuanGroup/ChatLaw) | 4228 | 🔠⛽🚕 | 中文法律大模型 |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | 924 | 🔠⛽🚕1️⃣2️⃣3️⃣🀄 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. 训练医疗大模型，实现包括二次预训练、有监督微调、奖励建模、强化学习训练。 |
| 2023-05-31 | [yuchenlin/LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | 445 | 🔠⛽🚌2️⃣ | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | 1156 | 🔠⛽🚌2️⃣📱🀄 | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-25 | [imoneoi/openchat](https://github.com/imoneoi/openchat) | 1378 | 🔠⛽🚌🚕2️⃣ | OpenChat: Less is More for Open-source Models |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | 118 | 🔠⛽🚌2️⃣ | SAIL: Search Augmented Instruction Learning |
| 2023-05-24 | [wenge-research/YaYi](https://github.com/wenge-research/YaYi) | 883 | 🔠⛽🚕2️⃣ | 雅意大模型：为每一家企业打造大模型 |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | 255 | 🔠⛽`🚌`2️⃣ | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 478 | 🔠🖼️⛽🚌 | 🩺 首个会看胸部X光片的中文多模态医学大模型 \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1096 | 🔠🖼️🎵⛽🚌2️⃣ | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-22 | [google-research-datasets/seahorse](https://github.com/google-research-datasets/seahorse) | 61 | 🔠⛽ | Seahorse is a dataset for multilingual, multi-faceted summarization evaluation. It consists of 96K summaries with human ratings along 6 quality dimensions: comprehensibility, repetition, grammar, attribution, main idea(s), and conciseness, covering 6 languages, 9 systems and 4 datasets. |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | 4581 | 🔠⛽🚌`2️⃣`🔨💰 | Gorilla: An API store for LLMs |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | 408 | 🔠🎥⛽🚌2️⃣ | "Video-ChatGPT" is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. We also introduce a rigorous 'Quantitative Evaluation Benchmarking' for video-based conversational models. |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | 316 | 🔠🖼️⛽🚕2️⃣ | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 426 | 🖼️`⛽`🚌`2️⃣` | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | 517 | 🔠🎵`⛽``🚌``2️⃣` | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | 556 | 🔠⛽🚌2️⃣ | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | 704 | 🔠⛽🚌2️⃣3️⃣ | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-12 | [SJTU-LIT/ceval](https://github.com/SJTU-LIT/ceval) | 842 | 🔠⛽ | Official github repo for C-Eval, a Chinese evaluation suite for foundation models |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | 1593 | 🔠⛽🚌1️⃣2️⃣ | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 388 | 🔠⛽🚌1️⃣2️⃣🀄 | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1092 | 🖼️⛽🚌2️⃣ | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | 825 | 🔠⛽🚌2️⃣ | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | 470 | 🔠⛽🚌2️⃣ | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-05-02 | [Docta-ai/docta](https://github.com/Docta-ai/docta) | 1184 | 🔠🖼️⛽ | A Doctor for your data |
| 2023-05-02 | [salesforce/CodeTF](https://github.com/salesforce/CodeTF) | 1288 | 🔠⛽🚕2️⃣ | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | 834 | 🔠⛽🚌🀄 | Panda: 海外中文开源大语言模型，基于 Llama-7B, -13B, -33B, -65B 进行中文领域上的持续预训练。 |
| 2023-04-28 | [mlfoundations/datacomp](https://github.com/mlfoundations/datacomp) | 356 | 🔠🖼️⛽ | DataComp: In search of the next generation of multimodal datasets |
| 2023-04-28 | [replit/ReplitLM](https://github.com/replit/ReplitLM) | 807 | 🔠⛽🚌 | Inference code and configs for the ReplitLM model family |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 261 | 🖼️⛽🚌2️⃣ | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1106 | 🔠🖼️⛽🚌 | Multimodal-GPT |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1195 | 🔠🖼️⛽🚌2️⃣ | mPLUG-Owl🦉: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [bigcode-project/starcoder](https://github.com/bigcode-project/starcoder) | 5781 | 🔠⛽🚕2️⃣ | Home of StarCoder: fine-tuning & inference! |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 530 | 🔠🖼️⛽🚌2️⃣ | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3014 | 🔠🖼️⛽🚌2️⃣✂️🀄 | Chinese and English multimodal conversational language model \| 多模态中英双语对话语言模型 |
| 2023-04-23 | [mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | 688 | 🔠⛽🚌 | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | 4143 | 🔠⛽🚌2️⃣ | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder |
| 2023-04-21 | [lvwzhen/law-cn-ai](https://github.com/lvwzhen/law-cn-ai) | 4330 | 🔠⛽📱🀄 | ⚖️ AI 法律助手 |
| 2023-04-21 | [voidful/awesome-chatgpt-dataset](https://github.com/voidful/awesome-chatgpt-dataset) | 464 | 🔠⛽📝 | Unlock the Power of LLM: Explore These Datasets to Train Your Own ChatGPT! |
| 2023-04-20 | [lamini-ai/lamini](https://github.com/lamini-ai/lamini) | 2005 | 🔠⛽ |  |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 4974 | 🔠⛽🚕2️⃣🀄 |  🎉 Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. 基于中文法律知识的大语言模型 |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 2286 | 🔠⛽🚌2️⃣💰 | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 3640 | 🔠🖼️⛽🚌1️⃣2️⃣ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | 11217 | 🔠⛽🚌✂️💰🀄 | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-14 | [togethercomputer/RedPajama-Data](https://github.com/togethercomputer/RedPajama-Data) | 3268 | 🔠⛽ | The RedPajama-Data repository contains code for preparing large datasets for training large language models. |
| 2023-04-13 | [FreedomIntelligence/HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT) | 532 | 🔠⛽🚕2️⃣ | HuatuoGPT, Towards Taming Language Models To Be a Doctor. (An Open Medical GPT) |
| 2023-04-13 | [openai/prm800k](https://github.com/openai/prm800k) | 895 | 🔠⛽ | 800,000 step-level correctness labels on LLM solutions to MATH problems |
| 2023-04-12 | [langgenius/dify](https://github.com/langgenius/dify) | 5533 | 🔠⛽2️⃣📱 | One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications. |
| 2023-04-10 | [GanjinZero/RRHF](https://github.com/GanjinZero/RRHF) | 596 | 🔠⛽🚌3️⃣ | RRHF & Wombat |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | 2356 | 🔠⛽2️⃣3️⃣🀄 | Fine-tuning ChatGLM-6B with PEFT \| 基于 PEFT 的高效 ChatGLM 微调 |
| 2023-04-06 | [Instruction-Tuning-with-GPT-4/GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | 3080 | 🔠⛽2️⃣ | Instruction Tuning with GPT-4 |
| 2023-04-03 | [thunlp/UltraChat](https://github.com/thunlp/UltraChat) | 1641 | 🔠⛽2️⃣ | Large-scale, Informative, and Diverse Multi-round Chat Data (and Models) |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | 1048 | 🔠⛽🚌2️⃣✂️🀄 | Firefly(流萤): 中文对话式大语言模型(全量微调+QLoRA) |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | 2495 | 🔠⛽🚌2️⃣✂️📝 | ⚡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.⚡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | 2150 | 🔠🖼️⛽🚌2️⃣ | 🦦 Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | 626 | 🔠⛽🚌🀄 | 骆驼:A Chinese finetuned instruction LLaMA. Developed by 陈启源 @ 华中师范大学 & 李鲁鲁 @ 商汤科技 & 冷子昂 @ 商汤科技 |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 3361 | 🔠⛽🚕2️⃣🀄 | Repo for BenTsao [original name: HuaTuo (华驼)], Llama-7B tuned with Chinese medical knowledge. 本草（原名：华驼）模型仓库，基于中文医学知识的LLaMA模型指令微调 |
| 2023-03-31 | [SCIR-HI/Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM) | 695 | 🔠⛽🚕2️⃣ | Repo for Chinese Medical ChatGLM 基于中文医学知识的ChatGLM指令微调 |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | 2948 | 🔠⛽🚌2️⃣ | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | 646 | 🔠⛽🚌2️⃣ | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-29 | [yaodongC/awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset) | 669 | 🔠⛽ | A collection of open-source dataset to train instruction-following LLMs (ChatGPT,LLaMA,Alpaca) |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | 6920 | 🔠⛽🚌2️⃣3️⃣ | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [PhoebusSi/Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT) | 1891 | 🔠⛽2️⃣ | We unified the interfaces of instruction-tuning data (e.g., CoT data), multiple LLMs and parameter-efficient methods (e.g., lora, p-tuning) together for easy use. Meanwhile, we created a new branch to build a Tabular LLM.（我们分别统一了丰富的IFT数据（如CoT数据，目前仍不断扩充）、多种训练效率方法（如lora，p-tuning）以及多种LLMs，三个层面上的接口，打造方便研究人员上手的LLM-IFT研究平台。同时tabular_llm分支构建了面向表格智能任务的LLM。 |
| 2023-03-24 | [databrickslabs/dolly](https://github.com/databrickslabs/dolly) | 10458 | 🔠⛽🚌2️⃣💰 | Databricks’ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-23 | [yanqiangmiffy/InstructGLM](https://github.com/yanqiangmiffy/InstructGLM) | 587 | 🔠⛽2️⃣ | ChatGLM-6B 指令学习\|指令数据\|Instruct |
| 2023-03-22 | [sahil280114/codealpaca](https://github.com/sahil280114/codealpaca) | 1167 | 🔠⛽2️⃣ | This is the repo for the Code Alpaca project, which aims to build and share an instruction-following LLaMA model for code generation. This repo is fully based on Stanford Alpaca ,and only changes the data used for training. Training approach is the same. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2315 | 🔠⛽🚌1️⃣2️⃣`3️⃣`✂️💡💰🀄 | Chinese-LLaMA 、Chinese-Falcon 基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 |
| 2023-03-21 | [Kent0n-Li/ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor) | 2986 | 🔠⛽🚕2️⃣ |  |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | 3116 | 🔠⛽🚌🀄 | 骆驼(Luotuo): Open Sourced Chinese Language Models. Developed by 陈启源 @ 华中师范大学 & 李鲁鲁 @ 商汤科技 & 冷子昂 @ 商汤科技 |
| 2023-03-21 | [gururise/AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) | 1173 | 🔠⛽ | Alpaca dataset from Stanford, cleaned and curated |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | 623 | 🎥⛽🚌2️⃣ | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4416 | 🔠🖼️⛽🚌2️⃣ | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | 1203 | 🔠⛽🚌2️⃣ | KoAlpaca: 한국어 명령어를 이해하는 오픈소스 언어모델 |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | 6247 | 🔠⛽🚌2️⃣✂️🀄 | BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型） |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | 883 | 🔠⛽2️⃣🀄 | 人工精调的中文对话数据集和一段chatglm的微调代码 |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | 763 | 🔠🎥⛽🚌2️⃣ | Pytorch Implementation for [ICCV 2023] "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-10 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | 25891 | 🔠⛽🚌2️⃣ | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-04 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | 903 | 🎵⛽🚌2️⃣ | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8681 | 🔠⛽🚌1️⃣2️⃣ |  |
| 2023-02-11 | [AI4Finance-Foundation/FinGPT](https://github.com/AI4Finance-Foundation/FinGPT) | 7203 | 🔠⛽🚕🀄 | Data-Centric FinGPT.  Open-source for open finance!  Revolutionize 🔥    We'll soon release the trained model. |
| 2023-01-23 | [openai/evals](https://github.com/openai/evals) | 11155 | 🔠⛽ | Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 4962 | 🖼️⛽🚌2️⃣ | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 22901 | 🔠⛽🚌1️⃣2️⃣ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-20 | [yizhongw/self-instruct](https://github.com/yizhongw/self-instruct) | 2794 | 🔠⛽ | Aligning pretrained language models with instruction data generated by themselves. |
| 2022-11-23 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | 27230 | 🖼️⛽🚌 | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2512 | 🔠🖼️`🎥`⛽🚌2️⃣ | An open-source framework for training large multimodal models. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | 2298 | 🎥⛽🚌2️⃣ | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 5975 | 🔠🖼️⛽🚌1️⃣2️⃣ | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | 57941 | 🖼️⛽🚌 | A latent text-to-image diffusion model |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | 2493 | 🖼️⛽🚌2️⃣ |  |
