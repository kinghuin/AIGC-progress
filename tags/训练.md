| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-08 | [Yujun-Shi/DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | ![Yujun-Shi/DragDiffusion Stars](https://img.shields.io/github/stars/Yujun-Shi/DragDiffusion.svg?label=&style=flat-square) | 🖼️🚌2️⃣ | Official code for DragDiffusion |
| 2023-07-08 | [taprosoft/llm_finetuning](https://github.com/taprosoft/llm_finetuning) | ![taprosoft/llm_finetuning Stars](https://img.shields.io/github/stars/taprosoft/llm_finetuning.svg?label=&style=flat-square) | 🔠2️⃣✂️ | Convenient wrapper for fine-tuning and inference of Large Language Models (LLMs) with several quantization techniques (GTPQ, bitsandbytes) |
| 2023-07-06 | [InternLM/InternLM](https://github.com/InternLM/InternLM) | ![InternLM/InternLM Stars](https://img.shields.io/github/stars/InternLM/InternLM.svg?label=&style=flat-square) | 🔠🚌2️⃣🀄 | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | ![jshilong/GPT4RoI Stars](https://img.shields.io/github/stars/jshilong/GPT4RoI.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣ | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [SpongebBob/Finetune-ChatGLM2-6B](https://github.com/SpongebBob/Finetune-ChatGLM2-6B) | ![SpongebBob/Finetune-ChatGLM2-6B Stars](https://img.shields.io/github/stars/SpongebBob/Finetune-ChatGLM2-6B.svg?label=&style=flat-square) | 🔠⛽2️⃣✂️ | ChatGLM2-6B 全参数微调，支持多轮对话的高效微调。 |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | ![zideliu/StyleDrop-PyTorch Stars](https://img.shields.io/github/stars/zideliu/StyleDrop-PyTorch.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | ![OpenBMB/VisCPM Stars](https://img.shields.io/github/stars/OpenBMB/VisCPM.svg?label=&style=flat-square) | 🔠🖼️🚌2️⃣🀄 | Chinese and English Multimodal Large Model Series (Chat and Paint) \| 基于CPM基础模型的中英双语多模态大模型系列 |
| 2023-06-29 | [IMOSR/Media-LLaMA](https://github.com/IMOSR/Media-LLaMA) | ![IMOSR/Media-LLaMA Stars](https://img.shields.io/github/stars/IMOSR/Media-LLaMA.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣🀄 | 中文的自媒体大语言模型 |
| 2023-06-28 | [gmltmd789/UnitSpeech](https://github.com/gmltmd789/UnitSpeech) | ![gmltmd789/UnitSpeech Stars](https://img.shields.io/github/stars/gmltmd789/UnitSpeech.svg?label=&style=flat-square) | 🎵🚌2️⃣ | An official implementation of "UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data" |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | ![Stability-AI/generative-models Stars](https://img.shields.io/github/stars/Stability-AI/generative-models.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | Generative Models by Stability AI |
| 2023-06-22 | [eric-mitchell/direct-preference-optimization](https://github.com/eric-mitchell/direct-preference-optimization) | ![eric-mitchell/direct-preference-optimization Stars](https://img.shields.io/github/stars/eric-mitchell/direct-preference-optimization.svg?label=&style=flat-square) | 🔠2️⃣3️⃣ | Reference implementation for DPO (Direct Preference Optimization) |
| 2023-06-19 | [beyondguo/LLM-Tuning](https://github.com/beyondguo/LLM-Tuning) | ![beyondguo/LLM-Tuning Stars](https://img.shields.io/github/stars/beyondguo/LLM-Tuning.svg?label=&style=flat-square) | 🔠2️⃣ | Tuning LLMs with no tears💦, sharing LLM-tools with love❤️. |
| 2023-06-16 | [SpeechifyInc/Meta-voicebox](https://github.com/SpeechifyInc/Meta-voicebox) | ![SpeechifyInc/Meta-voicebox Stars](https://img.shields.io/github/stars/SpeechifyInc/Meta-voicebox.svg?label=&style=flat-square) | 🎵2️⃣ | Implementation of Meta-Voicebox : The first generative AI model for speech to generalize across tasks with state-of-the-art performance. |
| 2023-06-13 | [SizheAn/PanoHead](https://github.com/SizheAn/PanoHead) | ![SizheAn/PanoHead Stars](https://img.shields.io/github/stars/SizheAn/PanoHead.svg?label=&style=flat-square) | 🖼️🚌2️⃣🧊 | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | ![lyogavin/Anima Stars](https://img.shields.io/github/stars/lyogavin/Anima.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣🀄 | 第一个开源的基于QLoRA的33B中文大语言模型First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [allenai/open-instruct](https://github.com/allenai/open-instruct) | ![allenai/open-instruct Stars](https://img.shields.io/github/stars/allenai/open-instruct.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-08 | [facebookresearch/audiocraft](https://github.com/facebookresearch/audiocraft) | ![facebookresearch/audiocraft Stars](https://img.shields.io/github/stars/facebookresearch/audiocraft.svg?label=&style=flat-square) | 🎵🚌2️⃣ | Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
| 2023-06-05 | [BrandonHanx/HeadSculpt](https://github.com/BrandonHanx/HeadSculpt) | ![BrandonHanx/HeadSculpt Stars](https://img.shields.io/github/stars/BrandonHanx/HeadSculpt.svg?label=&style=flat-square) | 🔠2️⃣🧊 | [arXiv 2023 WIP] HeadSculpt: Crafting 3D Head Avatars with Text |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | ![shibing624/MedicalGPT Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT.svg?label=&style=flat-square) | 🔠⛽🚕1️⃣2️⃣3️⃣🀄 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. 训练医疗大模型，实现包括二次预训练、有监督微调、奖励建模、强化学习训练。 |
| 2023-05-31 | [yuchenlin/LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | ![yuchenlin/LLM-Blender Stars](https://img.shields.io/github/stars/yuchenlin/LLM-Blender.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | ![THUDM/WebGLM Stars](https://img.shields.io/github/stars/THUDM/WebGLM.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣📱🀄 | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-28 | [hiyouga/LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) | ![hiyouga/LLaMA-Efficient-Tuning Stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Efficient-Tuning.svg?label=&style=flat-square) | 🔠1️⃣2️⃣3️⃣ | Easy-to-use fine-tuning framework using PEFT (PT+SFT+RLHF with QLoRA) |
| 2023-05-25 | [imoneoi/openchat](https://github.com/imoneoi/openchat) | ![imoneoi/openchat Stars](https://img.shields.io/github/stars/imoneoi/openchat.svg?label=&style=flat-square) | 🔠⛽🚌🚕2️⃣ | OpenChat: Less is More for Open-source Models |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | ![luohongyin/SAIL Stars](https://img.shields.io/github/stars/luohongyin/SAIL.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | SAIL: Search Augmented Instruction Learning |
| 2023-05-24 | [wenge-research/YaYi](https://github.com/wenge-research/YaYi) | ![wenge-research/YaYi Stars](https://img.shields.io/github/stars/wenge-research/YaYi.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ | 雅意大模型：为每一家企业打造大模型 |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | ![OFA-Sys/ExpertLLaMA Stars](https://img.shields.io/github/stars/OFA-Sys/ExpertLLaMA.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | ![lyuchenyang/Macaw-LLM Stars](https://img.shields.io/github/stars/lyuchenyang/Macaw-LLM.svg?label=&style=flat-square) | 🔠🖼️🎵⛽🚌2️⃣ | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | ![ShishirPatil/gorilla Stars](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣🔨✅ | Gorilla: An API store for LLMs |
| 2023-05-19 | [YuanGongND/ltu](https://github.com/YuanGongND/ltu) | ![YuanGongND/ltu Stars](https://img.shields.io/github/stars/YuanGongND/ltu.svg?label=&style=flat-square) | 🔠🎵2️⃣ | Github Repo for Paper "Listen, Think, and Understand". |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | ![OFA-Sys/ONE-PEACE Stars](https://img.shields.io/github/stars/OFA-Sys/ONE-PEACE.svg?label=&style=flat-square) | 🖼️🚌1️⃣2️⃣ | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | ![OpenGVLab/VisionLLM Stars](https://img.shields.io/github/stars/OpenGVLab/VisionLLM.svg?label=&style=flat-square) | 🖼️🚌2️⃣ | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | ![mbzuai-oryx/Video-ChatGPT Stars](https://img.shields.io/github/stars/mbzuai-oryx/Video-ChatGPT.svg?label=&style=flat-square) | 🔠🎥⛽🚌2️⃣ | Video-ChatGPT is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | ![mbzuai-oryx/XrayGPT Stars](https://img.shields.io/github/stars/mbzuai-oryx/XrayGPT.svg?label=&style=flat-square) | 🔠🖼️⛽🚕2️⃣ | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-18 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | ![yxuansu/PandaGPT Stars](https://img.shields.io/github/stars/yxuansu/PandaGPT.svg?label=&style=flat-square) | 🔠🖼️🚌2️⃣ | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [lucidrains/soundstorm-pytorch](https://github.com/lucidrains/soundstorm-pytorch) | ![lucidrains/soundstorm-pytorch Stars](https://img.shields.io/github/stars/lucidrains/soundstorm-pytorch.svg?label=&style=flat-square) | 🎵2️⃣ | Implementation of SoundStorm, Efficient Parallel Audio Generation from Google Deepmind, in Pytorch |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | ![mit-han-lab/fastcomposer Stars](https://img.shields.io/github/stars/mit-han-lab/fastcomposer.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-17 | [princeton-nlp/tree-of-thought-llm](https://github.com/princeton-nlp/tree-of-thought-llm) | ![princeton-nlp/tree-of-thought-llm Stars](https://img.shields.io/github/stars/princeton-nlp/tree-of-thought-llm.svg?label=&style=flat-square) | 🔠2️⃣ | Official Implementation of "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | ![0nutation/SpeechGPT Stars](https://img.shields.io/github/stars/0nutation/SpeechGPT.svg?label=&style=flat-square) | 🔠🎵⛽🚌2️⃣ | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | ![sambanova/bloomchat Stars](https://img.shields.io/github/stars/sambanova/bloomchat.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | ![PKU-Alignment/safe-rlhf Stars](https://img.shields.io/github/stars/PKU-Alignment/safe-rlhf.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣3️⃣ | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-13 | [HeliosZhao/Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | ![HeliosZhao/Make-A-Protagonist Stars](https://img.shields.io/github/stars/HeliosZhao/Make-A-Protagonist.svg?label=&style=flat-square) | 🎥🚌2️⃣ | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | ![TigerResearch/TigerBot Stars](https://img.shields.io/github/stars/TigerResearch/TigerBot.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣ | TigerBot: A multi-language multi-task LLM |
| 2023-05-11 | [artidoro/qlora](https://github.com/artidoro/qlora) | ![artidoro/qlora Stars](https://img.shields.io/github/stars/artidoro/qlora.svg?label=&style=flat-square) | 🔠2️⃣✂️ | QLoRA: Efficient Finetuning of Quantized LLMs |
| 2023-05-11 | [kuleshov-group/llmtune](https://github.com/kuleshov-group/llmtune) | ![kuleshov-group/llmtune Stars](https://img.shields.io/github/stars/kuleshov-group/llmtune.svg?label=&style=flat-square) | 🔠2️⃣ | 4-Bit Finetuning of Large Language Models on One Consumer GPU |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | ![Neutralzz/BiLLa Stars](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣🀄 | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-07 | [conceptofmind/PaLM](https://github.com/conceptofmind/PaLM) | ![conceptofmind/PaLM Stars](https://img.shields.io/github/stars/conceptofmind/PaLM.svg?label=&style=flat-square) | 🔠🚌2️⃣ | An open-source implementation of Google's PaLM models |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | ![DAMO-NLP-SG/Video-LLaMA Stars](https://img.shields.io/github/stars/DAMO-NLP-SG/Video-LLaMA.svg?label=&style=flat-square) | 🔠🎥🚌1️⃣2️⃣ | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | ![Lightning-AI/lit-gpt Stars](https://img.shields.io/github/stars/Lightning-AI/lit-gpt.svg?label=&style=flat-square) | 🔠🖼️🚌1️⃣2️⃣ | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | ![ZrrSkywalker/Personalize-SAM Stars](https://img.shields.io/github/stars/ZrrSkywalker/Personalize-SAM.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | ![thunlp/WebCPM Stars](https://img.shields.io/github/stars/thunlp/WebCPM.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [IBM/Dromedary](https://github.com/IBM/Dromedary) | ![IBM/Dromedary Stars](https://img.shields.io/github/stars/IBM/Dromedary.svg?label=&style=flat-square) | 🔠🚌2️⃣ | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-03 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | ![tatsu-lab/alpaca_farm Stars](https://img.shields.io/github/stars/tatsu-lab/alpaca_farm.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-05-02 | [salesforce/CodeTF](https://github.com/salesforce/CodeTF) | ![salesforce/CodeTF Stars](https://img.shields.io/github/stars/salesforce/CodeTF.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM |
| 2023-04-28 | [mosaicml/llm-foundry](https://github.com/mosaicml/llm-foundry) | ![mosaicml/llm-foundry Stars](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?label=&style=flat-square) | 🔠🚌2️⃣ | LLM training code for MosaicML foundation models |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | ![Zhendong-Wang/Prompt-Diffusion Stars](https://img.shields.io/github/stars/Zhendong-Wang/Prompt-Diffusion.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [mosaicml/diffusion](https://github.com/mosaicml/diffusion) | ![mosaicml/diffusion Stars](https://img.shields.io/github/stars/mosaicml/diffusion.svg?label=&style=flat-square) | 🖼️2️⃣ | This repo contains code used to train your own Stable Diffusion model on your own data. |
| 2023-04-25 | [HugAILab/HugNLP](https://github.com/HugAILab/HugNLP) | ![HugAILab/HugNLP Stars](https://img.shields.io/github/stars/HugAILab/HugNLP.svg?label=&style=flat-square) | 🔠2️⃣ | HugNLP is a unified and comprehensive NLP library based on HuggingFace Transformer. Please hugging for NLP now!😊 |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | ![X-PLUG/mPLUG-Owl Stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-Owl.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣ | mPLUG-Owl🦉: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [bigcode-project/starcoder](https://github.com/bigcode-project/starcoder) | ![bigcode-project/starcoder Stars](https://img.shields.io/github/stars/bigcode-project/starcoder.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ | Home of StarCoder: fine-tuning & inference! |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | ![StevenGrove/GPT4Tools Stars](https://img.shields.io/github/stars/StevenGrove/GPT4Tools.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣ | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | ![THUDM/VisualGLM-6B Stars](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣✂️🀄 | Chinese and English multimodal conversational language model \| 多模态中英双语对话语言模型 |
| 2023-04-23 | [minosvasilias/godot-dodo](https://github.com/minosvasilias/godot-dodo) | ![minosvasilias/godot-dodo Stars](https://img.shields.io/github/stars/minosvasilias/godot-dodo.svg?label=&style=flat-square) | 🔠🚕2️⃣ | Finetuning large language models for GDScript generation. |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | ![nlpxucan/WizardLM Stars](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | ![pengxiao-song/LaWGPT Stars](https://img.shields.io/github/stars/pengxiao-song/LaWGPT.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣🀄 |  🎉 Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. 基于中文法律知识的大语言模型 |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | ![RiseInRose/MiniGPT-4-ZH Stars](https://img.shields.io/github/stars/RiseInRose/MiniGPT-4-ZH.svg?label=&style=flat-square) | 🔠🖼️🚌2️⃣✂️ | MiniGPT-4 中文部署翻译 完善部署细节 |
| 2023-04-19 | [lucidrains/naturalspeech2-pytorch](https://github.com/lucidrains/naturalspeech2-pytorch) | ![lucidrains/naturalspeech2-pytorch Stars](https://img.shields.io/github/stars/lucidrains/naturalspeech2-pytorch.svg?label=&style=flat-square) | 🎵2️⃣ | Implementation of Natural Speech 2, Zero-shot Speech and Singing Synthesizer, in Pytorch |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | ![h2oai/h2o-llmstudio Stars](https://img.shields.io/github/stars/h2oai/h2o-llmstudio.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✅ | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | ![haotian-liu/LLaVA Stars](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?label=&style=flat-square) | 🔠🖼️⛽🚌1️⃣2️⃣ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | ![Vision-CAIR/MiniGPT-4 Stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4.svg?label=&style=flat-square) | 🔠🖼️🚌1️⃣2️⃣ | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-13 | [FreedomIntelligence/HuatuoGPT](https://github.com/FreedomIntelligence/HuatuoGPT) | ![FreedomIntelligence/HuatuoGPT Stars](https://img.shields.io/github/stars/FreedomIntelligence/HuatuoGPT.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ | HuatuoGPT, Towards Taming Language Models To Be a Doctor. (An Open Medical GPT) |
| 2023-04-12 | [langgenius/dify](https://github.com/langgenius/dify) | ![langgenius/dify Stars](https://img.shields.io/github/stars/langgenius/dify.svg?label=&style=flat-square) | 🔠⛽2️⃣📱 | One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications. |
| 2023-04-10 | [declare-lab/tango](https://github.com/declare-lab/tango) | ![declare-lab/tango Stars](https://img.shields.io/github/stars/declare-lab/tango.svg?label=&style=flat-square) | 🔠🎵🚌2️⃣ | Codes and Model of the paper "Text-to-Audio Generation using Instruction Tuned LLM and Latent Diffusion Model" |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | ![hiyouga/ChatGLM-Efficient-Tuning Stars](https://img.shields.io/github/stars/hiyouga/ChatGLM-Efficient-Tuning.svg?label=&style=flat-square) | 🔠⛽2️⃣3️⃣🀄 | Fine-tuning ChatGLM-6B with PEFT \| 基于 PEFT 的高效 ChatGLM 微调 |
| 2023-04-06 | [Instruction-Tuning-with-GPT-4/GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | ![Instruction-Tuning-with-GPT-4/GPT-4-LLM Stars](https://img.shields.io/github/stars/Instruction-Tuning-with-GPT-4/GPT-4-LLM.svg?label=&style=flat-square) | 🔠⛽2️⃣ | Instruction Tuning with GPT-4 |
| 2023-04-06 | [liucongg/ChatGLM-Finetuning](https://github.com/liucongg/ChatGLM-Finetuning) | ![liucongg/ChatGLM-Finetuning Stars](https://img.shields.io/github/stars/liucongg/ChatGLM-Finetuning.svg?label=&style=flat-square) | 🔠2️⃣🀄 | 基于ChatGLM-6B模型，进行下游具体任务微调，涉及Freeze、Lora、P-tuning等 |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | ![threestudio-project/threestudio Stars](https://img.shields.io/github/stars/threestudio-project/threestudio.svg?label=&style=flat-square) | 🖼️🚌2️⃣🧊 | A unified framework for 3D content generation. |
| 2023-04-03 | [VideoCrafter/VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | ![VideoCrafter/VideoCrafter Stars](https://img.shields.io/github/stars/VideoCrafter/VideoCrafter.svg?label=&style=flat-square) | 🔠🎥🚌2️⃣ | A Toolkit for Text-to-Video Generation and Editing |
| 2023-04-03 | [thunlp/UltraChat](https://github.com/thunlp/UltraChat) | ![thunlp/UltraChat Stars](https://img.shields.io/github/stars/thunlp/UltraChat.svg?label=&style=flat-square) | 🔠⛽2️⃣ | Large-scale, Informative, and Diverse Multi-round Chat Data (and Models) |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | ![yangjianxin1/Firefly Stars](https://img.shields.io/github/stars/yangjianxin1/Firefly.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✂️🀄 | Firefly(流萤): 中文对话式大语言模型(全量微调+QLoRA) |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | ![FreedomIntelligence/LLMZoo Stars](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✂️📝 | ⚡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.⚡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | ![Luodian/Otter Stars](https://img.shields.io/github/stars/Luodian/Otter.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣ | 🦦 Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | ![SCIR-HI/Huatuo-Llama-Med-Chinese Stars](https://img.shields.io/github/stars/SCIR-HI/Huatuo-Llama-Med-Chinese.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣🀄 | Repo for BenTsao [original name: HuaTuo (华驼)], Llama-7B tuned with Chinese medical knowledge. 本草（原名：华驼）模型仓库，基于中文医学知识的LLaMA模型指令微调 |
| 2023-03-31 | [SCIR-HI/Med-ChatGLM](https://github.com/SCIR-HI/Med-ChatGLM) | ![SCIR-HI/Med-ChatGLM Stars](https://img.shields.io/github/stars/SCIR-HI/Med-ChatGLM.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ | Repo for Chinese Medical ChatGLM 基于中文医学知识的ChatGLM指令微调 |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | ![project-baize/baize-chatbot Stars](https://img.shields.io/github/stars/project-baize/baize-chatbot.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-30 | [AetherCortex/Llama-X](https://github.com/AetherCortex/Llama-X) | ![AetherCortex/Llama-X Stars](https://img.shields.io/github/stars/AetherCortex/Llama-X.svg?label=&style=flat-square) | 🔠🚌2️⃣ | Open Academic Research on Improving LLaMA to SOTA LLM |
| 2023-03-30 | [mayuelala/FollowYourPose](https://github.com/mayuelala/FollowYourPose) | ![mayuelala/FollowYourPose Stars](https://img.shields.io/github/stars/mayuelala/FollowYourPose.svg?label=&style=flat-square) | 🎥🚌2️⃣ | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | ![AGI-Edgerunners/LLM-Adapters Stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-28 | [WangRongsheng/ChatGenTitle](https://github.com/WangRongsheng/ChatGenTitle) | ![WangRongsheng/ChatGenTitle Stars](https://img.shields.io/github/stars/WangRongsheng/ChatGenTitle.svg?label=&style=flat-square) | 🔠🚕2️⃣ | 🌟 ChatGenTitle：使用百万arXiv论文信息在LLaMA模型上进行微调的论文题目生成模型 |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | ![OptimalScale/LMFlow Stars](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣3️⃣ | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [PhoebusSi/Alpaca-CoT](https://github.com/PhoebusSi/Alpaca-CoT) | ![PhoebusSi/Alpaca-CoT Stars](https://img.shields.io/github/stars/PhoebusSi/Alpaca-CoT.svg?label=&style=flat-square) | 🔠⛽2️⃣ | We unified the interfaces of instruction-tuning data (e.g., CoT data), multiple LLMs and parameter-efficient methods (e.g., lora, p-tuning) together for easy use. Meanwhile, we created a new branch to build a Tabular LLM.（我们分别统一了丰富的IFT数据（如CoT数据，目前仍不断扩充）、多种训练效率方法（如lora，p-tuning）以及多种LLMs，三个层面上的接口，打造方便研究人员上手的LLM-IFT研究平台。同时tabular_llm分支构建了面向表格智能任务的LLM。 |
| 2023-03-24 | [databrickslabs/dolly](https://github.com/databrickslabs/dolly) | ![databrickslabs/dolly Stars](https://img.shields.io/github/stars/databrickslabs/dolly.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✅ | Databricks’ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-24 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | ![h2oai/h2ogpt Stars](https://img.shields.io/github/stars/h2oai/h2ogpt.svg?label=&style=flat-square) | 🔠🚌2️⃣✅ | Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0 https://arxiv.org/pdf/2306.08161.pdf   Live Demo: https://gpt.h2o.ai/ |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | ![Facico/Chinese-Vicuna Stars](https://img.shields.io/github/stars/Facico/Chinese-Vicuna.svg?label=&style=flat-square) | 🔠🚌2️⃣✂️🀄 | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca |
| 2023-03-23 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | ![junshutang/Make-It-3D Stars](https://img.shields.io/github/stars/junshutang/Make-It-3D.svg?label=&style=flat-square) | 🖼️🚌2️⃣🧊 | Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-23 | [yanqiangmiffy/InstructGLM](https://github.com/yanqiangmiffy/InstructGLM) | ![yanqiangmiffy/InstructGLM Stars](https://img.shields.io/github/stars/yanqiangmiffy/InstructGLM.svg?label=&style=flat-square) | 🔠⛽2️⃣ | ChatGLM-6B 指令学习\|指令数据\|Instruct |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | ![Lightning-AI/lit-llama Stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama.svg?label=&style=flat-square) | 🔠🚌1️⃣2️⃣✂️✅ | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-22 | [sahil280114/codealpaca](https://github.com/sahil280114/codealpaca) | ![sahil280114/codealpaca Stars](https://img.shields.io/github/stars/sahil280114/codealpaca.svg?label=&style=flat-square) | 🔠⛽2️⃣ | This is the repo for the Code Alpaca project, which aims to build and share an instruction-following LLaMA model for code generation. This repo is fully based on Stanford Alpaca ,and only changes the data used for training. Training approach is the same. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣3️⃣✂️💡✅🀄 | Chinese-LLaMA 、Chinese-Falcon 基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 |
| 2023-03-21 | [Kent0n-Li/ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor) | ![Kent0n-Li/ChatDoctor Stars](https://img.shields.io/github/stars/Kent0n-Li/ChatDoctor.svg?label=&style=flat-square) | 🔠⛽🚕2️⃣ |  |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | ![johannakarras/DreamPose Stars](https://img.shields.io/github/stars/johannakarras/DreamPose.svg?label=&style=flat-square) | 🎥⛽🚌2️⃣ | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | ![OpenGVLab/LLaMA-Adapter Stars](https://img.shields.io/github/stars/OpenGVLab/LLaMA-Adapter.svg?label=&style=flat-square) | 🔠🖼️⛽🚌2️⃣ | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | ![lm-sys/FastChat Stars](https://img.shields.io/github/stars/lm-sys/FastChat.svg?label=&style=flat-square) | 🔠🚌2️⃣✅ | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5. |
| 2023-03-19 | [stochasticai/xTuring](https://github.com/stochasticai/xTuring) | ![stochasticai/xTuring Stars](https://img.shields.io/github/stars/stochasticai/xTuring.svg?label=&style=flat-square) | 🔠2️⃣ | Easily build, customize and control your own LLMs |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | ![Beomi/KoAlpaca Stars](https://img.shields.io/github/stars/Beomi/KoAlpaca.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | KoAlpaca: 한국어 명령어를 이해하는 오픈소스 언어모델 |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | ![LianjiaTech/BELLE Stars](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✂️🀄 | BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型） |
| 2023-03-17 | [cvlab-columbia/zero123](https://github.com/cvlab-columbia/zero123) | ![cvlab-columbia/zero123 Stars](https://img.shields.io/github/stars/cvlab-columbia/zero123.svg?label=&style=flat-square) | 🖼️2️⃣🧊 | Zero-1-to-3: Zero-shot One Image to 3D Object: https://zero123.cs.columbia.edu/ |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | ![hikariming/alpaca_chinese_dataset Stars](https://img.shields.io/github/stars/hikariming/alpaca_chinese_dataset.svg?label=&style=flat-square) | 🔠⛽2️⃣🀄 | 人工精调的中文对话数据集和一段chatglm的微调代码 |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | ![ChenyangQiQi/FateZero Stars](https://img.shields.io/github/stars/ChenyangQiQi/FateZero.svg?label=&style=flat-square) | 🔠🎥⛽🚌2️⃣ | Pytorch Implementation for "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-16 | [lich99/ChatGLM-finetune-LoRA](https://github.com/lich99/ChatGLM-finetune-LoRA) | ![lich99/ChatGLM-finetune-LoRA Stars](https://img.shields.io/github/stars/lich99/ChatGLM-finetune-LoRA.svg?label=&style=flat-square) | 🔠2️⃣ | Code for fintune ChatGLM-6b using low-rank adaptation (LoRA) |
| 2023-03-16 | [mymusise/ChatGLM-Tuning](https://github.com/mymusise/ChatGLM-Tuning) | ![mymusise/ChatGLM-Tuning Stars](https://img.shields.io/github/stars/mymusise/ChatGLM-Tuning.svg?label=&style=flat-square) | 🔠2️⃣🀄 | 一种平价的chatgpt实现方案,  基于ChatGLM-6B + LoRA |
| 2023-03-15 | [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | ![voicepaw/so-vits-svc-fork Stars](https://img.shields.io/github/stars/voicepaw/so-vits-svc-fork.svg?label=&style=flat-square) | 🎵🚌2️⃣ | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | ![ymcui/Chinese-LLaMA-Alpaca Stars](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?label=&style=flat-square) | 🔠1️⃣2️⃣✂️💡🀄 | 中文LLaMA&Alpaca大语言模型+本地CPU/GPU训练部署 (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-14 | [ssbuild/chatglm_finetuning](https://github.com/ssbuild/chatglm_finetuning) | ![ssbuild/chatglm_finetuning Stars](https://img.shields.io/github/stars/ssbuild/chatglm_finetuning.svg?label=&style=flat-square) | 🔠2️⃣🀄 | chatglm 6b finetuning and alpaca finetuning |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | ![THUDM/ChatGLM-6B Stars](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg?label=&style=flat-square) | 🔠🚌2️⃣✂️🀄 | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| 开源双语对话语言模型 |
| 2023-03-13 | [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) | ![tloen/alpaca-lora Stars](https://img.shields.io/github/stars/tloen/alpaca-lora.svg?label=&style=flat-square) | 🔠🚌2️⃣ | Instruct-tune LLaMA on consumer hardware |
| 2023-03-10 | [svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | ![svc-develop-team/so-vits-svc Stars](https://img.shields.io/github/stars/svc-develop-team/so-vits-svc.svg?label=&style=flat-square) | 🎵🚌2️⃣ | SoftVC VITS Singing Voice Conversion |
| 2023-03-10 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | ![tatsu-lab/stanford_alpaca Stars](https://img.shields.io/github/stars/tatsu-lab/stanford_alpaca.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣ | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | ![IDEA-Research/GroundingDINO Stars](https://img.shields.io/github/stars/IDEA-Research/GroundingDINO.svg?label=&style=flat-square) | 🔠🖼️🚌2️⃣ | The official implementation of "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-04 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | ![yxlllc/DDSP-SVC Stars](https://img.shields.io/github/stars/yxlllc/DDSP-SVC.svg?label=&style=flat-square) | 🎵⛽🚌2️⃣ | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | ![togethercomputer/OpenChatKit Stars](https://img.shields.io/github/stars/togethercomputer/OpenChatKit.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣ |  |
| 2023-02-26 | [openai/consistency_models](https://github.com/openai/consistency_models) | ![openai/consistency_models Stars](https://img.shields.io/github/stars/openai/consistency_models.svg?label=&style=flat-square) | 🖼️🚌2️⃣✂️ | Official repo for consistency models. |
| 2023-02-11 | [Plachtaa/VITS-fast-fine-tuning](https://github.com/Plachtaa/VITS-fast-fine-tuning) | ![Plachtaa/VITS-fast-fine-tuning Stars](https://img.shields.io/github/stars/Plachtaa/VITS-fast-fine-tuning.svg?label=&style=flat-square) | 🎵2️⃣ | This repo is a pipeline of VITS finetuning for fast speaker adaptation TTS, and many-to-many voice conversion |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | ![lllyasviel/ControlNet Stars](https://img.shields.io/github/stars/lllyasviel/ControlNet.svg?label=&style=flat-square) | 🖼️🚌2️⃣ | Let us control diffusion models! |
| 2023-01-27 | [lucidrains/musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | ![lucidrains/musiclm-pytorch Stars](https://img.shields.io/github/stars/lucidrains/musiclm-pytorch.svg?label=&style=flat-square) | 🎵🚌2️⃣✂️ | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | ![timothybrooks/instruct-pix2pix Stars](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | ![karpathy/nanoGPT Stars](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-08 | [cloneofsimo/lora](https://github.com/cloneofsimo/lora) | ![cloneofsimo/lora Stars](https://img.shields.io/github/stars/cloneofsimo/lora.svg?label=&style=flat-square) | 🖼️2️⃣ | Using Low-rank adaptation to quickly fine-tune diffusion models. |
| 2022-11-25 | [huggingface/peft](https://github.com/huggingface/peft) | ![huggingface/peft Stars](https://img.shields.io/github/stars/huggingface/peft.svg?label=&style=flat-square) | 🔠2️⃣ | 🤗 PEFT: State-of-the-art Parameter-Efficient Fine-Tuning. |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | ![OpenTalker/SadTalker Stars](https://img.shields.io/github/stars/OpenTalker/SadTalker.svg?label=&style=flat-square) | 🖼️🎵🎥🚌2️⃣ | [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-10-22 | [prophesier/diff-svc](https://github.com/prophesier/diff-svc) | ![prophesier/diff-svc Stars](https://img.shields.io/github/stars/prophesier/diff-svc.svg?label=&style=flat-square) | 🎵🚌2️⃣ | Singing Voice Conversion via diffusion model |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | ![mlfoundations/open_flamingo Stars](https://img.shields.io/github/stars/mlfoundations/open_flamingo.svg?label=&style=flat-square) | 🔠🖼️🎥⛽🚌2️⃣ | An open-source framework for training large multimodal models. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | ![GuyTevet/motion-diffusion-model Stars](https://img.shields.io/github/stars/GuyTevet/motion-diffusion-model.svg?label=&style=flat-square) | 🎥⛽🚌2️⃣ | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-09 | [williamyang1991/VToonify](https://github.com/williamyang1991/VToonify) | ![williamyang1991/VToonify Stars](https://img.shields.io/github/stars/williamyang1991/VToonify.svg?label=&style=flat-square) | 🎥🚌2️⃣ | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-09-06 | [XavierXiao/Dreambooth-Stable-Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) | ![XavierXiao/Dreambooth-Stable-Diffusion Stars](https://img.shields.io/github/stars/XavierXiao/Dreambooth-Stable-Diffusion.svg?label=&style=flat-square) | 🖼️2️⃣ | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | ![salesforce/LAVIS Stars](https://img.shields.io/github/stars/salesforce/LAVIS.svg?label=&style=flat-square) | 🔠🖼️⛽🚌1️⃣2️⃣ | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | ![rinongal/textual_inversion Stars](https://img.shields.io/github/stars/rinongal/textual_inversion.svg?label=&style=flat-square) | 🖼️⛽🚌2️⃣ |  |
| 2022-07-25 | [modelscope/modelscope](https://github.com/modelscope/modelscope) | ![modelscope/modelscope Stars](https://img.shields.io/github/stars/modelscope/modelscope.svg?label=&style=flat-square) | 🔠🖼️🎵2️⃣ | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-05-30 | [huggingface/diffusers](https://github.com/huggingface/diffusers) | ![huggingface/diffusers Stars](https://img.shields.io/github/stars/huggingface/diffusers.svg?label=&style=flat-square) | 🖼️🎵2️⃣📝 | 🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
