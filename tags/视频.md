| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-05-22 | [cg1177/VideoLLM](https://github.com/cg1177/VideoLLM) | ![cg1177/VideoLLM Stars](https://img.shields.io/github/stars/cg1177/VideoLLM.svg?label=&style=flat-square) | ğŸ¥ğŸ“ | VideoLLM: Modeling Video Sequence with Large Language Models |
| 2023-05-22 | [YBYBZhang/ControlVideo](https://github.com/YBYBZhang/ControlVideo) | ![YBYBZhang/ControlVideo Stars](https://img.shields.io/github/stars/YBYBZhang/ControlVideo.svg?label=&style=flat-square) | ğŸ¥ğŸ“± | Official pytorch implementation of "ControlVideo: Training-free Controllable Text-to-Video Generation" |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | ![mbzuai-oryx/Video-ChatGPT Stars](https://img.shields.io/github/stars/mbzuai-oryx/Video-ChatGPT.svg?label=&style=flat-square) | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Video-ChatGPT is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. |
| 2023-05-17 | [simoninithomas/awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | ![simoninithomas/awesome-ai-tools-for-game-dev Stars](https://img.shields.io/github/stars/simoninithomas/awesome-ai-tools-for-game-dev.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | A curated list of awesome AI tools for game developers |
| 2023-05-13 | [HeliosZhao/Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | ![HeliosZhao/Make-A-Protagonist Stars](https://img.shields.io/github/stars/HeliosZhao/Make-A-Protagonist.svg?label=&style=flat-square) | ğŸ¥ğŸšŒ2ï¸âƒ£ | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | ![DAMO-NLP-SG/Video-LLaMA Stars](https://img.shields.io/github/stars/DAMO-NLP-SG/Video-LLaMA.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-05 | [SCUTlihaoyu/open-chat-video-editor](https://github.com/SCUTlihaoyu/open-chat-video-editor) | ![SCUTlihaoyu/open-chat-video-editor Stars](https://img.shields.io/github/stars/SCUTlihaoyu/open-chat-video-editor.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸ“± | Open source short video automatic generation tool |
| 2023-05-02 | [kaleido-lab/dolphin](https://github.com/kaleido-lab/dolphin) | ![kaleido-lab/dolphin Stars](https://img.shields.io/github/stars/kaleido-lab/dolphin.svg?label=&style=flat-square) | ğŸ¥ğŸ“± | General video interaction platform based on LLMs, including Video ChatGPT |
| 2023-04-20 | [showlab/VLog](https://github.com/showlab/VLog) | ![showlab/VLog Stars](https://img.shields.io/github/stars/showlab/VLog.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸ“± | Transform Video as a Document with ChatGPT, CLIP, BLIP2, GRIT, Whisper, LangChain. |
| 2023-04-19 | [OpenGVLab/Ask-Anything](https://github.com/OpenGVLab/Ask-Anything) | ![OpenGVLab/Ask-Anything Stars](https://img.shields.io/github/stars/OpenGVLab/Ask-Anything.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸ“± | [VideoChatGPT] ChatGPT with video understanding! And many more supported LMs such as miniGPT4, StableLM, and MOSS. |
| 2023-04-09 | [geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | ![geekyutao/Inpaint-Anything Stars](https://img.shields.io/github/stars/geekyutao/Inpaint-Anything.svg?label=&style=flat-square) | ğŸ–¼ï¸ğŸ¥ğŸšŒğŸ§Š | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-03 | [VideoCrafter/VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | ![VideoCrafter/VideoCrafter Stars](https://img.shields.io/github/stars/VideoCrafter/VideoCrafter.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸšŒ2ï¸âƒ£ | A Toolkit for Text-to-Video Generation and Editing |
| 2023-03-30 | [mayuelala/FollowYourPose](https://github.com/mayuelala/FollowYourPose) | ![mayuelala/FollowYourPose Stars](https://img.shields.io/github/stars/mayuelala/FollowYourPose.svg?label=&style=flat-square) | ğŸ¥ğŸšŒ2ï¸âƒ£ | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-22 | [aschmelyun/subvert](https://github.com/aschmelyun/subvert) | ![aschmelyun/subvert Stars](https://img.shields.io/github/stars/aschmelyun/subvert.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸ“± | Generate subtitles, summaries, and chapters from videos in seconds |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | ![johannakarras/DreamPose Stars](https://img.shields.io/github/stars/johannakarras/DreamPose.svg?label=&style=flat-square) | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-21 | [Picsart-AI-Research/Text2Video-Zero](https://github.com/Picsart-AI-Research/Text2Video-Zero) | ![Picsart-AI-Research/Text2Video-Zero Stars](https://img.shields.io/github/stars/Picsart-AI-Research/Text2Video-Zero.svg?label=&style=flat-square) | ğŸ¥ğŸšŒ | Text-to-Image Diffusion Models are Zero-Shot Video Generators |
| 2023-03-19 | [kabachuha/sd-webui-text2video](https://github.com/kabachuha/sd-webui-text2video) | ![kabachuha/sd-webui-text2video Stars](https://img.shields.io/github/stars/kabachuha/sd-webui-text2video.svg?label=&style=flat-square) | ğŸ–¼ï¸ğŸ¥ğŸ”Œ | Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies |
| 2023-03-19 | [camenduru/text-to-video-synthesis-colab](https://github.com/camenduru/text-to-video-synthesis-colab) | ![camenduru/text-to-video-synthesis-colab Stars](https://img.shields.io/github/stars/camenduru/text-to-video-synthesis-colab.svg?label=&style=flat-square) | ğŸ” ğŸ¥ğŸ”¨ | Text To Video Synthesis Colab |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | ![ChenyangQiQi/FateZero Stars](https://img.shields.io/github/stars/ChenyangQiQi/FateZero.svg?label=&style=flat-square) | ğŸ” ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | Pytorch Implementation for "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-15 | [microsoft/MM-REACT](https://github.com/microsoft/MM-REACT) | ![microsoft/MM-REACT Stars](https://img.shields.io/github/stars/microsoft/MM-REACT.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸ¥ğŸ“± | Official repo for MM-REACT |
| 2023-02-26 | [JimmyLv/BibiGPT](https://github.com/JimmyLv/BibiGPT) | ![JimmyLv/BibiGPT Stars](https://img.shields.io/github/stars/JimmyLv/BibiGPT.svg?label=&style=flat-square) | ğŸ” ğŸµğŸ¥ğŸ“± | BibiGPT Â· 1-click AI Summary for video &  audio content: Bilibili \| YouTube \| Local files \| Websitesä¸¨Podcasts \| Meetings \| Lectures, etc. éŸ³è§†é¢‘å†…å®¹ AI ä¸€é”®æ€»ç»“ & å¯¹è¯ï¼šå“”å“©å“”å“©ä¸¨YouTubeä¸¨ç½‘é¡µä¸¨æ’­å®¢ä¸¨ä¼šè®®ä¸¨æœ¬åœ°æ–‡ä»¶ç­‰ (åŸ BiliGPT çœæµç¥å™¨ & è¯¾ä»£è¡¨) |
| 2023-01-08 | [dair-ai/ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | ![dair-ai/ML-Papers-of-the-Week Stars](https://img.shields.io/github/stars/dair-ai/ML-Papers-of-the-Week.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | ğŸ”¥Highlighting the top ML papers every week. |
| 2022-12-25 | [showlab/Tune-A-Video](https://github.com/showlab/Tune-A-Video) | ![showlab/Tune-A-Video Stars](https://img.shields.io/github/stars/showlab/Tune-A-Video.svg?label=&style=flat-square) | ğŸ¥ğŸšŒ | Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | ![OpenTalker/SadTalker Stars](https://img.shields.io/github/stars/OpenTalker/SadTalker.svg?label=&style=flat-square) | ğŸ–¼ï¸ğŸµğŸ¥ğŸšŒ2ï¸âƒ£ | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-10-28 | [mli/autocut](https://github.com/mli/autocut) | ![mli/autocut Stars](https://img.shields.io/github/stars/mli/autocut.svg?label=&style=flat-square) | ğŸ¥ğŸ“± | ç”¨æ–‡æœ¬ç¼–è¾‘å™¨å‰ªè§†é¢‘ |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | ![mlfoundations/open_flamingo Stars](https://img.shields.io/github/stars/mlfoundations/open_flamingo.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | An open-source framework for training large multimodal models. |
| 2022-10-17 | [MubertAI/Mubert-Text-to-Music](https://github.com/MubertAI/Mubert-Text-to-Music) | ![MubertAI/Mubert-Text-to-Music Stars](https://img.shields.io/github/stars/MubertAI/Mubert-Text-to-Music.svg?label=&style=flat-square) | ğŸ” ğŸµğŸ¥ğŸ“ | A simple notebook demonstrating prompt-based music generation via Mubert API |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | ![GuyTevet/motion-diffusion-model Stars](https://img.shields.io/github/stars/GuyTevet/motion-diffusion-model.svg?label=&style=flat-square) | ğŸ¥â›½ğŸšŒ2ï¸âƒ£ | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-09 | [williamyang1991/VToonify](https://github.com/williamyang1991/VToonify) | ![williamyang1991/VToonify Stars](https://img.shields.io/github/stars/williamyang1991/VToonify.svg?label=&style=flat-square) | ğŸ¥ğŸšŒ2ï¸âƒ£ | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-09-06 | [nateraw/stable-diffusion-videos](https://github.com/nateraw/stable-diffusion-videos) | ![nateraw/stable-diffusion-videos Stars](https://img.shields.io/github/stars/nateraw/stable-diffusion-videos.svg?label=&style=flat-square) | ğŸ¥ğŸ“± | Create ğŸ”¥ videos with Stable Diffusion by exploring the latent space and morphing between text prompts |
| 2022-09-04 | [swyxio/ai-notes](https://github.com/swyxio/ai-notes) | ![swyxio/ai-notes Stars](https://img.shields.io/github/stars/swyxio/ai-notes.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
