| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-19 | [michael-wzhu/Chinese-LlaMA2](https://github.com/michael-wzhu/Chinese-LlaMA2) | 534 | 🔠`🚌``🚕``1️⃣``2️⃣`💰🀄 | Repo for adapting Meta LlaMA2 in Chinese! META最新发布的LlaMA2的汉化版！ （完全开源可商用） |
| 2023-07-19 | [yangjianxin1/Firefly-LLaMA2-Chinese](https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese) | 73 | 🔠`🚌``🚕``1️⃣``2️⃣`🀄 | 中文LLaMA-2大模型，兼容对中文大模型进行增量预训练 |
| 2023-07-18 | [longyuewangdcu/Chinese-Llama-2](https://github.com/longyuewangdcu/Chinese-Llama-2) | 204 | 🔠🚌`1️⃣`2️⃣ | Chinese-Llama-2 is a project that aims to expand the impressive capabilities of the Llama-2 language model to the Chinese language. |
| 2023-07-18 | [ymcui/Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 653 | 🔠`🚌``1️⃣``2️⃣`💰🀄 | 中文LLaMA-2 & Alpaca-2大语言模型 (Chinese LLaMA-2 & Alpaca-2 LLMs) |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | 1039 | 🔠⛽🚕1️⃣2️⃣3️⃣🀄 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. 训练医疗大模型，实现包括二次预训练、有监督微调、奖励建模、强化学习训练。 |
| 2023-05-28 | [hiyouga/LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) | 1939 | 🔠1️⃣2️⃣3️⃣ | Easy-to-use fine-tuning framework using PEFT (PT+SFT+RLHF with QLoRA) (LLaMA-2, BLOOM, Falcon, Baichuan) |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 533 | 🖼️🚌1️⃣2️⃣ | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | 1615 | 🔠⛽🚌1️⃣2️⃣ | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 392 | 🔠⛽🚌1️⃣2️⃣🀄 | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1334 | 🔠🎥🚌1️⃣2️⃣ | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 1997 | 🔠🖼️🚌`1️⃣`2️⃣ | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 4052 | 🔠🖼️⛽🚌1️⃣2️⃣ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 21825 | 🔠🖼️🚌1️⃣2️⃣ | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | 4960 | 🔠🚌1️⃣2️⃣✂️💰 | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2433 | 🔠⛽🚌1️⃣2️⃣`3️⃣`✂️💡💰🀄 | Chinese-LLaMA 1&2、Chinese-Falcon 基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 13347 | 🔠1️⃣2️⃣✂️💡🀄 | 中文LLaMA&Alpaca大语言模型+本地CPU/GPU训练部署 (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8697 | 🔠⛽🚌1️⃣2️⃣ |  |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 23502 | 🔠⛽🚌1️⃣2️⃣ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 6090 | 🔠🖼️⛽🚌1️⃣2️⃣ | LAVIS - A One-stop Library for Language-Vision Intelligence |
