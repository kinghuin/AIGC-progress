| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | ![OFA-Sys/ONE-PEACE Stars](https://img.shields.io/github/stars/OFA-Sys/ONE-PEACE.svg?label=&style=flat-square) | ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | A general representation modal across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | ![Neutralzz/BiLLa Stars](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | ![haotian-liu/LLaVA Stars](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | ![Vision-CAIR/MiniGPT-4 Stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | ![Lightning-AI/lit-llama Stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama.svg?label=&style=flat-square) | ğŸ” ğŸšŒ1ï¸âƒ£2ï¸âƒ£âœ‚ï¸âœ… | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£âœ‚ï¸ğŸ’¡âœ…ğŸ€„ | Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | ![ymcui/Chinese-LLaMA-Alpaca Stars](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?label=&style=flat-square) | ğŸ” 1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’¡ğŸ€„ | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | ![togethercomputer/OpenChatKit Stars](https://img.shields.io/github/stars/togethercomputer/OpenChatKit.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |  |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | ![karpathy/nanoGPT Stars](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | ![salesforce/LAVIS Stars](https://img.shields.io/github/stars/salesforce/LAVIS.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | LAVIS - A One-stop Library for Language-Vision Intelligence |
