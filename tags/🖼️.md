| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-08-16 | [tencent-ailab/IP-Adapter](https://github.com/tencent-ailab/IP-Adapter) | 40 | ğŸ–¼ï¸ğŸšŒ | The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.  |
| 2023-08-14 | [opendatalab/WanJuan1.0](https://github.com/opendatalab/WanJuan1.0) | 159 | ğŸ” ğŸ–¼ï¸ğŸ¥â›½ | ä¸‡å·1.0å¤šæ¨¡æ€è¯­æ–™ |
| 2023-08-10 | [modelscope/facechain](https://github.com/modelscope/facechain) | 2342 | ğŸ–¼ï¸ğŸ“± | FaceChain is a deep-learning toolchain for generating your Digital-Twin. |
| 2023-08-09 | [lllyasviel/Fooocus](https://github.com/lllyasviel/Fooocus) | 4089 | ğŸ–¼ï¸ğŸ”Œ | Focus on prompting and generating |
| 2023-08-03 | [OpenGVLab/all-seeing](https://github.com/OpenGVLab/all-seeing) | 208 | ğŸ” ğŸ–¼ï¸`ğŸšŒ` | This is the official implementation of the paper "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World" |
| 2023-08-01 | [dvlab-research/LISA](https://github.com/dvlab-research/LISA) | 764 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | Project Page for "LISA: Reasoning Segmentation via Large Language Model" |
| 2023-07-30 | [LinkSoul-AI/Chinese-LLaVA](https://github.com/LinkSoul-AI/Chinese-LLaVA) | 126 | ğŸ” ğŸ–¼ï¸ğŸ”¨ğŸ’°ğŸ€„ | æ”¯æŒä¸­è‹±æ–‡åŒè¯­è§†è§‰-æ–‡æœ¬å¯¹è¯çš„å¼€æºå¯å•†ç”¨å¤šæ¨¡æ€æ¨¡å‹ã€‚ |
| 2023-07-28 | [SpenserCai/sd-webui-deoldify](https://github.com/SpenserCai/sd-webui-deoldify) | 246 | ğŸ–¼ï¸ğŸ”Œ | DeOldify for Stable Diffusion WebUIï¼šThis is an extension for StableDiffusion's AUTOMATIC1111 web-ui that allows colorize of old photos and old video. It is based on deoldify. |
| 2023-07-26 | [rynmurdock/inanimate](https://github.com/rynmurdock/inanimate) | 35 | ğŸ–¼ï¸ğŸ”Œ | Generate images from an initial frame and text |
| 2023-07-24 | [glucauze/sd-webui-faceswaplab](https://github.com/glucauze/sd-webui-faceswaplab) | 125 | ğŸ–¼ï¸ğŸ”Œ |  Extended faceswap extension for StableDiffusion web-ui with multiple faceswaps, inpainting, checkpoints, ....  |
| 2023-07-21 | [Alpha-VLLM/LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory) | 1287 | ğŸ” ğŸ–¼ï¸â›½1ï¸âƒ£2ï¸âƒ£ğŸ“± | An Open-source Toolkit for LLM Development |
| 2023-07-21 | [OPPO-Mente-Lab/Subject-Diffusion](https://github.com/OPPO-Mente-Lab/Subject-Diffusion) | 145 | ğŸ–¼ï¸`â›½`ğŸšŒ2ï¸âƒ£ | Subject-Diffusion:Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning |
| 2023-07-21 | [segmind/distill-sd](https://github.com/segmind/distill-sd) | 268 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ | Segmind Distilled diffusion |
| 2023-07-20 | [ThisisBillhe/tiny-stable-diffusion](https://github.com/ThisisBillhe/tiny-stable-diffusion) | 91 | ğŸ” ğŸ–¼ï¸âœ‚ï¸ | Tiny optimized Stable-diffusion that can run on GPUs with just 1GB of VRAM. (Beta) |
| 2023-07-18 | [continue-revolution/sd-webui-animatediff](https://github.com/continue-revolution/sd-webui-animatediff) | 372 | ğŸ–¼ï¸ğŸ”Œ | AnimateDiff for AUTOMATIC1111 Stable Diffusion WebUI |
| 2023-07-16 | [caopulan/iKUNet](https://github.com/caopulan/iKUNet) | 137 | ğŸ–¼ï¸ğŸ“± | è¿‘å¹´æ¥ï¼Œç”±äºæ˜æ˜Ÿã€ä¼ä¸šé¢‘ç¹å¡Œæˆ¿ï¼Œè¡ç”Ÿå‡ºä¸€ä¸ªæ–°çš„éœ€æ±‚ï¼Œå³ç§»é™¤æƒ…èŠ‚ä¸­çš„æŸä¸ªå…ƒç´ ï¼Œå¦‚æŸä¸ªæ˜æ˜Ÿæˆ–æŸä¸ªèµåŠ©å•†ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªä»»åŠ¡å‘½åä¸ºğŸ¥å…ƒç´ ç§»é™¤ã€‚  |
| 2023-07-16 | [magic-research/bubogpt](https://github.com/magic-research/bubogpt) | 269 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-15 | [AILab-CVC/SEED](https://github.com/AILab-CVC/SEED) | 145 | ğŸ–¼ï¸`ğŸšŒ` | Empowers LLMs with the ability to see and draw. |
| 2023-07-15 | [CodeAlchemyAI/ViLT-GPT](https://github.com/CodeAlchemyAI/ViLT-GPT) | 113 | ğŸ” ğŸ–¼ï¸ğŸ“± | By integrating OpenAI's Language Models (LLM) and LangChain with Vision-and-Language models, this app can answer queries based on the content of images.  |
| 2023-07-15 | [RimoChan/emmmbedding](https://github.com/RimoChan/emmmbedding) | 135 | ğŸ–¼ï¸ğŸ“± | ã€emmmbeddingã€‘ä¸ç”¨å­˜å‚¨çš„å›¾åºŠï¼ |
| 2023-07-14 | [vitoplantamura/OnnxStream](https://github.com/vitoplantamura/OnnxStream) | 700 | ğŸ–¼ï¸ğŸ’¡ | Running Stable Diffusion on a RPI Zero 2 (or in 260MB of RAM) |
| 2023-07-13 | [ThioJoe/Full-Stack-AI-Meme-Generator](https://github.com/ThioJoe/Full-Stack-AI-Meme-Generator) | 205 | ğŸ” ğŸ–¼ï¸ğŸ“± | Uses Various AI Service APIs to generate memes with text and images |
| 2023-07-13 | [bytedance/lynx-llm](https://github.com/bytedance/lynx-llm) | 153 | ğŸ” ğŸ–¼ï¸2ï¸âƒ£â“ | paper: https://arxiv.org/abs/2307.02469 page: https://lynx-llm.github.io/ |
| 2023-07-12 | [SeargeDP/SeargeSDXL](https://github.com/SeargeDP/SeargeSDXL) | 244 | ğŸ–¼ï¸ğŸ”¨ | Custom nodes and workflows for SDXL in ComfyUI |
| 2023-07-12 | [yangyuke001/SD-inference](https://github.com/yangyuke001/SD-inference) | 175 | ğŸ” ğŸ–¼ï¸ğŸ’¡ | Stable Diffusion inference |
| 2023-07-11 | [baaivision/Emu](https://github.com/baaivision/Emu) | 479 | ğŸ” ğŸ–¼ï¸ğŸšŒ | Emu: An Open Multimodal Generalist |
| 2023-07-08 | [Yujun-Shi/DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 564 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ | Official code for DragDiffusion |
| 2023-07-07 | [ringa-tech/asistente-virtual](https://github.com/ringa-tech/asistente-virtual) | 123 | ğŸ” ğŸ–¼ï¸ğŸš• | An attempt to extend PULSE to a biomedical multimodal conversational assistant. |
| 2023-07-06 | [camenduru/sdxl-colab](https://github.com/camenduru/sdxl-colab) | 206 | ğŸ–¼ï¸ğŸ”¨ |  |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | 294 | ğŸ” ğŸ–¼ï¸â›½`ğŸšŒ`2ï¸âƒ£ | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-04 | [sd-fabric/fabric](https://github.com/sd-fabric/fabric) | 248 | ğŸ–¼ï¸ğŸ”¨ |  |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 427 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-07-02 | [antfu/sd-webui-qrcode-toolkit](https://github.com/antfu/sd-webui-qrcode-toolkit) | 451 | ğŸ–¼ï¸ğŸ”Œ | Anthony's QR Toolkit for Stable Diffusion WebUI |
| 2023-07-01 | [TonyLianLong/stable-diffusion-xl-demo](https://github.com/TonyLianLong/stable-diffusion-xl-demo) | 163 | ğŸ” ğŸ–¼ï¸ğŸ”¨ | A gradio web UI demo for Stable Diffusion XL 1.0, with refiner and MultiGPU support |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | 757 | ğŸ” ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£`ğŸ€„ | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-30 | [jtydhr88/sd-webui-3d-editor](https://github.com/jtydhr88/sd-webui-3d-editor) | 90 | ğŸ–¼ï¸ğŸ”Œ | A custom extension for sd-webui that with 3D modeling features (add/edit basic elements, load your custom model, modify scene and so on), then send screenshot to txt2img or img2img as your ControlNet's reference image, basing on ThreeJS editor |
| 2023-06-27 | [SALT-NLP/LLaVAR](https://github.com/SALT-NLP/LLaVAR) | 122 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Code/Data for the paper: "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding" |
| 2023-06-27 | [painebenjamin/app.enfugue.ai](https://github.com/painebenjamin/app.enfugue.ai) | 184 | ğŸ–¼ï¸ğŸ”¨ | ENFUGUE is a feature-rich self-hosted Stable Diffusion webapp |
| 2023-06-26 | [antfu/qrcode-toolkit](https://github.com/antfu/qrcode-toolkit) | 844 | ğŸ–¼ï¸ğŸ”Œ | Anthony's QR Code Toolkit for AI generated QR Codes |
| 2023-06-26 | [artyfacialintelagent/CloneCleaner](https://github.com/artyfacialintelagent/CloneCleaner) | 69 | ğŸ–¼ï¸ğŸ”Œ | An extension for Automatic1111 to work around Stable Diffusion's "clone problem". It automatically modifies your prompts with random names, nationalities, hair style and hair color to create more variations in generated people. |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | 8498 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Generative Models by Stability AI |
| 2023-06-17 | [e-johnstonn/FableForge](https://github.com/e-johnstonn/FableForge) | 302 | ğŸ” ğŸ–¼ï¸ğŸ”¨ | Generate a picture book from a single prompt using OpenAI function calling, replicate, and Deep Lake |
| 2023-06-17 | [s0md3v/sd-webui-roop](https://github.com/s0md3v/sd-webui-roop) | 2048 | ğŸ–¼ï¸ğŸ”Œ | roop extension for StableDiffusion web-ui |
| 2023-06-14 | [life-exe/UnrealOpenAIPlugin](https://github.com/life-exe/UnrealOpenAIPlugin) | 73 | ğŸ” ğŸ–¼ï¸ğŸµğŸ“± | This plugin is a comprehensive Unreal Engine wrapper for the OpenAI API. |
| 2023-06-13 | [SizheAn/PanoHead](https://github.com/SizheAn/PanoHead) | 1436 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ğŸ§Š | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-06 | [autodistill/autodistill](https://github.com/autodistill/autodistill) | 545 | ğŸ–¼ï¸ğŸ”¨ | Images to inference with no labeling (use foundation models to train supervised models) |
| 2023-06-05 | [Licoy/ChatGPT-Midjourney](https://github.com/Licoy/ChatGPT-Midjourney) | 4449 | ğŸ” ğŸ–¼ï¸ğŸ”¨ | ğŸ­ ä¸€é”®æ‹¥æœ‰ä½ è‡ªå·±çš„ ChatGPT+Midjourney ç½‘é¡µæœåŠ¡ \| Own your own ChatGPT+Midjourney web service with one click |
| 2023-06-05 | [Richasy/FantasyCopilot](https://github.com/Richasy/FantasyCopilot) | 346 | ğŸ” ğŸ–¼ï¸ğŸµğŸ”¨ | A new-age AI desktop tool |
| 2023-06-04 | [axodox/axodox-machinelearning](https://github.com/axodox/axodox-machinelearning) | 522 | ğŸ–¼ï¸ğŸ’¡ | This repository contains a C++ ONNX implementation of StableDiffusion. |
| 2023-05-29 | [icoz69/StyleAvatar3D](https://github.com/icoz69/StyleAvatar3D) | 457 | ğŸ–¼ï¸ğŸ“ğŸ§Š | Official repo for StyleAvatar3D |
| 2023-05-23 | [ShihaoZhaoZSH/Uni-ControlNet](https://github.com/ShihaoZhaoZSH/Uni-ControlNet) | 376 | ğŸ–¼ï¸ğŸ“± | Uni-ControlNet is a novel controllable diffusion model that allows for the simultaneous utilization of different local controls and global controls in a flexible and composable manner within one model. |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 528 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | ğŸ©º é¦–ä¸ªä¼šçœ‹èƒ¸éƒ¨Xå…‰ç‰‡çš„ä¸­æ–‡å¤šæ¨¡æ€åŒ»å­¦å¤§æ¨¡å‹ \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1132 | ğŸ” ğŸ–¼ï¸ğŸµâ›½ğŸšŒ2ï¸âƒ£ | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-20 | [OpenGVLab/DragGAN](https://github.com/OpenGVLab/DragGAN) | 4825 | ğŸ–¼ï¸ğŸ”¨ | Unofficial Implementation of DragGAN - "Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold" ï¼ˆDragGAN å…¨åŠŸèƒ½å®ç°ï¼Œåœ¨çº¿Demoï¼Œæœ¬åœ°éƒ¨ç½²è¯•ç”¨ï¼Œä»£ç ã€æ¨¡å‹å·²å…¨éƒ¨å¼€æºï¼Œæ”¯æŒWindows, macOS, Linuxï¼‰ |
| 2023-05-20 | [pkuliyi2015/sd-webui-stablesr](https://github.com/pkuliyi2015/sd-webui-stablesr) | 663 | ğŸ–¼ï¸ğŸ”Œ | StableSR for Stable Diffusion WebUI - Ultra High-quality Image Upscaler |
| 2023-05-19 | [SHI-Labs/Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | 585 | ğŸ–¼ï¸ğŸšŒ | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 560 | ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 431 | ğŸ–¼ï¸`ğŸšŒ``2ï¸âƒ£` | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [drboog/ProFusion](https://github.com/drboog/ProFusion) | 413 | ğŸ–¼ï¸ğŸ“± | Code for Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach |
| 2023-05-18 | [mbzuai-oryx/XrayGPT](https://github.com/mbzuai-oryx/XrayGPT) | 339 | ğŸ” ğŸ–¼ï¸â›½ğŸš•2ï¸âƒ£ | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. |
| 2023-05-18 | [salesforce/UniControl](https://github.com/salesforce/UniControl) | 477 | ğŸ–¼ï¸ğŸšŒ | Unified Controllable Visual Generation Model |
| 2023-05-18 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | 587 | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 454 | ğŸ–¼ï¸`â›½`ğŸšŒ`2ï¸âƒ£` | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-17 | [simoninithomas/awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | 259 | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | A curated list of awesome AI tools for game developers |
| 2023-05-13 | [Zo3i/chatgptWithMidjourney](https://github.com/Zo3i/chatgptWithMidjourney) | 394 | ğŸ” ğŸ–¼ï¸ğŸ”¨ |  |
| 2023-05-12 | [Stability-AI/StableSwarmUI](https://github.com/Stability-AI/StableSwarmUI) | 587 | ğŸ–¼ï¸ğŸ”¨ | StableSwarmUI, A Modular Stable Diffusion Web-User-Interface, with an emphasis on making powertools easily accessible, high performance, and extensibility. |
| 2023-05-11 | [fiatrete/OpenDAN-Personal-AI-OS](https://github.com/fiatrete/OpenDAN-Personal-AI-OS) | 1235 | ğŸ” ğŸ–¼ï¸ğŸµğŸ”¨ | OpenDAN is an open source Personal AI OS , which consolidates various AI modules in one place for your personal use. |
| 2023-05-08 | [Physton/sd-webui-prompt-all-in-one](https://github.com/Physton/sd-webui-prompt-all-in-one) | 1435 | ğŸ–¼ï¸ğŸ”Œ | This is an extension based on sd-webui, aimed at improving the user experience of the prompt/negative prompt input box. It has a more intuitive and powerful input interface function, and provides automatic translation, history record, and bookmarking functions.    è¿™æ˜¯ä¸€ä¸ªåŸºäº sd-webui çš„æ‰©å±•ï¼Œæ—¨åœ¨æé«˜æç¤ºè¯/åå‘æç¤ºè¯è¾“å…¥æ¡†çš„ä½¿ç”¨ä½“éªŒã€‚å®ƒæ‹¥æœ‰æ›´ç›´è§‚ã€å¼ºå¤§çš„è¾“å…¥ç•Œé¢åŠŸèƒ½ï¼Œå®ƒæä¾›äº†è‡ªåŠ¨ç¿»è¯‘ã€å†å²è®°å½•å’Œæ”¶è—ç­‰åŠŸèƒ½ã€‚ |
| 2023-05-06 | [yankooliveira/sd-webui-photopea-embed](https://github.com/yankooliveira/sd-webui-photopea-embed) | 624 | ğŸ–¼ï¸ğŸ”Œ | A simple Stable Diffusion WebUI extension that adds a Photopea tab and integration. |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2320 | ğŸ” ğŸ–¼ï¸ğŸšŒ`1ï¸âƒ£`2ï¸âƒ£ | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1150 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-02 | [Docta-ai/docta](https://github.com/Docta-ai/docta) | 1282 | ğŸ” ğŸ–¼ï¸â›½ | A Doctor for your data |
| 2023-05-01 | [FurkanGozukara/Stable-Diffusion](https://github.com/FurkanGozukara/Stable-Diffusion) | 834 | ğŸ–¼ï¸ğŸ“ | Stable Diffusion, SDXL, LoRA Training, DreamBooth Training, Automatic1111 Web UI, DeepFake, Deep Fakes, TTS, Animation, Text To Video, Tutorials, Guides, Lectures, Courses, ComfyUI, Google Colab, RunPod, NoteBooks, ControlNet, TTS, Voice Cloning, AI, AI News, ML, ML News, News, Tech, Tech News, Kohya LoRA, Kandinsky 2, DeepFloyd IF, Midjourney |
| 2023-04-29 | [mishalhossin/Discord-AI-Chatbot](https://github.com/mishalhossin/Discord-AI-Chatbot) | 1025 | ğŸ–¼ï¸ğŸ“± | This Discord chatbot is incredibly versatile, offering a wide range of customization options.  |
| 2023-04-28 | [mlfoundations/datacomp](https://github.com/mlfoundations/datacomp) | 378 | ğŸ” ğŸ–¼ï¸â›½ | DataComp: In search of the next generation of multimodal datasets |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 267 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [Bing-su/adetailer](https://github.com/Bing-su/adetailer) | 1906 | ğŸ–¼ï¸ğŸ”Œ | Auto detecting, masking and inpainting with detection model. |
| 2023-04-26 | [mosaicml/diffusion](https://github.com/mosaicml/diffusion) | 440 | ğŸ–¼ï¸2ï¸âƒ£ | This repo contains code used to train your own Stable Diffusion model on your own data. |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1159 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ | Multimodal-GPT |
| 2023-04-26 | [vijishmadhavan/UnpromptedControl](https://github.com/vijishmadhavan/UnpromptedControl) | 349 | ğŸ” ğŸ–¼ï¸ğŸ“± | Remove unwanted objects and restore images without prompts, powered by ControlNet. |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1337 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-24 | [erictik/midjourney-api](https://github.com/erictik/midjourney-api) | 1025 | ğŸ–¼ï¸ğŸ”¨ | MidJourney client. Unofficial Node.js client |
| 2023-04-24 | [novicezk/midjourney-proxy](https://github.com/novicezk/midjourney-proxy) | 2655 | ğŸ–¼ï¸ğŸ”¨ | ä»£ç† MidJourney çš„discordé¢‘é“ï¼Œå®ç°apiå½¢å¼è°ƒç”¨AIç»˜å›¾ |
| 2023-04-24 | [stassius/StableHoudini](https://github.com/stassius/StableHoudini) | 306 | ğŸ–¼ï¸ğŸ”Œ | Stable Diffusion Houdini Toolset |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 567 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3212 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-22 | [LemonQu-GIT/ChatGLM-6B-Engineering](https://github.com/LemonQu-GIT/ChatGLM-6B-Engineering) | 534 | ğŸ” ğŸ–¼ï¸ğŸ”¨ | ChatGLM-6B Prompt Engineering Project |
| 2023-04-20 | [SupaGruen/StableDiffusion-CheatSheet](https://github.com/SupaGruen/StableDiffusion-CheatSheet) | 1330 | ğŸ–¼ï¸ğŸ“ | A list of StableDiffusion styles and some notes for offline use. Pure HTML, CSS and a bit of JS. |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 750 | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£âœ‚ï¸ | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-19 | [lupantech/chameleon-llm](https://github.com/lupantech/chameleon-llm) | 853 | ğŸ” ğŸ–¼ï¸ğŸ“± | Codes for "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models". |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 4457 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-17 | [houseofsecrets/SdPaint](https://github.com/houseofsecrets/SdPaint) | 1515 | ğŸ–¼ï¸ğŸ”Œ | Stable Diffusion Painting |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22083 | ğŸ” ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-13 | [Anything-of-anything/Anything-3D](https://github.com/Anything-of-anything/Anything-3D) | 1283 | ğŸ–¼ï¸`ğŸ“±`ğŸ§Š | Segment-Anything + 3D. Let's lift anything to 3D. |
| 2023-04-12 | [CiaraStrawberry/TemporalKit](https://github.com/CiaraStrawberry/TemporalKit) | 1425 | ğŸ–¼ï¸ğŸ”Œ | An all in one solution for adding Temporal Stability to a Stable Diffusion Render via an automatic1111 extension |
| 2023-04-12 | [showlab/Image2Paragraph](https://github.com/showlab/Image2Paragraph) | 685 | ğŸ–¼ï¸ğŸ“± | [A toolbox for fun.] Transform Image into Unique Paragraph with ChatGPT, BLIP2, OFA, GRIT, Segment Anything, ControlNet. |
| 2023-04-10 | [continue-revolution/sd-webui-segment-anything](https://github.com/continue-revolution/sd-webui-segment-anything) | 2376 | ğŸ–¼ï¸ğŸ”Œ | Segment Anything for Stable Diffusion WebUI |
| 2023-04-09 | [KohakuBlueleaf/a1111-sd-webui-lycoris](https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris) | 726 | ğŸ–¼ï¸ğŸ”Œ | An extension for stable-diffusion-webui to load lycoris models.  |
| 2023-04-09 | [geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 3936 | ğŸ–¼ï¸ğŸ¥ğŸšŒğŸ§Š | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-09 | [sail-sg/EditAnything](https://github.com/sail-sg/EditAnything) | 2513 | ğŸ–¼ï¸ğŸ”¨ | Edit anything in images  powered by segment-anything, ControlNet, StableDiffusion, etc. |
| 2023-04-08 | [agiresearch/OpenAGI](https://github.com/agiresearch/OpenAGI) | 1332 | ğŸ” ğŸ–¼ï¸ğŸ“± | OpenAGI: When LLM Meets Domain Experts |
| 2023-04-07 | [ttengwang/Caption-Anything](https://github.com/ttengwang/Caption-Anything) | 1343 | ğŸ” ğŸ–¼ï¸ğŸ“± | Caption-Anything is a versatile tool combining image segmentation, visual captioning, and ChatGPT, generating tailored captions with diverse controls for user preferences. https://huggingface.co/spaces/TencentARC/Caption-Anything https://huggingface.co/spaces/VIPLab/Caption-Anything |
| 2023-04-06 | [IDEA-Research/Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything) | 10423 | ğŸ” ğŸ–¼ï¸ğŸ“± | Grounded-SAM: Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | 2432 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ğŸ§Š | A unified framework for 3D content generation. |
| 2023-04-04 | [carefree0910/carefree-drawboard](https://github.com/carefree0910/carefree-drawboard) | 907 | ğŸ–¼ï¸ğŸ”¨ | ğŸ¨ Infinite Drawboard in Python |
| 2023-04-04 | [soulteary/docker-prompt-generator](https://github.com/soulteary/docker-prompt-generator) | 1027 | ğŸ” ğŸ–¼ï¸ğŸ“± | Using a Model to generate prompts for Model applications. / ä½¿ç”¨æ¨¡å‹æ¥ç”Ÿæˆä½œå›¾å’’è¯­çš„å·æ‡’å·¥å…·ï¼Œæ”¯æŒ MidJourneyã€Stable Diffusion ç­‰ã€‚ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | 2271 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-04-01 | [THUDM/ImageReward](https://github.com/THUDM/ImageReward) | 591 | ğŸ” ğŸ–¼ï¸3ï¸âƒ£ğŸ”Œ | ImageReward: Learning and Evaluating Human Preferences for Text-to-image Generation |
| 2023-03-30 | [microsoft/JARVIS](https://github.com/microsoft/JARVIS) | 21607 | ğŸ” ğŸ–¼ï¸ğŸµğŸ“± | JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf |
| 2023-03-28 | [dbolya/tomesd](https://github.com/dbolya/tomesd) | 1008 | ğŸ–¼ï¸ğŸ”Œ | Speed up Stable Diffusion with this one simple trick! |
| 2023-03-26 | [visual-openllm/visual-openllm](https://github.com/visual-openllm/visual-openllm) | 1110 | ğŸ” ğŸ–¼ï¸ğŸ”¨ | something like visual-chatgpt, æ–‡å¿ƒä¸€è¨€çš„å¼€æºç‰ˆ |
| 2023-03-23 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1247 | ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£`ğŸ§Š | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-21 | [lukasHoel/text2room](https://github.com/lukasHoel/text2room) | 830 | ğŸ” ğŸ–¼ï¸ğŸšŒğŸ§Š | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models (ICCV2023). |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4650 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [hako-mikan/sd-webui-regional-prompter](https://github.com/hako-mikan/sd-webui-regional-prompter) | 802 | ğŸ–¼ï¸ğŸ”Œ | set prompt to divided region |
| 2023-03-19 | [kabachuha/sd-webui-text2video](https://github.com/kabachuha/sd-webui-text2video) | 1030 | ğŸ–¼ï¸ğŸ¥ğŸ”Œ | Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies |
| 2023-03-18 | [go-skynet/LocalAI](https://github.com/go-skynet/LocalAI) | 9910 | ğŸ” ğŸ–¼ï¸ğŸ’¡ | :robot: Self-hosted, community-driven, local OpenAI compatible API. Drop-in replacement for OpenAI running LLMs on consumer-grade hardware. Free Open Source OpenAI alternative. No GPU required. Runs ggml, GPTQ, onnx, TF compatible models: llama, gpt4all, rwkv, whisper, vicuna, koala, gpt4all-j, cerebras, falcon, dolly, starcoder, and many others |
| 2023-03-17 | [cvlab-columbia/zero123](https://github.com/cvlab-columbia/zero123) | 1668 | ğŸ–¼ï¸2ï¸âƒ£ğŸ§Š | Zero-1-to-3: Zero-shot One Image to 3D Object (ICCV 2023) |
| 2023-03-17 | [volotat/SD-CN-Animation](https://github.com/volotat/SD-CN-Animation) | 681 | ğŸ–¼ï¸ğŸ”Œ | This script allows to automate video stylization task using StableDiffusion and ControlNet. |
| 2023-03-16 | [Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) | 146540 | ğŸ” ğŸ–¼ï¸ğŸµğŸ“± | An experimental open-source attempt to make GPT-4 fully autonomous. |
| 2023-03-15 | [microsoft/MM-REACT](https://github.com/microsoft/MM-REACT) | 761 | ğŸ” ğŸ–¼ï¸ğŸ¥ğŸ“± | Official repo for MM-REACT |
| 2023-03-14 | [lllyasviel/ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | 3286 | ğŸ–¼ï¸ğŸšŒ | Nightly release of ControlNet 1.1 |
| 2023-03-13 | [KU-CVLAB/3DFuse](https://github.com/KU-CVLAB/3DFuse) | 636 | ğŸ–¼ï¸ğŸšŒğŸ§Š | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-11 | [hnmr293/sd-webui-cutoff](https://github.com/hnmr293/sd-webui-cutoff) | 951 | ğŸ–¼ï¸ğŸ”Œ | Cutoff - Cutting Off Prompt Effect |
| 2023-03-10 | [thu-ml/unidiffuser](https://github.com/thu-ml/unidiffuser) | 1046 | ğŸ–¼ï¸ğŸšŒ | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2834 | ğŸ” ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£` | Official implementation of the paper "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-06 | [mlc-ai/web-stable-diffusion](https://github.com/mlc-ai/web-stable-diffusion) | 3004 | ğŸ–¼ï¸ğŸ’¡ | Bringing stable diffusion models to web browsers. Everything runs inside the browser with no server support.  |
| 2023-03-02 | [jexom/sd-webui-depth-lib](https://github.com/jexom/sd-webui-depth-lib) | 1210 | ğŸ–¼ï¸ğŸ”Œ | Depth map library for use with the Control Net extension for Automatic1111/stable-diffusion-webui |
| 2023-03-02 | [microsoft/TaskMatrix](https://github.com/microsoft/TaskMatrix) | 33900 | ğŸ” ğŸ–¼ï¸ğŸ“± | TaskMatrix connects ChatGPT and a series of Visual Foundation Models to enable sending and receiving images during chatting. |
| 2023-03-01 | [Shiriluz/Word-As-Image](https://github.com/Shiriluz/Word-As-Image) | 984 | ğŸ–¼ï¸ğŸ“± |  |
| 2023-02-27 | [KohakuBlueleaf/LyCORIS](https://github.com/KohakuBlueleaf/LyCORIS) | 1353 | ğŸ–¼ï¸ğŸ“ | Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion. |
| 2023-02-27 | [Scholar01/sd-webui-mov2mov](https://github.com/Scholar01/sd-webui-mov2mov) | 1430 | ğŸ–¼ï¸ğŸ”Œ | é€‚ç”¨äºAutomatic1111/stable-diffusion-webui çš„ Mov2mov æ’ä»¶ã€‚ |
| 2023-02-27 | [pkuliyi2015/multidiffusion-upscaler-for-automatic1111](https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111) | 3356 | ğŸ–¼ï¸ğŸ”Œ | Tiled Diffusion and VAE optimize, licensed under CC BY-NC-SA 4.0 |
| 2023-02-26 | [openai/consistency_models](https://github.com/openai/consistency_models) | 5376 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£âœ‚ï¸ | Official repo for consistency models. |
| 2023-02-25 | [hnmr293/sd-webui-llul](https://github.com/hnmr293/sd-webui-llul) | 661 | ğŸ–¼ï¸ğŸ”Œ | LLuL - Local Latent upscaLer |
| 2023-02-23 | [coolzilj/Blender-ControlNet](https://github.com/coolzilj/Blender-ControlNet) | 685 | ğŸ–¼ï¸ğŸ”Œ | Using ControlNet right in Blender. |
| 2023-02-23 | [kale5195/chilloutai](https://github.com/kale5195/chilloutai) | 752 | ğŸ–¼ï¸ğŸ“ | AI å›¾ç‰‡ç”Ÿæˆ |
| 2023-02-21 | [Nutlope/roomGPT](https://github.com/Nutlope/roomGPT) | 8237 | ğŸ–¼ï¸ğŸ“± | Upload a photo of your room to generate your dream room with AI. |
| 2023-02-19 | [prompt-engineering/understand-prompt](https://github.com/prompt-engineering/understand-prompt) | 3296 | ğŸ” ğŸ–¼ï¸ğŸ“ | ã€ğŸ”ğŸ”ğŸ” å†…å«ä¸é€‚åˆæœªæˆå¹´äººé˜…è¯»çš„å›¾ç‰‡ã€‘åŸºäºæˆ‘æ“…é•¿çš„ç¼–ç¨‹ã€ç»˜ç”»ã€å†™ä½œå±•å¼€çš„ AI æ¢ç´¢å’Œæ€»ç»“ï¼šStableDiffusion æ˜¯ä¸€ç§å¼ºå¤§çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œèƒ½å¤Ÿé€šè¿‡å¯¹ä¸€å¼ å›¾ç‰‡è¿›è¡Œæ¼”åŒ–æ¥ç”Ÿæˆæ–°çš„å›¾ç‰‡ã€‚ChatGPT æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„è¯­è¨€ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿè‡ªåŠ¨ä¸ºè¾“å…¥çš„ä¸»é¢˜ç”Ÿæˆåˆé€‚çš„æ–‡ç« ã€‚è€Œ Github Copilot æ˜¯ä¸€ä¸ªæ™ºèƒ½ç¼–ç¨‹åŠ©æ‰‹ï¼Œèƒ½å¤ŸåŠ é€Ÿæ—¥å¸¸ç¼–ç¨‹æ´»åŠ¨ã€‚ |
| 2023-02-15 | [TencentARC/T2I-Adapter](https://github.com/TencentARC/T2I-Adapter) | 2229 | ğŸ” ğŸ–¼ï¸ğŸšŒ | T2I-Adapter |
| 2023-02-13 | [replicate/scribble-diffusion](https://github.com/replicate/scribble-diffusion) | 2578 | ğŸ–¼ï¸ğŸ“± | Turn your rough sketch into a refined image using AI |
| 2023-02-12 | [Mikubill/sd-webui-controlnet](https://github.com/Mikubill/sd-webui-controlnet) | 12055 | ğŸ–¼ï¸ğŸ”Œ | WebUI extension for ControlNet |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | 22696 | ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ | Let us control diffusion models! |
| 2023-01-20 | [deep-floyd/IF](https://github.com/deep-floyd/IF) | 6993 | ğŸ–¼ï¸ğŸšŒ |  |
| 2023-01-17 | [comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | 10507 | ğŸ–¼ï¸ğŸ”¨ | A powerful and modular stable diffusion GUI with a graph/nodes interface. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 5091 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2023-01-08 | [dair-ai/ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | 4604 | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | ğŸ”¥Highlighting the top ML papers every week. |
| 2022-12-20 | [AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin](https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin) | 4945 | ğŸ–¼ï¸ğŸ”Œ | A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.  |
| 2022-12-15 | [godly-devotion/MochiDiffusion](https://github.com/godly-devotion/MochiDiffusion) | 6247 | ğŸ–¼ï¸ğŸ”¨ | Run Stable Diffusion on Mac natively |
| 2022-12-08 | [cloneofsimo/lora](https://github.com/cloneofsimo/lora) | 5504 | ğŸ–¼ï¸2ï¸âƒ£ | Using Low-rank adaptation to quickly fine-tune diffusion models. |
| 2022-12-06 | [openai/point-e](https://github.com/openai/point-e) | 5752 | ğŸ–¼ï¸ğŸšŒğŸ§Š | Point cloud diffusion for 3D model synthesis |
| 2022-12-05 | [shinework/photoshot](https://github.com/shinework/photoshot) | 2313 | ğŸ–¼ï¸ğŸ“± | An open-source AI avatar generator web app - https://photoshot.app |
| 2022-11-25 | [riffusion/riffusion](https://github.com/riffusion/riffusion) | 2438 | ğŸ–¼ï¸ğŸµğŸ“± | Stable diffusion for real-time music generation |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | 6051 | ğŸ–¼ï¸ğŸµğŸ¥ğŸšŒ`2ï¸âƒ£` | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-23 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | 28799 | ğŸ–¼ï¸â›½ğŸšŒ | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-11-20 | [riffusion/riffusion-app](https://github.com/riffusion/riffusion-app) | 2416 | ğŸ–¼ï¸ğŸµğŸ“± | Stable diffusion for real-time music generation (web app) |
| 2022-11-16 | [apple/ml-stable-diffusion](https://github.com/apple/ml-stable-diffusion) | 14215 | ğŸ–¼ï¸ğŸ’¡ | Stable Diffusion with Core ML on Apple Silicon |
| 2022-10-30 | [bmaltais/kohya_ss](https://github.com/bmaltais/kohya_ss) | 5241 | ğŸ–¼ï¸ğŸ”¨ | This repository provides a Windows-focused Gradio GUI for Kohya's Stable Diffusion trainers. The GUI allows you to set the training parameters and generate and run the required CLI commands to train the model. |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2730 | ğŸ” ğŸ–¼ï¸`ğŸ¥`â›½ğŸšŒ2ï¸âƒ£ | An open-source framework for training large multimodal models. |
| 2022-10-18 | [runwayml/stable-diffusion](https://github.com/runwayml/stable-diffusion) | 2902 | ğŸ–¼ï¸ğŸšŒ | Latent Text-to-Image Diffusion |
| 2022-10-14 | [ai-forever/Kandinsky-2](https://github.com/ai-forever/Kandinsky-2) | 2314 | ğŸ–¼ï¸ğŸ“± | Kandinsky 2 â€” multilingual text2image latent diffusion model |
| 2022-10-13 | [huggingface/diffusion-models-class](https://github.com/huggingface/diffusion-models-class) | 2508 | ğŸ–¼ï¸ğŸ“ | Materials for the Hugging Face Diffusion Models Course |
| 2022-10-11 | [civitai/civitai](https://github.com/civitai/civitai) | 4413 | ğŸ–¼ï¸ğŸ”Œ | A repository of models, textual inversions, and more |
| 2022-10-08 | [hua1995116/awesome-ai-painting](https://github.com/hua1995116/awesome-ai-painting) | 9308 | ğŸ–¼ï¸ğŸ“ | AIç»˜ç”»èµ„æ–™åˆé›†ï¼ˆåŒ…å«å›½å†…å¤–å¯ä½¿ç”¨å¹³å°ã€ä½¿ç”¨æ•™ç¨‹ã€å‚æ•°æ•™ç¨‹ã€éƒ¨ç½²æ•™ç¨‹ã€ä¸šç•Œæ–°é—»ç­‰ç­‰ï¼‰ stable diffusion tutorialã€disco diffusion tutorialã€ AI Platform |
| 2022-10-06 | [ashawkey/stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | 6553 | ğŸ–¼ï¸ğŸšŒğŸ§Š | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-10-05 | [camenduru/stable-diffusion-webui-colab](https://github.com/camenduru/stable-diffusion-webui-colab) | 13351 | ğŸ–¼ï¸ğŸ”¨ | stable diffusion webui colab |
| 2022-10-03 | [google/prompt-to-prompt](https://github.com/google/prompt-to-prompt) | 2289 | ğŸ–¼ï¸ğŸ“± | Null-text inversion enables intuitive text-based editing of real images with the Stable Diffusion model. |
| 2022-09-21 | [TheLastBen/fast-stable-diffusion](https://github.com/TheLastBen/fast-stable-diffusion) | 6432 | ğŸ–¼ï¸ğŸ”¨ | fast-stable-diffusion + DreamBooth |
| 2022-09-17 | [JoePenna/Dreambooth-Stable-Diffusion](https://github.com/JoePenna/Dreambooth-Stable-Diffusion) | 3022 | ğŸ–¼ï¸ğŸ“± | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) by way of Textual Inversion (https://arxiv.org/abs/2208.01618) for Stable Diffusion (https://arxiv.org/abs/2112.10752). Tweaks focused on training faces, objects, and styles. |
| 2022-09-13 | [carefree0910/carefree-creator](https://github.com/carefree0910/carefree-creator) | 2051 | ğŸ–¼ï¸ğŸ”¨ | AI magics meet Infinite draw board. |
| 2022-09-12 | [brycedrennan/imaginAIry](https://github.com/brycedrennan/imaginAIry) | 7272 | ğŸ–¼ï¸ğŸ“± | AI imagined images. Pythonic generation of images. |
| 2022-09-08 | [carson-katri/dream-textures](https://github.com/carson-katri/dream-textures) | 6964 | ğŸ–¼ï¸ğŸ“± | Stable Diffusion built-in to Blender |
| 2022-09-06 | [XavierXiao/Dreambooth-Stable-Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) | 6891 | ğŸ–¼ï¸2ï¸âƒ£ | Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion |
| 2022-09-06 | [divamgupta/diffusionbee-stable-diffusion-ui](https://github.com/divamgupta/diffusionbee-stable-diffusion-ui) | 10736 | ğŸ–¼ï¸ğŸ”¨ | Diffusion Bee is the easiest way to run Stable Diffusion locally on your M1 Mac. Comes with a one-click installer. No dependencies or technical knowledge needed. |
| 2022-09-04 | [swyxio/ai-notes](https://github.com/swyxio/ai-notes) | 3608 | ğŸ” ğŸ–¼ï¸ğŸµğŸ¥ğŸ“ | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
| 2022-09-02 | [lkwq007/stablediffusion-infinity](https://github.com/lkwq007/stablediffusion-infinity) | 3558 | ğŸ–¼ï¸ğŸ“± | Outpainting with Stable Diffusion on an infinite canvas |
| 2022-08-27 | [AbdBarho/stable-diffusion-webui-docker](https://github.com/AbdBarho/stable-diffusion-webui-docker) | 4495 | ğŸ–¼ï¸ğŸ”¨ | Easy Docker setup for Stable Diffusion with user-friendly UI |
| 2022-08-24 | [Sygil-Dev/sygil-webui](https://github.com/Sygil-Dev/sygil-webui) | 7569 | ğŸ–¼ï¸ğŸ”¨ | Stable Diffusion web UI |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 6329 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-23 | [easydiffusion/easydiffusion](https://github.com/easydiffusion/easydiffusion) | 7438 | ğŸ–¼ï¸ğŸ”¨ | Easiest 1-click way to install and use Stable Diffusion on your computer. Provides a browser UI for generating images from text prompts and images. Just enter your text prompt, and see the generated image. |
| 2022-08-22 | [AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) | 97263 | ğŸ–¼ï¸ğŸ”¨ | Stable Diffusion web UI |
| 2022-08-22 | [Stability-AI/stability-sdk](https://github.com/Stability-AI/stability-sdk) | 2320 | ğŸ–¼ï¸ğŸ”¨ | SDK for interacting with stability.ai APIs (e.g. stable diffusion inference) |
| 2022-08-17 | [invoke-ai/InvokeAI](https://github.com/invoke-ai/InvokeAI) | 18189 | ğŸ–¼ï¸ğŸ”Œ | InvokeAI is a leading creative engine for Stable Diffusion models, empowering professionals, artists, and enthusiasts to generate and create visual media using the latest AI-driven technologies. The solution offers an industry leading WebUI, supports terminal use through a CLI, and serves as the foundation for multiple commercial products. |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | 59065 | ğŸ–¼ï¸â›½ğŸšŒ | A latent text-to-image diffusion model |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | 2547 | ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£ |  |
| 2022-07-25 | [modelscope/modelscope](https://github.com/modelscope/modelscope) | 3490 | ğŸ” ğŸ–¼ï¸ğŸµ2ï¸âƒ£ | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-07-15 | [facebookincubator/AITemplate](https://github.com/facebookincubator/AITemplate) | 4154 | ğŸ–¼ï¸ğŸ’¡ | AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference. |
| 2022-07-03 | [willwulfken/MidJourney-Styles-and-Keywords-Reference](https://github.com/willwulfken/MidJourney-Styles-and-Keywords-Reference) | 10637 | ğŸ–¼ï¸ğŸ“ | A reference containing Styles and Keywords that you can use with MidJourney AI. There are also pages showing resolution comparison, image weights, and much more! |
| 2022-06-30 | [jina-ai/discoart](https://github.com/jina-ai/discoart) | 3823 | ğŸ–¼ï¸ğŸ”¨ | ğŸª© Create Disco Diffusion artworks in one line |
| 2022-05-30 | [huggingface/diffusers](https://github.com/huggingface/diffusers) | 17260 | ğŸ–¼ï¸ğŸµ2ï¸âƒ£ğŸ“ | ğŸ¤— Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
