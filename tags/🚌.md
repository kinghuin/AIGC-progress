| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-19 | [FlagAlpha/Llama2-Chinese](https://github.com/FlagAlpha/Llama2-Chinese) | 28 | 🔠⛽🚌2️⃣💰🀄 | 最好的中文Llama大模型，完全开源可商用 |
| 2023-07-19 | [michael-wzhu/Chinese-LlaMA2](https://github.com/michael-wzhu/Chinese-LlaMA2) | 121 | 🔠`🚌``🚕``1️⃣``2️⃣`💰🀄 | Repo for adapting Meta LlaMA2 in Chinese! META最新发布的LlaMA2的汉化版！ （完全开源可商用） |
| 2023-07-18 | [ymcui/Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 125 | 🔠`🚌``1️⃣``2️⃣`💰🀄 | 中文LLaMA-2 & Alpaca-2大语言模型 (Chinese LLaMA-2 & Alpaca-2 LLMs) |
| 2023-07-17 | [facebookresearch/llama-recipes](https://github.com/facebookresearch/llama-recipes) | 445 | 🔠🚌2️⃣ | Examples and recipes for Llama 2 model |
| 2023-07-16 | [magic-research/bubogpt](https://github.com/magic-research/bubogpt) | 58 | 🔠🖼️⛽🚌 | BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs |
| 2023-07-11 | [baaivision/Emu](https://github.com/baaivision/Emu) | 377 | 🔠🖼️🚌 | Emu: An Open Multimodal Generalist |
| 2023-07-10 | [baichuan-inc/Baichuan-13B](https://github.com/baichuan-inc/Baichuan-13B) | 1687 | 🔠🚌✂️ | A 13B large language model developed by Baichuan Intelligent Technology |
| 2023-07-08 | [Yujun-Shi/DragDiffusion](https://github.com/Yujun-Shi/DragDiffusion) | 348 | 🖼️🚌2️⃣ | Official code for DragDiffusion |
| 2023-07-06 | [CStanKonrad/long_llama](https://github.com/CStanKonrad/long_llama) | 807 | 🔠🚌 | LongLLaMA is a large language model capable of handling long contexts. It is based on OpenLLaMA and fine-tuned with the Focused Transformer (FoT) method. |
| 2023-07-06 | [InternLM/InternLM](https://github.com/InternLM/InternLM) | 2147 | 🔠🚌2️⃣🀄 | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-06 | [jshilong/GPT4RoI](https://github.com/jshilong/GPT4RoI) | 267 | 🔠🖼️⛽`🚌`2️⃣ | GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest |
| 2023-07-05 | [OpenLMLab/MOSS-RLHF](https://github.com/OpenLMLab/MOSS-RLHF) | 543 | 🔠🚌3️⃣🀄 | MOSS-RLHF |
| 2023-07-04 | [LPengYang/FreeDrag](https://github.com/LPengYang/FreeDrag) | 253 | 🖼️🚌 | Official Implementation of FreeDrag |
| 2023-07-04 | [text2cinemagraph/text2cinemagraph](https://github.com/text2cinemagraph/text2cinemagraph) | 126 | 🔠🎥🚌2️⃣ | Official Pytorch implementation of Text2Cinemagraph: Synthesizing Artistic Cinemagraphs from Text |
| 2023-07-04 | [zideliu/StyleDrop-PyTorch](https://github.com/zideliu/StyleDrop-PyTorch) | 393 | 🖼️⛽🚌2️⃣ | Unoffical implement for [StyleDrop](https://arxiv.org/abs/2306.00983) |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | 670 | 🔠🖼️🚌`2️⃣`🀄 | Chinese and English Multimodal Large Model Series (Chat and Paint) \| 基于CPM基础模型的中英双语多模态大模型系列 |
| 2023-06-28 | [gmltmd789/UnitSpeech](https://github.com/gmltmd789/UnitSpeech) | 67 | 🎵🚌2️⃣ | An official implementation of "UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data" |
| 2023-06-24 | [THUDM/ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B) | 9515 | 🔠🚌✂️🀄 | ChatGLM2-6B: An Open Bilingual Chat LLM \| 开源双语对话语言模型 |
| 2023-06-23 | [salesforce/xgen](https://github.com/salesforce/xgen) | 635 | 🔠🚌 | Salesforce open-source LLMs with 8k sequence length. |
| 2023-06-22 | [Stability-AI/generative-models](https://github.com/Stability-AI/generative-models) | 3057 | 🖼️⛽🚌2️⃣ | Generative Models by Stability AI |
| 2023-06-17 | [guoyww/AnimateDiff](https://github.com/guoyww/AnimateDiff) | 1921 | 🔠🎥🚌 | Official implementation of AnimateDiff. |
| 2023-06-16 | [ictnlp/BayLing](https://github.com/ictnlp/BayLing) | 214 | 🔠🚌 |  “百聆”是一个具有增强的语言对齐的英语/中文大语言模型，具有优越的英语/中文能力，在多项测试中取得ChatGPT 90%的性能。BayLing is an English/Chinese LLM equipped with advanced language alignment, showing superior capability in English/Chinese generation, instruction following and multi-turn interaction. |
| 2023-06-14 | [baichuan-inc/Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 4562 | 🔠⛽🚌🀄 | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-13 | [SizheAn/PanoHead](https://github.com/SizheAn/PanoHead) | 1300 | 🖼️🚌2️⃣🧊 | Code Repository for CVPR 2023 Paper "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360 degree" |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | 1025 | 🔠⛽🚌2️⃣🀄 | 第一个开源的基于QLoRA的33B中文大语言模型First QLoRA based open source 33B Chinese LLM |
| 2023-06-09 | [allenai/open-instruct](https://github.com/allenai/open-instruct) | 321 | 🔠⛽🚌2️⃣ | We explore instruction-tuning popular base models on publicly available datasets. |
| 2023-06-08 | [facebookresearch/audiocraft](https://github.com/facebookresearch/audiocraft) | 8732 | 🎵🚌`2️⃣` | Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
| 2023-06-05 | [RUC-GSAI/YuLan-Chat](https://github.com/RUC-GSAI/YuLan-Chat) | 223 | 🔠🚌✂️ | YuLan-Chat: An Open-Source Bilingual Chatbot |
| 2023-06-03 | [InternLM/InternLM-techreport](https://github.com/InternLM/InternLM-techreport) | 834 | 🔠`🚌` | We present InternLM, a multilingual foundational language model with 104B parameters. InternLM is pre-trained on a large corpora with 1.6T tokens with a multi-phase progressive process, and then fine-tuned to align with human preferences. |
| 2023-06-01 | [damo-vilab/videocomposer](https://github.com/damo-vilab/videocomposer) | 512 | 🔠🎥🚌 | Official repo for VideoComposer: Compositional Video Synthesis with Motion Controllability |
| 2023-05-31 | [xaviviro/refacer](https://github.com/xaviviro/refacer) | 265 | 🎥🚌 | Refacer: One-Click Deepfake Multi-Face Swap Tool |
| 2023-05-31 | [yuchenlin/LLM-Blender](https://github.com/yuchenlin/LLM-Blender) | 445 | 🔠⛽🚌2️⃣ | [ACL2023] We introduce LLM-Blender, an innovative ensembling framework to attain consistently superior performance by leveraging the diverse strengths of multiple open-source LLMs. LLM-Blender cut the weaknesses through ranking and integrate the strengths through fusing generation to enhance the capability of LLMs. |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | 1156 | 🔠⛽🚌2️⃣📱🀄 | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-25 | [imoneoi/openchat](https://github.com/imoneoi/openchat) | 1378 | 🔠⛽🚌🚕2️⃣ | OpenChat: Less is More for Open-source Models |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | 118 | 🔠⛽🚌2️⃣ | SAIL: Search Augmented Instruction Learning |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | 255 | 🔠⛽`🚌`2️⃣ | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | 478 | 🔠🖼️⛽🚌 | 🩺 首个会看胸部X光片的中文多模态医学大模型 \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1096 | 🔠🖼️🎵⛽🚌2️⃣ | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [SHI-Labs/Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | 559 | 🖼️🚌 | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | 4581 | 🔠⛽🚌`2️⃣`🔨💰 | Gorilla: An API store for LLMs |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 522 | 🖼️🚌1️⃣2️⃣ | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | 396 | 🖼️`🚌``2️⃣` | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [mbzuai-oryx/Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | 408 | 🔠🎥⛽🚌2️⃣ | "Video-ChatGPT" is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. We also introduce a rigorous 'Quantitative Evaluation Benchmarking' for video-based conversational models. |
| 2023-05-18 | [salesforce/UniControl](https://github.com/salesforce/UniControl) | 344 | 🖼️🚌 | Unified Controllable Visual Generation Model |
| 2023-05-18 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | 554 | 🔠🖼️🚌2️⃣ | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | 426 | 🖼️`⛽`🚌`2️⃣` | FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | 517 | 🔠🎵`⛽``🚌``2️⃣` | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-16 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | 556 | 🔠⛽🚌2️⃣ | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | 704 | 🔠⛽🚌2️⃣3️⃣ | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-13 | [HeliosZhao/Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | 251 | 🎥🚌`2️⃣` | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | 1593 | 🔠⛽🚌1️⃣2️⃣ | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 388 | 🔠⛽🚌1️⃣2️⃣🀄 | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-07 | [conceptofmind/PaLM](https://github.com/conceptofmind/PaLM) | 634 | 🔠🚌2️⃣ | An open-source implementation of Google's PaLM models |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1274 | 🔠🎥🚌1️⃣2️⃣ | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 1823 | 🔠🖼️🚌`1️⃣`2️⃣ | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-05-04 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | 1092 | 🖼️⛽🚌2️⃣ | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | 825 | 🔠⛽🚌2️⃣ | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [IBM/Dromedary](https://github.com/IBM/Dromedary) | 949 | 🔠🚌2️⃣ | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-03 | [melodysdreamj/WizardVicunaLM](https://github.com/melodysdreamj/WizardVicunaLM) | 601 | 🔠🚌 | LLM that combines the principles of wizardLM and vicunaLM |
| 2023-05-03 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | 470 | 🔠⛽🚌2️⃣ | A simulation framework for RLHF and alternatives. Develop your RLHF method without collecting human data.  |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | 834 | 🔠⛽🚌🀄 | Panda: 海外中文开源大语言模型，基于 Llama-7B, -13B, -33B, -65B 进行中文领域上的持续预训练。 |
| 2023-04-28 | [mosaicml/llm-foundry](https://github.com/mosaicml/llm-foundry) | 2780 | 🔠🚌2️⃣ | LLM training code for MosaicML foundation models |
| 2023-04-28 | [openlm-research/open_llama](https://github.com/openlm-research/open_llama) | 6308 | 🔠🚌💰 | In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. |
| 2023-04-28 | [replit/ReplitLM](https://github.com/replit/ReplitLM) | 807 | 🔠⛽🚌 | Inference code and configs for the ReplitLM model family |
| 2023-04-27 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | 261 | 🖼️⛽🚌2️⃣ | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [OpenBuddy/OpenBuddy](https://github.com/OpenBuddy/OpenBuddy) | 734 | 🔠🚌🀄 | Open Multilingual Chatbot for Everyone |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | 1106 | 🔠🖼️⛽🚌 | Multimodal-GPT |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | 1195 | 🔠🖼️⛽🚌2️⃣ | mPLUG-Owl🦉: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | 530 | 🔠🖼️⛽🚌2️⃣ | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 3014 | 🔠🖼️⛽🚌2️⃣✂️🀄 | Chinese and English multimodal conversational language model \| 多模态中英双语对话语言模型 |
| 2023-04-23 | [mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | 688 | 🔠⛽🚌 | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | 4143 | 🔠⛽🚌2️⃣ | Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | 736 | 🔠🖼️🚌2️⃣✂️ | MiniGPT-4 中文部署翻译 完善部署细节 |
| 2023-04-19 | [Stability-AI/StableLM](https://github.com/Stability-AI/StableLM) | 15017 | 🔠🚌 | StableLM: Stability AI Language Models |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 2286 | 🔠⛽🚌2️⃣💰 | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 3640 | 🔠🖼️⛽🚌1️⃣2️⃣ | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | 11217 | 🔠⛽🚌✂️💰🀄 | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 21654 | 🔠🖼️🚌1️⃣2️⃣ | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-10 | [GanjinZero/RRHF](https://github.com/GanjinZero/RRHF) | 596 | 🔠⛽🚌3️⃣ | RRHF & Wombat |
| 2023-04-10 | [declare-lab/tango](https://github.com/declare-lab/tango) | 708 | 🔠🎵🚌2️⃣ | Codes and Model of the paper "Text-to-Audio Generation using Instruction Tuned LLM and Latent Diffusion Model" |
| 2023-04-09 | [geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 3716 | 🖼️🎥🚌🧊 | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | 2131 | 🖼️🚌2️⃣🧊 | A unified framework for 3D content generation. |
| 2023-04-03 | [VideoCrafter/VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | 1888 | 🔠🎥🚌`2️⃣` | A Toolkit for Text-to-Video Generation and Editing |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | 1048 | 🔠⛽🚌2️⃣✂️🀄 | Firefly(流萤): 中文对话式大语言模型(全量微调+QLoRA) |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | 2495 | 🔠⛽🚌2️⃣✂️📝 | ⚡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.⚡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | 2150 | 🔠🖼️⛽🚌2️⃣ | 🦦 Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following and in-context learning ability. |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | 626 | 🔠⛽🚌🀄 | 骆驼:A Chinese finetuned instruction LLaMA. Developed by 陈启源 @ 华中师范大学 & 李鲁鲁 @ 商汤科技 & 冷子昂 @ 商汤科技 |
| 2023-03-31 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | 2948 | 🔠⛽🚌2️⃣ | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-03-30 | [AetherCortex/Llama-X](https://github.com/AetherCortex/Llama-X) | 1296 | 🔠`🚌`2️⃣ | Open Academic Research on Improving LLaMA to SOTA LLM |
| 2023-03-30 | [mayuelala/FollowYourPose](https://github.com/mayuelala/FollowYourPose) | 617 | 🎥🚌2️⃣ | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | 646 | 🔠⛽🚌2️⃣ | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | 6920 | 🔠⛽🚌2️⃣3️⃣ | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All. |
| 2023-03-24 | [databrickslabs/dolly](https://github.com/databrickslabs/dolly) | 10458 | 🔠⛽🚌2️⃣💰 | Databricks’ Dolly, a large language model trained on the Databricks Machine Learning Platform |
| 2023-03-24 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | 5382 | 🔠🚌2️⃣💰 | Private Q&A and summarization of documents+images or chat with local GPT, 100% private, no data leaks, Apache 2.0. Demo: https://gpt.h2o.ai/ |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 3847 | 🔠🚌2️⃣✂️🀄 | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca |
| 2023-03-23 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | 1077 | 🖼️🚌`2️⃣`🧊 | [ICCV 2023] Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | 4866 | 🔠🚌1️⃣2️⃣✂️💰 | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2315 | 🔠⛽🚌1️⃣2️⃣`3️⃣`✂️💡💰🀄 | Chinese-LLaMA 、Chinese-Falcon 基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | 3116 | 🔠⛽🚌🀄 | 骆驼(Luotuo): Open Sourced Chinese Language Models. Developed by 陈启源 @ 华中师范大学 & 李鲁鲁 @ 商汤科技 & 冷子昂 @ 商汤科技 |
| 2023-03-21 | [Picsart-AI-Research/Text2Video-Zero](https://github.com/Picsart-AI-Research/Text2Video-Zero) | 3069 | 🎥🚌 | Text-to-Image Diffusion Models are Zero-Shot Video Generators, ICCV 2023 |
| 2023-03-21 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | 623 | 🎥⛽🚌2️⃣ | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-21 | [lukasHoel/text2room](https://github.com/lukasHoel/text2room) | 746 | 🔠🖼️🚌🧊 | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models (ICCV2023). |
| 2023-03-19 | [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 4416 | 🔠🖼️⛽🚌2️⃣ | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | 25149 | 🔠🚌2️⃣💰 | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5. |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | 1203 | 🔠⛽🚌2️⃣ | KoAlpaca: 한국어 명령어를 이해하는 오픈소스 언어모델 |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | 6247 | 🔠⛽🚌2️⃣✂️🀄 | BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型） |
| 2023-03-16 | [AIGC-Audio/AudioGPT](https://github.com/AIGC-Audio/AudioGPT) | 8934 | 🔠🎵🚌 | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head |
| 2023-03-16 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | 763 | 🔠🎥⛽🚌2️⃣ | Pytorch Implementation for [ICCV 2023] "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-15 | [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | 6232 | 🎵🚌2️⃣ | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-14 | [lllyasviel/ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | 3061 | 🖼️🚌 | Nightly release of ControlNet 1.1 |
| 2023-03-13 | [KU-CVLAB/3DFuse](https://github.com/KU-CVLAB/3DFuse) | 621 | 🖼️🚌🧊 | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | 32191 | 🔠🚌2️⃣✂️🀄 | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| 开源双语对话语言模型 |
| 2023-03-13 | [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) | 16335 | 🔠🚌2️⃣ | Instruct-tune LLaMA on consumer hardware |
| 2023-03-10 | [svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | 17205 | 🎵🚌2️⃣ | SoftVC VITS Singing Voice Conversion |
| 2023-03-10 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | 25891 | 🔠⛽🚌2️⃣ | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-10 | [thu-ml/unidiffuser](https://github.com/thu-ml/unidiffuser) | 1000 | 🖼️🚌 | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | 2574 | 🔠🖼️🚌`2️⃣` | The official implementation of "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-04 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | 903 | 🎵⛽🚌2️⃣ | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8681 | 🔠⛽🚌1️⃣2️⃣ |  |
| 2023-02-26 | [openai/consistency_models](https://github.com/openai/consistency_models) | 5336 | 🖼️🚌2️⃣✂️ | Official repo for consistency models. |
| 2023-02-15 | [TencentARC/T2I-Adapter](https://github.com/TencentARC/T2I-Adapter) | 2063 | 🔠🖼️🚌 | T2I-Adapter |
| 2023-02-14 | [facebookresearch/llama](https://github.com/facebookresearch/llama) | 27766 | 🔠🚌 | Inference code for LLaMA models |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | 21973 | 🖼️🚌2️⃣ | Let us control diffusion models! |
| 2023-01-27 | [lucidrains/musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | 2616 | 🎵🚌2️⃣✂️ | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-20 | [deep-floyd/IF](https://github.com/deep-floyd/IF) | 6894 | 🖼️🚌 |  |
| 2023-01-13 | [BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV) | 8432 | 🔠🚌 | ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | 4962 | 🖼️⛽🚌2️⃣ | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 22901 | 🔠⛽🚌1️⃣2️⃣ | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-25 | [showlab/Tune-A-Video](https://github.com/showlab/Tune-A-Video) | 3441 | 🎥🚌 | Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation |
| 2022-12-06 | [openai/point-e](https://github.com/openai/point-e) | 5671 | 🖼️🚌🧊 | Point cloud diffusion for 3D model synthesis |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | 5398 | 🖼️🎵🎥🚌`2️⃣` | [CVPR 2023] SadTalker：Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-23 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | 27230 | 🖼️⛽🚌 | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-10-22 | [prophesier/diff-svc](https://github.com/prophesier/diff-svc) | 2329 | 🎵🚌2️⃣ | Singing Voice Conversion via diffusion model |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2512 | 🔠🖼️`🎥`⛽🚌2️⃣ | An open-source framework for training large multimodal models. |
| 2022-10-18 | [runwayml/stable-diffusion](https://github.com/runwayml/stable-diffusion) | 2813 | 🖼️🚌 | Latent Text-to-Image Diffusion |
| 2022-10-06 | [ashawkey/stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | 6316 | 🖼️🚌🧊 | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | 2298 | 🎥⛽🚌2️⃣ | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-25 | [ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp) | 21123 | 🎵🚌✂️ | Port of OpenAI's Whisper model in C/C++ |
| 2022-09-16 | [openai/whisper](https://github.com/openai/whisper) | 41463 | 🔠🎵🚌 | Robust Speech Recognition via Large-Scale Weak Supervision |
| 2022-09-09 | [williamyang1991/VToonify](https://github.com/williamyang1991/VToonify) | 3225 | 🎥🚌2️⃣ | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 5975 | 🔠🖼️⛽🚌1️⃣2️⃣ | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | 57941 | 🖼️⛽🚌 | A latent text-to-image diffusion model |
| 2022-08-03 | [THUDM/GLM-130B](https://github.com/THUDM/GLM-130B) | 6794 | 🔠🚌 | GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023) |
| 2022-08-02 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | 2493 | 🖼️⛽🚌2️⃣ |  |
