| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-08-26 | [whishper](https://github.com/pluja/whishper) | 91 | ğŸµ ğŸ”¨ `Svelte`  | Transcribe any audio to text, translate and edit subtitles 100% locally with a web UI. Powered by whisper models! |
| 2023-08-25 | [awesome-ai-tools](https://github.com/mahseema/awesome-ai-tools) | 75 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | A curated list of Artificial Intelligence Top Tools |
| 2023-08-22 | [seamless-m4t-colab](https://github.com/camenduru/seamless-m4t-colab) | 102 | ğŸµ ğŸ“  |  |
| 2023-08-18 | [awesome-large-audio-models](https://github.com/EmulationAI/awesome-large-audio-models) | 106 | ğŸµ ğŸ“  | Collection of resources on the applications of Large Language Models (LLMs) in Audio AI. |
| 2023-08-14 | [AIVoiceChat](https://github.com/KoljaB/AIVoiceChat) | 48 | ğŸµ ğŸ”¨ `Python`  | Low latency ai companion voice talk in 60 lines of code using faster_whisper and elevenlabs input streaming |
| 2023-08-14 | [song-solver](https://github.com/przadka/song-solver) | 37 | ğŸµ ğŸ”¨ `Python`  | A Python application that allows users to sing in front of their laptop's microphone, processes the recording using the Whisper API, and then leverages a Large Language Model (LLM) to recognize the song. |
| 2023-08-12 | [whisper.api](https://github.com/innovatorved/whisper.api) | 731 | ğŸµ ğŸ”¨ `Python`  | This project provides an API with user level access support to transcribe speech to text using a finetuned and processed Whisper ASR model. |
| 2023-08-04 | [AudioLDM2](https://github.com/haoheliu/AudioLDM2) | 1372 | ğŸ”  ğŸµ ğŸš•  | Text-to-Audio/Music Generation |
| 2023-08-01 | [seamless_communication](https://github.com/facebookresearch/seamless_communication) | 4637 | ğŸµ ğŸ”¨ `Python`  | Foundational Models for State-of-the-Art Speech and Text Translation |
| 2023-07-31 | [LLaSM](https://github.com/LinkSoul-AI/LLaSM) | 193 | ğŸ”  ğŸµ ğŸšŒ ğŸ’° ğŸ€„  | ç¬¬ä¸€ä¸ªæ”¯æŒä¸­è‹±æ–‡åŒè¯­è¯­éŸ³-æ–‡æœ¬å¤šæ¨¡æ€å¯¹è¯çš„å¼€æºå¯å•†ç”¨å¯¹è¯æ¨¡å‹ã€‚ä¾¿æ·çš„è¯­éŸ³è¾“å…¥å°†å¤§å¹…æ”¹å–„ä»¥æ–‡æœ¬ä¸ºè¾“å…¥çš„å¤§æ¨¡å‹çš„ä½¿ç”¨ä½“éªŒï¼ŒåŒæ—¶é¿å…äº†åŸºäº ASR è§£å†³æ–¹æ¡ˆçš„ç¹çæµç¨‹ä»¥åŠå¯èƒ½å¼•å…¥çš„é”™è¯¯ã€‚ |
| 2023-07-29 | [VALL-E-X](https://github.com/Plachtaa/VALL-E-X) | 4410 | ğŸµ ğŸšŒ  | An open source implementation of Microsoft's VALL-E X zero-shot TTS model. Demo is available in https://plachtaa.github.io |
| 2023-07-26 | [WavJourney](https://github.com/Audio-AGI/WavJourney) | 358 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | WavJourney: Compositional Audio Creation with LLMs |
| 2023-07-23 | [whisper-burn](https://github.com/Gadersd/whisper-burn) | 119 | ğŸµ ğŸ’¡  | A Rust implementation of OpenAI's Whisper model using the burn framework |
| 2023-07-17 | [ChatGLM2-Voice-Cloning](https://github.com/KevinWang676/ChatGLM2-Voice-Cloning) | 321 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Chat with any character you like: ChatGLM2+SadTalker+Voice Cloning \| å’Œå–œæ¬¢çš„è§’è‰²æ²‰æµ¸å¼å¯¹è¯å§ï¼šChatGLM2+å£°éŸ³å…‹éš†+è§†é¢‘å¯¹è¯ |
| 2023-07-15 | [unloop](https://github.com/hugofloresgarcia/unloop) | 252 | ğŸµ ğŸ”¨ `Max`  | a co-creative looper that uses generative modeling to **not** repeat itself.  |
| 2023-07-06 | [whisper-at](https://github.com/YuanGongND/whisper-at) | 137 | ğŸµ ğŸšŒ  | Code and Pretrained Models for Interspeech 2023 Paper "Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong Audio Event Taggers" |
| 2023-07-02 | [openai-whisper-api](https://github.com/Illyism/openai-whisper-api) | 39 | ğŸµ ğŸ”¨ `TypeScript`  | OpenAI Whisper API based on Node.js / Bun.sh in a Docker Container + Google Cloud Run Example |
| 2023-07-02 | [minutes-maker](https://github.com/discus0434/minutes-maker) | 48 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | A web app that automatically generates transcripts and summaries of meetings or lectures. |
| 2023-06-28 | [UnitSpeech](https://github.com/gmltmd789/UnitSpeech) | 88 | ğŸµ ğŸšŒ 2ï¸âƒ£  | An official implementation of "UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data" |
| 2023-06-26 | [RealChar](https://github.com/Shaunwei/RealChar) | 5005 | ğŸ”  ğŸµ ğŸ”¨ `JavaScript`  | ğŸ™ï¸ğŸ¤–Create, Customize and Talk to your AI Character/Companion in Realtime (All in One Codebase!). Have a natural seamless conversation with AI everywhere (mobile, web and terminal) using LLM OpenAI GPT3.5/4, Anthropic Claude2, Chroma Vector DB, Whisper Speech2Text, ElevenLabs Text2SpeechğŸ™ï¸ğŸ¤– |
| 2023-06-16 | [Meta-voicebox](https://github.com/SpeechifyInc/Meta-voicebox) | 447 | ğŸµ 2ï¸âƒ£  | Implementation of Meta-Voicebox : The first generative AI model for speech to generalize across tasks with state-of-the-art performance. |
| 2023-06-14 | [UnrealOpenAIPlugin](https://github.com/life-exe/UnrealOpenAIPlugin) | 73 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `C++`  | This plugin is a comprehensive Unreal Engine wrapper for the OpenAI API. |
| 2023-06-12 | [talk](https://github.com/yacineMTB/talk) | 466 | ğŸµ ğŸ”¨ `TypeScript`  | Let's make sand talk |
| 2023-06-11 | [Bark-Voice-Cloning](https://github.com/KevinWang676/Bark-Voice-Cloning) | 542 | ğŸµ ğŸ”¨ `Jupyter`  | Bark Voice Cloning and Voice Cloning for Chinese Speech |
| 2023-06-09 | [MusicGen-colab](https://github.com/camenduru/MusicGen-colab) | 411 | ğŸµ ğŸ“  |  |
| 2023-06-08 | [audiocraft](https://github.com/facebookresearch/audiocraft) | 15755 | ğŸµ ğŸšŒ 2ï¸âƒ£  | Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
| 2023-06-05 | [FantasyCopilot](https://github.com/Richasy/FantasyCopilot) | 363 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `C#`  | A new-age AI desktop tool |
| 2023-05-31 | [Chat-Haruhi-Suzumiya](https://github.com/LC1332/Chat-Haruhi-Suzumiya) | 699 | ğŸ”  ğŸµ â›½ ğŸš•  | Chatå‡‰å®«æ˜¥æ—¥, ç”±æé²é², å†·å­æ˜‚ç­‰åŒå­¦å¼€å‘çš„æ¨¡ä»¿äºŒæ¬¡å…ƒå¯¹è¯çš„èŠå¤©æœºå™¨äººã€‚ |
| 2023-05-28 | [wingmanAI](https://github.com/e-johnstonn/wingmanAI) | 360 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Real-time transcription of audio, integrated with ChatGPT for interactive use. Save, load, and append transcripts for effective context management in conversations. |
| 2023-05-23 | [Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | 1145 | ğŸ”  ğŸ–¼ï¸ ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [ltu](https://github.com/YuanGongND/ltu) | 99 | ğŸ”  ğŸµ 2ï¸âƒ£  | Github Repo for Paper "Listen, Think, and Understand". |
| 2023-05-19 | [PodcastCopilot](https://github.com/microsoft/PodcastCopilot) | 592 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Build 2023 demo |
| 2023-05-17 | [soundstorm-pytorch](https://github.com/lucidrains/soundstorm-pytorch) | 997 | ğŸµ 2ï¸âƒ£  | Implementation of SoundStorm, Efficient Parallel Audio Generation from Google Deepmind, in Pytorch |
| 2023-05-17 | [awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | 268 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | A curated list of awesome AI tools for game developers |
| 2023-05-16 | [SpeechGPT](https://github.com/0nutation/SpeechGPT) | 562 | ğŸ”  ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-11 | [OpenDAN-Personal-AI-OS](https://github.com/fiatrete/OpenDAN-Personal-AI-OS) | 1256 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | OpenDAN is an open source Personal AI OS , which consolidates various AI modules in one place for your personal use. |
| 2023-05-10 | [awesome-whisper](https://github.com/sindresorhus/awesome-whisper) | 559 | ğŸµ ğŸ“  | ğŸ”Š Awesome list for Whisper â€” an open-source AI-powered speech recognition system developed by OpenAI |
| 2023-05-08 | [ecoute](https://github.com/SevaSk/ecoute) | 5012 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Ecoute is a live transcription tool that provides real-time transcripts for both the user's microphone input (You) and the user's speakers output (Speaker) in a textbox. It also generates a suggested response using OpenAI's GPT-3.5 for the user to say based on the live transcription of the conversation. |
| 2023-04-27 | [Digital_Life_Server](https://github.com/zixiiu/Digital_Life_Server) | 1967 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Yet another voice assistant, but alive. |
| 2023-04-19 | [naturalspeech2-pytorch](https://github.com/lucidrains/naturalspeech2-pytorch) | 915 | ğŸµ 2ï¸âƒ£  | Implementation of Natural Speech 2, Zero-shot Speech and Singing Synthesizer, in Pytorch |
| 2023-04-19 | [quillman](https://github.com/modal-labs/quillman) | 809 | ğŸ”  ğŸµ ğŸ”¨ `JavaScript`  | A chat app that transcribes audio in real-time, streams back a response from a language model, and synthesizes this response as natural-sounding speech. |
| 2023-04-07 | [bark](https://github.com/suno-ai/bark) | 26004 | ğŸ”  ğŸµ ğŸšŒ ğŸ’°  | ğŸ”Š Text-Prompted Generative Audio Model |
| 2023-03-30 | [JARVIS](https://github.com/microsoft/JARVIS) | 21716 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | JARVIS, a system to connect LLMs with ML community. Paper: https://arxiv.org/pdf/2303.17580.pdf |
| 2023-03-27 | [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) | 10753 | ğŸµ ğŸ”¨ `Python`  | Voice data <= 10 mins can also be used to train a good VC model! |
| 2023-03-16 | [AudioGPT](https://github.com/AIGC-Audio/AudioGPT) | 9140 | ğŸ”  ğŸµ ğŸšŒ  | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head |
| 2023-03-16 | [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) | 147730 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | An experimental open-source attempt to make GPT-4 fully autonomous. |
| 2023-03-15 | [so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | 6771 | ğŸµ ğŸšŒ 2ï¸âƒ£  | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-10 | [so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | 18690 | ğŸµ ğŸšŒ 2ï¸âƒ£  | SoftVC VITS Singing Voice Conversion |
| 2023-03-04 | [DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | 1079 | ğŸµ â›½ ğŸšŒ 2ï¸âƒ£  | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-02 | [whisper-jax](https://github.com/sanchit-gandhi/whisper-jax) | 3268 | ğŸµ â“  | JAX implementation of OpenAI's Whisper model for up to 70x speed-up on TPU. |
| 2023-02-26 | [BibiGPT](https://github.com/JimmyLv/BibiGPT) | 4086 | ğŸ”  ğŸµ ğŸ¥ ğŸ”¨ `TypeScript`  | BibiGPT v1 Â· one-Click AI Summary for Audio/Video & Chat with Learning Content: Bilibili \| YouTube \| Tweetä¸¨TikTokä¸¨Dropboxä¸¨Google Driveä¸¨Local files \| Websitesä¸¨Podcasts \| Meetings \| Lectures, etc. éŸ³è§†é¢‘å†…å®¹ AI ä¸€é”®æ€»ç»“ & å¯¹è¯ï¼šå“”å“©å“”å“©ä¸¨YouTubeä¸¨æ¨ç‰¹ä¸¨å°çº¢ä¹¦ä¸¨æŠ–éŸ³ä¸¨å¿«æ‰‹ä¸¨ç™¾åº¦ç½‘ç›˜ä¸¨é˜¿é‡Œäº‘ç›˜ä¸¨ç½‘é¡µä¸¨æ’­å®¢ä¸¨ä¼šè®®ä¸¨æœ¬åœ°æ–‡ä»¶ç­‰ (åŸ BiliGPT çœæµç¥å™¨ & AIè¯¾ä»£è¡¨) |
| 2023-02-24 | [vocode-python](https://github.com/vocodedev/vocode-python) | 1663 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | ğŸ¤– Build voice-based LLM agents. Modular + open source. |
| 2023-02-11 | [VITS-fast-fine-tuning](https://github.com/Plachtaa/VITS-fast-fine-tuning) | 3019 | ğŸµ 2ï¸âƒ£  | This repo is a pipeline of VITS finetuning for fast speaker adaptation TTS, and many-to-many voice conversion |
| 2023-02-11 | [faster-whisper](https://github.com/guillaumekln/faster-whisper) | 4490 | ğŸµ ğŸ’¡  | Faster Whisper transcription with CTranslate2 |
| 2023-01-27 | [musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | 2680 | ğŸµ ğŸšŒ 2ï¸âƒ£ âœ‚ï¸  | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-08 | [ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | 4775 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | ğŸ”¥Highlighting the top ML papers every week. |
| 2023-01-07 | [Whisper](https://github.com/Const-me/Whisper) | 4754 | ğŸµ ğŸ”¨ `C++`  | High-performance GPGPU inference of OpenAI's Whisper automatic speech recognition (ASR) model |
| 2022-12-09 | [whisperX](https://github.com/m-bain/whisperX) | 4843 | ğŸµ ğŸ”¨ `Python`  | WhisperX:  Automatic Speech Recognition with Word-level Timestamps (& Diarization) |
| 2022-11-25 | [riffusion](https://github.com/riffusion/riffusion) | 2474 | ğŸ–¼ï¸ ğŸµ ğŸ”¨ `Python`  | Stable diffusion for real-time music generation |
| 2022-11-23 | [SadTalker](https://github.com/OpenTalker/SadTalker) | 6358 | ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-11-20 | [riffusion-app](https://github.com/riffusion/riffusion-app) | 2423 | ğŸ–¼ï¸ ğŸµ ğŸ”¨ `TypeScript`  | Stable diffusion for real-time music generation (web app) |
| 2022-10-22 | [diff-svc](https://github.com/prophesier/diff-svc) | 2398 | ğŸµ ğŸšŒ 2ï¸âƒ£  | Singing Voice Conversion via diffusion model |
| 2022-10-17 | [Mubert-Text-to-Music](https://github.com/MubertAI/Mubert-Text-to-Music) | 2666 | ğŸ”  ğŸµ ğŸ¥ ğŸ“  | A simple notebook demonstrating prompt-based music generation via Mubert API |
| 2022-09-25 | [whisper.cpp](https://github.com/ggerganov/whisper.cpp) | 22609 | ğŸµ ğŸšŒ âœ‚ï¸  | Port of OpenAI's Whisper model in C/C++ |
| 2022-09-24 | [buzz](https://github.com/chidiwilliams/buzz) | 7220 | ğŸ”  ğŸµ ğŸ”¨ `Python`  | Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAI's Whisper. |
| 2022-09-16 | [whisper](https://github.com/openai/whisper) | 43994 | ğŸ”  ğŸµ ğŸšŒ  | Robust Speech Recognition via Large-Scale Weak Supervision |
| 2022-09-04 | [ai-notes](https://github.com/swyxio/ai-notes) | 3709 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
| 2022-07-25 | [modelscope](https://github.com/modelscope/modelscope) | 3841 | ğŸ”  ğŸ–¼ï¸ ğŸµ 2ï¸âƒ£  | ModelScope: bring the notion of Model-as-a-Service to life. |
| 2022-06-13 | [Fay](https://github.com/TheRamU/Fay) | 5033 | ğŸ”  ğŸµ ğŸ”¨ `JavaScript`  | Fayæ˜¯ä¸€ä¸ªå®Œæ•´çš„å¼€æºé¡¹ç›®ï¼ŒåŒ…å«Fayæ§åˆ¶å™¨åŠæ•°å­—äººæ¨¡å‹ï¼Œå¯çµæ´»ç»„åˆå‡ºä¸åŒçš„åº”ç”¨åœºæ™¯ï¼šè™šæ‹Ÿä¸»æ’­ã€ç°åœºæ¨é”€è´§ã€å•†å“å¯¼è´­ã€è¯­éŸ³åŠ©ç†ã€è¿œç¨‹è¯­éŸ³åŠ©ç†ã€æ•°å­—äººäº’åŠ¨ã€æ•°å­—äººé¢è¯•å®˜åŠå¿ƒç†æµ‹è¯„ã€è´¾ç»´æ–¯ã€Herã€‚ å¼€æºé¡¹ç›®ï¼Œéäº§å“è¯•ç”¨ï¼ï¼ï¼ |
| 2022-05-30 | [diffusers](https://github.com/huggingface/diffusers) | 17580 | ğŸ–¼ï¸ ğŸµ 2ï¸âƒ£ ğŸ“  | ğŸ¤— Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch |
