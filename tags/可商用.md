| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | ![ShishirPatil/gorilla Stars](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣🔨✅ | Gorilla: An API store for LLMs |
| 2023-05-05 | [eugeneyan/open-llms](https://github.com/eugeneyan/open-llms) | ![eugeneyan/open-llms Stars](https://img.shields.io/github/stars/eugeneyan/open-llms.svg?label=&style=flat-square) | 🔠📝✅ | 📋 A list of open LLMs available for commercial use. |
| 2023-04-28 | [openlm-research/open_llama](https://github.com/openlm-research/open_llama) | ![openlm-research/open_llama Stars](https://img.shields.io/github/stars/openlm-research/open_llama.svg?label=&style=flat-square) | 🔠🚌✅ | In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. |
| 2023-04-17 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | ![h2oai/h2o-llmstudio Stars](https://img.shields.io/github/stars/h2oai/h2o-llmstudio.svg?label=&style=flat-square) | 🔠⛽🚌2️⃣✅ | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | ![OpenLMLab/MOSS Stars](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?label=&style=flat-square) | 🔠⛽🚌✂️✅🀄 | An open-source tool-augmented conversational language model from Fudan University |
| 2023-03-24 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | ![h2oai/h2ogpt Stars](https://img.shields.io/github/stars/h2oai/h2ogpt.svg?label=&style=flat-square) | 🔠🚌2️⃣✅ | Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0 |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | ![Lightning-AI/lit-llama Stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama.svg?label=&style=flat-square) | 🔠🚌1️⃣2️⃣✂️✅ | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | 🔠⛽🚌1️⃣2️⃣3️⃣✂️💡✅🀄 | Chinese-LLaMA基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | ![lm-sys/FastChat Stars](https://img.shields.io/github/stars/lm-sys/FastChat.svg?label=&style=flat-square) | 🔠🚌2️⃣✅ | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5. |
