| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-13 | [X-PLUG/CValues](https://github.com/X-PLUG/CValues) | ![X-PLUG/CValues Stars](https://img.shields.io/github/stars/X-PLUG/CValues.svg?label=&style=flat-square) | ğŸ” â›½ğŸ€„â“ | é¢å‘ä¸­æ–‡å¤§æ¨¡å‹ä»·å€¼è§‚çš„è¯„ä¼°ä¸å¯¹é½ç ”ç©¶ |
| 2023-07-06 | [InternLM/InternLM](https://github.com/InternLM/InternLM) | ![InternLM/InternLM Stars](https://img.shields.io/github/stars/InternLM/InternLM.svg?label=&style=flat-square) | ğŸ” ğŸšŒ2ï¸âƒ£ğŸ€„ | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-05 | [OpenLMLab/MOSS-RLHF](https://github.com/OpenLMLab/MOSS-RLHF) | ![OpenLMLab/MOSS-RLHF Stars](https://img.shields.io/github/stars/OpenLMLab/MOSS-RLHF.svg?label=&style=flat-square) | ğŸ” ğŸšŒ3ï¸âƒ£ğŸ€„ | MOSS-RLHF |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | ![OpenBMB/VisCPM Stars](https://img.shields.io/github/stars/OpenBMB/VisCPM.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸ğŸšŒ2ï¸âƒ£ğŸ€„ | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-29 | [IMOSR/MediaGPT](https://github.com/IMOSR/MediaGPT) | ![IMOSR/MediaGPT Stars](https://img.shields.io/github/stars/IMOSR/MediaGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | ä¸­æ–‡çš„è‡ªåª’ä½“å¤§è¯­è¨€æ¨¡å‹MediaGPT(æ›¾ç”¨åMedia LLaMA) |
| 2023-06-24 | [THUDM/ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B) | ![THUDM/ChatGLM2-6B Stars](https://img.shields.io/github/stars/THUDM/ChatGLM2-6B.svg?label=&style=flat-square) | ğŸ” ğŸšŒâœ‚ï¸ğŸ€„ | ChatGLM2-6B: An Open Bilingual Chat LLM \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-06-16 | [haonan-li/CMMLU](https://github.com/haonan-li/CMMLU) | ![haonan-li/CMMLU Stars](https://img.shields.io/github/stars/haonan-li/CMMLU.svg?label=&style=flat-square) | ğŸ” â›½ğŸ€„â“ | CMMLUæ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„ä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚ |
| 2023-06-14 | [baichuan-inc/Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | ![baichuan-inc/Baichuan-7B Stars](https://img.shields.io/github/stars/baichuan-inc/Baichuan-7B.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | ![lyogavin/Anima Stars](https://img.shields.io/github/stars/lyogavin/Anima.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ€„ | ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹First QLoRA based open source 33B Chinese LLM |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | ![shibing624/MedicalGPT Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ğŸ€„ | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | ![THUDM/WebGLM Stars](https://img.shields.io/github/stars/THUDM/WebGLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ“±ğŸ€„ | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | ![Neutralzz/BiLLa Stars](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | ![dandelionsllm/pandallm Stars](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ |
| 2023-04-26 | [OpenBuddy/OpenBuddy](https://github.com/OpenBuddy/OpenBuddy) | ![OpenBuddy/OpenBuddy Stars](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?label=&style=flat-square) | ğŸ” ğŸšŒğŸ€„ | Open Multilingual Chatbot for Everyone |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | ![THUDM/VisualGLM-6B Stars](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?label=&style=flat-square) | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-21 | [lvwzhen/law-cn-ai](https://github.com/lvwzhen/law-cn-ai) | ![lvwzhen/law-cn-ai Stars](https://img.shields.io/github/stars/lvwzhen/law-cn-ai.svg?label=&style=flat-square) | ğŸ” â›½ğŸ“±ğŸ€„ | âš–ï¸ AI æ³•å¾‹åŠ©æ‰‹ |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | ![pengxiao-song/LaWGPT Stars](https://img.shields.io/github/stars/pengxiao-song/LaWGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-18 | [kaqijiang/Auto-GPT-ZH](https://github.com/kaqijiang/Auto-GPT-ZH) | ![kaqijiang/Auto-GPT-ZH Stars](https://img.shields.io/github/stars/kaqijiang/Auto-GPT-ZH.svg?label=&style=flat-square) | ğŸ” ğŸ“±ğŸ€„ | Auto-GPTä¸­æ–‡ç‰ˆæœ¬åŠçˆ±å¥½è€…ç»„ç»‡ åŒæ­¥æ›´æ–°åŸé¡¹ç›® AIé¢†åŸŸåˆ›ä¸š è‡ªåª’ä½“ç»„ç»‡ ç”¨AIå·¥ä½œå­¦ä¹ åˆ›ä½œå˜ç° |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | ![OpenLMLab/MOSS Stars](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒâœ‚ï¸âœ…ğŸ€„ | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | ![hiyouga/ChatGLM-Efficient-Tuning Stars](https://img.shields.io/github/stars/hiyouga/ChatGLM-Efficient-Tuning.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£3ï¸âƒ£ğŸ€„ | Fine-tuning ChatGLM-6B with PEFT \| åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ |
| 2023-04-06 | [liucongg/ChatGLM-Finetuning](https://github.com/liucongg/ChatGLM-Finetuning) | ![liucongg/ChatGLM-Finetuning Stars](https://img.shields.io/github/stars/liucongg/ChatGLM-Finetuning.svg?label=&style=flat-square) | ğŸ” 2ï¸âƒ£ğŸ€„ | åŸºäºChatGLM-6Bæ¨¡å‹ï¼Œè¿›è¡Œä¸‹æ¸¸å…·ä½“ä»»åŠ¡å¾®è°ƒï¼Œæ¶‰åŠFreezeã€Loraã€P-tuningç­‰ |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | ![yangjianxin1/Firefly Stars](https://img.shields.io/github/stars/yangjianxin1/Firefly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹(å…¨é‡å¾®è°ƒ+QLoRA) |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | ![LC1332/Chinese-alpaca-lora Stars](https://img.shields.io/github/stars/LC1332/Chinese-alpaca-lora.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | ![SCIR-HI/Huatuo-Llama-Med-Chinese Stars](https://img.shields.io/github/stars/SCIR-HI/Huatuo-Llama-Med-Chinese.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | Repo for BenTsao [original name: HuaTuo (åé©¼)], Llama-7B tuned with Chinese medical knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMAæ¨¡å‹æŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [imClumsyPanda/langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM) | ![imClumsyPanda/langchain-ChatGLM Stars](https://img.shields.io/github/stars/imClumsyPanda/langchain-ChatGLM.svg?label=&style=flat-square) | ğŸ” ğŸ“±ğŸ€„ | langchain-ChatGLM, local knowledge based ChatGLM with langchain ï½œ åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„ ChatGLM é—®ç­” |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | ![Facico/Chinese-Vicuna Stars](https://img.shields.io/github/stars/Facico/Chinese-Vicuna.svg?label=&style=flat-square) | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£âœ‚ï¸ğŸ’¡âœ…ğŸ€„ | Chinese-LLaMA ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | ![LC1332/Luotuo-Chinese-LLM Stars](https://img.shields.io/github/stars/LC1332/Luotuo-Chinese-LLM.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [yzfly/awesome-chatgpt-zh](https://github.com/yzfly/awesome-chatgpt-zh) | ![yzfly/awesome-chatgpt-zh Stars](https://img.shields.io/github/stars/yzfly/awesome-chatgpt-zh.svg?label=&style=flat-square) | ğŸ” ğŸ“ğŸ€„ | ChatGPT ä¸­æ–‡æŒ‡å—ğŸ”¥ï¼ŒChatGPT ä¸­æ–‡è°ƒæ•™æŒ‡å—ï¼ŒæŒ‡ä»¤æŒ‡å—ï¼Œåº”ç”¨å¼€å‘æŒ‡å—ï¼Œç²¾é€‰èµ„æºæ¸…å•ï¼Œæ›´å¥½çš„ä½¿ç”¨ chatGPT è®©ä½ çš„ç”Ÿäº§åŠ› up up up! ğŸš€ |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | ![LianjiaTech/BELLE Stars](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?label=&style=flat-square) | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | ![hikariming/alpaca_chinese_dataset Stars](https://img.shields.io/github/stars/hikariming/alpaca_chinese_dataset.svg?label=&style=flat-square) | ğŸ” â›½2ï¸âƒ£ğŸ€„ | äººå·¥ç²¾è°ƒçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›†å’Œä¸€æ®µchatglmçš„å¾®è°ƒä»£ç  |
| 2023-03-16 | [mymusise/ChatGLM-Tuning](https://github.com/mymusise/ChatGLM-Tuning) | ![mymusise/ChatGLM-Tuning Stars](https://img.shields.io/github/stars/mymusise/ChatGLM-Tuning.svg?label=&style=flat-square) | ğŸ” 2ï¸âƒ£ğŸ€„ | ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ,  åŸºäºChatGLM-6B + LoRA |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | ![ymcui/Chinese-LLaMA-Alpaca Stars](https://img.shields.io/github/stars/ymcui/Chinese-LLaMA-Alpaca.svg?label=&style=flat-square) | ğŸ” 1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’¡ğŸ€„ | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-14 | [ssbuild/chatglm_finetuning](https://github.com/ssbuild/chatglm_finetuning) | ![ssbuild/chatglm_finetuning Stars](https://img.shields.io/github/stars/ssbuild/chatglm_finetuning.svg?label=&style=flat-square) | ğŸ” 2ï¸âƒ£ğŸ€„ | chatglm 6b finetuning and alpaca finetuning |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | ![THUDM/ChatGLM-6B Stars](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg?label=&style=flat-square) | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-02-11 | [AI4Finance-Foundation/FinGPT](https://github.com/AI4Finance-Foundation/FinGPT) | ![AI4Finance-Foundation/FinGPT Stars](https://img.shields.io/github/stars/AI4Finance-Foundation/FinGPT.svg?label=&style=flat-square) | ğŸ” â›½ğŸš•ğŸ€„ | Data-Centric FinGPT.  Open-source for open finance!  Revolutionize ğŸ”¥    We'll soon release the trained model. |
