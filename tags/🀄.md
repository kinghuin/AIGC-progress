| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-07-13 | [X-PLUG/CValues](https://github.com/X-PLUG/CValues) | 166 | ğŸ” â›½ğŸ€„â“ | é¢å‘ä¸­æ–‡å¤§æ¨¡å‹ä»·å€¼è§‚çš„è¯„ä¼°ä¸å¯¹é½ç ”ç©¶ |
| 2023-07-06 | [InternLM/InternLM](https://github.com/InternLM/InternLM) | 2125 | ğŸ” ğŸšŒ2ï¸âƒ£ğŸ€„ | InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system. |
| 2023-07-05 | [OpenLMLab/MOSS-RLHF](https://github.com/OpenLMLab/MOSS-RLHF) | 527 | ğŸ” ğŸšŒ3ï¸âƒ£ğŸ€„ | MOSS-RLHF |
| 2023-06-30 | [OpenBMB/VisCPM](https://github.com/OpenBMB/VisCPM) | 665 | ğŸ” ğŸ–¼ï¸ğŸšŒ`2ï¸âƒ£`ğŸ€„ | Chinese and English Multimodal Large Model Series (Chat and Paint) \| åŸºäºCPMåŸºç¡€æ¨¡å‹çš„ä¸­è‹±åŒè¯­å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ— |
| 2023-06-29 | [IMOSR/MediaGPT](https://github.com/IMOSR/MediaGPT) | 403 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | ä¸­æ–‡çš„è‡ªåª’ä½“å¤§è¯­è¨€æ¨¡å‹MediaGPT(æ›¾ç”¨åMedia LLaMA) |
| 2023-06-24 | [THUDM/ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B) | 9367 | ğŸ” ğŸšŒâœ‚ï¸ğŸ€„ | ChatGLM2-6B: An Open Bilingual Chat LLM \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-06-16 | [haonan-li/CMMLU](https://github.com/haonan-li/CMMLU) | 126 | ğŸ” â›½ğŸ€„â“ | CMMLUæ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„ğŸ€„è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ğŸ€„è¯­å¢ƒä¸‹çš„çŸ¥è¯†å’ŒğŸ’¡èƒ½åŠ›ã€‚ |
| 2023-06-14 | [baichuan-inc/Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 4538 | ğŸ” â›½ğŸšŒğŸ€„ | A large-scale 7B pretraining language model developed by BaiChuan-Inc. |
| 2023-06-12 | [lyogavin/Anima](https://github.com/lyogavin/Anima) | 1019 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ€„ | ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹First QLoRA based open source 33B Chinese LLM |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | 911 | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ğŸ€„ | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ |
| 2023-05-28 | [THUDM/WebGLM](https://github.com/THUDM/WebGLM) | 1144 | ğŸ” â›½ğŸšŒ2ï¸âƒ£ğŸ“±ğŸ€„ | WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023) |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 387 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | 834 | ğŸ” â›½ğŸšŒğŸ€„ | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ |
| 2023-04-26 | [OpenBuddy/OpenBuddy](https://github.com/OpenBuddy/OpenBuddy) | 730 | ğŸ” ğŸšŒğŸ€„ | Open Multilingual Chatbot for Everyone |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | 2997 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-21 | [lvwzhen/law-cn-ai](https://github.com/lvwzhen/law-cn-ai) | 4323 | ğŸ” â›½ğŸ“±ğŸ€„ | âš–ï¸ AI æ³•å¾‹åŠ©æ‰‹ |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 4968 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-18 | [kaqijiang/Auto-GPT-ZH](https://github.com/kaqijiang/Auto-GPT-ZH) | 2204 | ğŸ” ğŸ“±ğŸ€„ | Auto-GPTä¸­æ–‡ç‰ˆæœ¬åŠçˆ±å¥½è€…ç»„ç»‡ åŒæ­¥æ›´æ–°åŸé¡¹ç›® AIé¢†åŸŸåˆ›ä¸š è‡ªåª’ä½“ç»„ç»‡ ç”¨AIå·¥ä½œå­¦ä¹ åˆ›ä½œå˜ç° |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | 11206 | ğŸ” â›½ğŸšŒâœ‚ï¸ğŸ’°ğŸ€„ | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-08 | [hiyouga/ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | 2318 | ğŸ” â›½2ï¸âƒ£3ï¸âƒ£ğŸ€„ | Fine-tuning ChatGLM-6B with PEFT \| åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ |
| 2023-04-06 | [liucongg/ChatGLM-Finetuning](https://github.com/liucongg/ChatGLM-Finetuning) | 1055 | ğŸ” 2ï¸âƒ£ğŸ€„ | åŸºäºChatGLM-6Bæ¨¡å‹ï¼Œè¿›è¡Œä¸‹æ¸¸å…·ä½“ä»»åŠ¡å¾®è°ƒï¼Œæ¶‰åŠFreezeã€Loraã€P-tuningç­‰ |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | 1028 | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹(å…¨é‡å¾®è°ƒ+QLoRA) |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | 625 | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-31 | [SCIR-HI/Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 3356 | ğŸ” â›½ğŸš•2ï¸âƒ£ğŸ€„ | Repo for BenTsao [original name: HuaTuo (åé©¼)], Llama-7B tuned with Chinese medical knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMAæ¨¡å‹æŒ‡ä»¤å¾®è°ƒ |
| 2023-03-31 | [imClumsyPanda/langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM) | 12095 | ğŸ” ğŸ“±ğŸ€„ | langchain-ChatGLM, local knowledge based ChatGLM with langchain ï½œ åŸºäºæœ¬åœ°çŸ¥è¯†åº“çš„ ChatGLM é—®ç­” |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 3837 | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2303 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£`3ï¸âƒ£`âœ‚ï¸ğŸ’¡ğŸ’°ğŸ€„ | Chinese-LLaMA ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | 3114 | ğŸ” â›½ğŸšŒğŸ€„ | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [yzfly/awesome-chatgpt-zh](https://github.com/yzfly/awesome-chatgpt-zh) | 7687 | ğŸ” ğŸ“ğŸ€„ | ChatGPT ä¸­æ–‡æŒ‡å—ğŸ”¥ï¼ŒChatGPT ä¸­æ–‡è°ƒæ•™æŒ‡å—ï¼ŒæŒ‡ä»¤æŒ‡å—ï¼Œåº”ç”¨å¼€å‘æŒ‡å—ï¼Œç²¾é€‰èµ„æºæ¸…å•ï¼Œæ›´å¥½çš„ä½¿ç”¨ chatGPT è®©ä½ çš„ç”Ÿäº§åŠ› up up up! ğŸš€ |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | 6238 | ğŸ” â›½ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-17 | [hikariming/alpaca_chinese_dataset](https://github.com/hikariming/alpaca_chinese_dataset) | 881 | ğŸ” â›½2ï¸âƒ£ğŸ€„ | äººå·¥ç²¾è°ƒçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›†å’Œä¸€æ®µchatglmçš„å¾®è°ƒä»£ç  |
| 2023-03-16 | [mymusise/ChatGLM-Tuning](https://github.com/mymusise/ChatGLM-Tuning) | 3145 | ğŸ” 2ï¸âƒ£ğŸ€„ | ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ,  åŸºäºChatGLM-6B + LoRA |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 12696 | ğŸ” 1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’¡ğŸ€„ | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-14 | [ssbuild/chatglm_finetuning](https://github.com/ssbuild/chatglm_finetuning) | 1377 | ğŸ” 2ï¸âƒ£ğŸ€„ | chatglm 6b finetuning and alpaca finetuning |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | 32102 | ğŸ” ğŸšŒ2ï¸âƒ£âœ‚ï¸ğŸ€„ | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-02-11 | [AI4Finance-Foundation/FinGPT](https://github.com/AI4Finance-Foundation/FinGPT) | 7178 | ğŸ” â›½ğŸš•ğŸ€„ | Data-Centric FinGPT.  Open-source for open finance!  Revolutionize ğŸ”¥    We'll soon release the trained model. |
