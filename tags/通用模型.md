| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-06-03 | [InternLM/InternLM-techreport](https://github.com/InternLM/InternLM-techreport) | ![InternLM/InternLM-techreport Stars](https://img.shields.io/github/stars/InternLM/InternLM-techreport.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹(TD)` | We present InternLM, a multilingual foundational language model with 104B parameters. InternLM is pre-trained on a large corpora with 1.6T tokens with a multi-phase progressive process, and then fine-tuned to align with human preferences. |
| 2023-05-24 | [luohongyin/SAIL](https://github.com/luohongyin/SAIL) | ![luohongyin/SAIL Stars](https://img.shields.io/github/stars/luohongyin/SAIL.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | SAIL: Search Augmented Instruction Learning |
| 2023-05-23 | [WangRongsheng/XrayGLM](https://github.com/WangRongsheng/XrayGLM) | ![WangRongsheng/XrayGLM Stars](https://img.shields.io/github/stars/WangRongsheng/XrayGLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | ğŸ©º é¦–ä¸ªä¼šçœ‹èƒ¸éƒ¨Xå…‰ç‰‡çš„ä¸­æ–‡å¤šæ¨¡æ€åŒ»å­¦å¤§æ¨¡å‹ \| The first Chinese Medical Multimodal Model that Chest Radiographs Summarization. |
| 2023-05-23 | [OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA) | ![OFA-Sys/ExpertLLaMA Stars](https://img.shields.io/github/stars/OFA-Sys/ExpertLLaMA.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹(TD)`,`è®­ç»ƒ` | An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability. |
| 2023-05-23 | [lyuchenyang/Macaw-LLM](https://github.com/lyuchenyang/Macaw-LLM) | ![lyuchenyang/Macaw-LLM Stars](https://img.shields.io/github/stars/lyuchenyang/Macaw-LLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`è¯­éŸ³`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration |
| 2023-05-19 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | ![OFA-Sys/ONE-PEACE Stars](https://img.shields.io/github/stars/OFA-Sys/ONE-PEACE.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | A general representation modal across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-19 | [ShishirPatil/gorilla](https://github.com/ShishirPatil/gorilla) | ![ShishirPatil/gorilla Stars](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)`,`å·¥å…·`,`å¯å•†ç”¨` | Gorilla: An API store for LLMs |
| 2023-05-19 | [SHI-Labs/Prompt-Free-Diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | ![SHI-Labs/Prompt-Free-Diffusion Stars](https://img.shields.io/github/stars/SHI-Labs/Prompt-Free-Diffusion.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models |
| 2023-05-19 | [yxuansu/PandaGPT](https://github.com/yxuansu/PandaGPT) | ![yxuansu/PandaGPT Stars](https://img.shields.io/github/stars/yxuansu/PandaGPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | PandaGPT: One Model To Instruction-Follow Them All |
| 2023-05-18 | [OpenGVLab/VisionLLM](https://github.com/OpenGVLab/VisionLLM) | ![OpenGVLab/VisionLLM Stars](https://img.shields.io/github/stars/OpenGVLab/VisionLLM.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹(TD)`,`è®­ç»ƒ(TD)` | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks |
| 2023-05-18 | [salesforce/UniControl](https://github.com/salesforce/UniControl) | ![salesforce/UniControl Stars](https://img.shields.io/github/stars/salesforce/UniControl.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` | Unified Controllable Visual Generation Model |
| 2023-05-17 | [mit-han-lab/fastcomposer](https://github.com/mit-han-lab/fastcomposer) | ![mit-han-lab/fastcomposer Stars](https://img.shields.io/github/stars/mit-han-lab/fastcomposer.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®(TD)`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` |  |
| 2023-05-17 | [sambanova/bloomchat](https://github.com/sambanova/bloomchat) | ![sambanova/bloomchat Stars](https://img.shields.io/github/stars/sambanova/bloomchat.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | This repo contains the data preparation, tokenization, training and inference code for BLOOMChat. BLOOMChat is a 176 billion parameter multilingual chat model based on BLOOM. |
| 2023-05-16 | [0nutation/SpeechGPT](https://github.com/0nutation/SpeechGPT) | ![0nutation/SpeechGPT Stars](https://img.shields.io/github/stars/0nutation/SpeechGPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è¯­éŸ³`,`æ•°æ®(TD)`,`é€šç”¨æ¨¡å‹(TD)`,`è®­ç»ƒ(TD)` | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities.  |
| 2023-05-15 | [PKU-Alignment/safe-rlhf](https://github.com/PKU-Alignment/safe-rlhf) | ![PKU-Alignment/safe-rlhf Stars](https://img.shields.io/github/stars/PKU-Alignment/safe-rlhf.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` | Safe-RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback |
| 2023-05-13 | [HeliosZhao/Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | ![HeliosZhao/Make-A-Protagonist Stars](https://img.shields.io/github/stars/HeliosZhao/Make-A-Protagonist.svg?label=&style=flat-square) | `è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | ![Neutralzz/BiLLa Stars](https://img.shields.io/github/stars/Neutralzz/BiLLa.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`ä¸­æ–‡` | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-08 | [conceptofmind/PaLM](https://github.com/conceptofmind/PaLM) | ![conceptofmind/PaLM Stars](https://img.shields.io/github/stars/conceptofmind/PaLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | An open-source implementation of Google's PaLM models |
| 2023-05-05 | [ZrrSkywalker/Personalize-SAM](https://github.com/ZrrSkywalker/Personalize-SAM) | ![ZrrSkywalker/Personalize-SAM Stars](https://img.shields.io/github/stars/ZrrSkywalker/Personalize-SAM.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Personalize Segment Anything Model (SAM) with 1 shot in 10 seconds |
| 2023-05-04 | [IBM/Dromedary](https://github.com/IBM/Dromedary) | ![IBM/Dromedary Stars](https://img.shields.io/github/stars/IBM/Dromedary.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Dromedary: towards helpful, ethical and reliable LLMs. |
| 2023-05-04 | [tatsu-lab/alpaca_farm](https://github.com/tatsu-lab/alpaca_farm) | ![tatsu-lab/alpaca_farm Stars](https://img.shields.io/github/stars/tatsu-lab/alpaca_farm.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | A Simulation Framework for RLHF and alternatives. |
| 2023-05-04 | [thunlp/WebCPM](https://github.com/thunlp/WebCPM) | ![thunlp/WebCPM Stars](https://img.shields.io/github/stars/thunlp/WebCPM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Official codes for ACL 2023 paper "WebCPM: Interactive Web Search for Chinese Long-form Question Answering" |
| 2023-05-03 | [melodysdreamj/WizardVicunaLM](https://github.com/melodysdreamj/WizardVicunaLM) | ![melodysdreamj/WizardVicunaLM Stars](https://img.shields.io/github/stars/melodysdreamj/WizardVicunaLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | LLM that combines the principles of wizardLM and vicunaLM |
| 2023-04-29 | [openlm-research/open_llama](https://github.com/openlm-research/open_llama) | ![openlm-research/open_llama Stars](https://img.shields.io/github/stars/openlm-research/open_llama.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`å¯å•†ç”¨` | In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. |
| 2023-04-29 | [mosaicml/llm-foundry](https://github.com/mosaicml/llm-foundry) | ![mosaicml/llm-foundry Stars](https://img.shields.io/github/stars/mosaicml/llm-foundry.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | LLM training code for MosaicML foundation models |
| 2023-04-29 | [replit/ReplitLM](https://github.com/replit/ReplitLM) | ![replit/ReplitLM Stars](https://img.shields.io/github/stars/replit/ReplitLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | Inference code and configs for the ReplitLM model family |
| 2023-04-28 | [dandelionsllm/pandallm](https://github.com/dandelionsllm/pandallm) | ![dandelionsllm/pandallm Stars](https://img.shields.io/github/stars/dandelionsllm/pandallm.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | Panda: æµ·å¤–ä¸­æ–‡å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº Llama-7B, -13B, -33B, -65B è¿›è¡Œä¸­æ–‡é¢†åŸŸä¸Šçš„æŒç»­é¢„è®­ç»ƒã€‚ |
| 2023-04-28 | [Zhendong-Wang/Prompt-Diffusion](https://github.com/Zhendong-Wang/Prompt-Diffusion) | ![Zhendong-Wang/Prompt-Diffusion Stars](https://img.shields.io/github/stars/Zhendong-Wang/Prompt-Diffusion.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Official PyTorch implementation of the paper "In-Context Learning Unlocked for Diffusion Models" |
| 2023-04-26 | [open-mmlab/Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) | ![open-mmlab/Multimodal-GPT Stars](https://img.shields.io/github/stars/open-mmlab/Multimodal-GPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | Multimodal-GPT |
| 2023-04-26 | [OpenBuddy/OpenBuddy](https://github.com/OpenBuddy/OpenBuddy) | ![OpenBuddy/OpenBuddy Stars](https://img.shields.io/github/stars/OpenBuddy/OpenBuddy.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | Open Multilingual Chatbot for Everyone |
| 2023-04-25 | [X-PLUG/mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) | ![X-PLUG/mPLUG-Owl Stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-Owl.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | mPLUG-OwlğŸ¦‰: Modularization Empowers Large Language Models with Multimodality |
| 2023-04-23 | [THUDM/VisualGLM-6B](https://github.com/THUDM/VisualGLM-6B) | ![THUDM/VisualGLM-6B Stars](https://img.shields.io/github/stars/THUDM/VisualGLM-6B.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | Chinese and English multimodal conversational language model \| å¤šæ¨¡æ€ä¸­è‹±åŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-04-23 | [nlpxucan/WizardLM](https://github.com/nlpxucan/WizardLM) | ![nlpxucan/WizardLM Stars](https://img.shields.io/github/stars/nlpxucan/WizardLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions |
| 2023-04-23 | [mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM) | ![mbzuai-nlp/LaMini-LM Stars](https://img.shields.io/github/stars/mbzuai-nlp/LaMini-LM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions |
| 2023-04-23 | [StevenGrove/GPT4Tools](https://github.com/StevenGrove/GPT4Tools) | ![StevenGrove/GPT4Tools Stars](https://img.shields.io/github/stars/StevenGrove/GPT4Tools.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | GPT4Tools is an intelligent system that can automatically decide, control, and utilize different visual foundation models, allowing the user to interact with images during a conversation. |
| 2023-04-19 | [RiseInRose/MiniGPT-4-ZH](https://github.com/RiseInRose/MiniGPT-4-ZH) | ![RiseInRose/MiniGPT-4-ZH Stars](https://img.shields.io/github/stars/RiseInRose/MiniGPT-4-ZH.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©` | MiniGPT-4 ä¸­æ–‡éƒ¨ç½²ç¿»è¯‘ å®Œå–„éƒ¨ç½²ç»†èŠ‚ |
| 2023-04-19 | [Stability-AI/StableLM](https://github.com/Stability-AI/StableLM) | ![Stability-AI/StableLM Stars](https://img.shields.io/github/stars/Stability-AI/StableLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | StableLM: Stability AI Language Models |
| 2023-04-18 | [h2oai/h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | ![h2oai/h2o-llmstudio Stars](https://img.shields.io/github/stars/h2oai/h2o-llmstudio.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs |
| 2023-04-18 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | ![haotian-liu/LLaVA Stars](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-16 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | ![Vision-CAIR/MiniGPT-4 Stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-04-15 | [OpenLMLab/MOSS](https://github.com/OpenLMLab/MOSS) | ![OpenLMLab/MOSS Stars](https://img.shields.io/github/stars/OpenLMLab/MOSS.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`å‹ç¼©`,`å¯å•†ç”¨`,`ä¸­æ–‡` | An open-source tool-augmented conversational language model from Fudan University |
| 2023-04-10 | [declare-lab/tango](https://github.com/declare-lab/tango) | ![declare-lab/tango Stars](https://img.shields.io/github/stars/declare-lab/tango.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Codes and Model of the paper "Text-to-Audio Generation using Instruction Tuned LLM and Latent Diffusion Model" |
| 2023-04-10 | [GanjinZero/RRHF](https://github.com/GanjinZero/RRHF) | ![GanjinZero/RRHF Stars](https://img.shields.io/github/stars/GanjinZero/RRHF.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`å¼ºåŒ–` | RRHF & Wombat |
| 2023-04-09 | [geekyutao/Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | ![geekyutao/Inpaint-Anything Stars](https://img.shields.io/github/stars/geekyutao/Inpaint-Anything.svg?label=&style=flat-square) | `å›¾åƒ`,`è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`3D` | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-06 | [threestudio-project/threestudio](https://github.com/threestudio-project/threestudio) | ![threestudio-project/threestudio Stars](https://img.shields.io/github/stars/threestudio-project/threestudio.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`3D` | A unified framework for 3D content generation. |
| 2023-04-03 | [VideoCrafter/VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | ![VideoCrafter/VideoCrafter Stars](https://img.shields.io/github/stars/VideoCrafter/VideoCrafter.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` | A Toolkit for Text-to-Video Generation and Editing |
| 2023-04-02 | [yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly) | ![yangjianxin1/Firefly Stars](https://img.shields.io/github/stars/yangjianxin1/Firefly.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | Firefly(æµè¤): ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-01 | [project-baize/baize-chatbot](https://github.com/project-baize/baize-chatbot) | ![project-baize/baize-chatbot Stars](https://img.shields.io/github/stars/project-baize/baize-chatbot.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Let ChatGPT teach your own chatbot in hours with a single GPU! |
| 2023-04-01 | [FreedomIntelligence/LLMZoo](https://github.com/FreedomIntelligence/LLMZoo) | ![FreedomIntelligence/LLMZoo Stars](https://img.shields.io/github/stars/FreedomIntelligence/LLMZoo.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`æ–‡æ¡£` | âš¡LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.âš¡ |
| 2023-04-01 | [Luodian/Otter](https://github.com/Luodian/Otter) | ![Luodian/Otter Stars](https://img.shields.io/github/stars/Luodian/Otter.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | ğŸ¦¦ Otter, a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning. |
| 2023-03-31 | [LC1332/Chinese-alpaca-lora](https://github.com/LC1332/Chinese-alpaca-lora) | ![LC1332/Chinese-alpaca-lora Stars](https://img.shields.io/github/stars/LC1332/Chinese-alpaca-lora.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | éª†é©¼:A Chinese finetuned instruction LLaMA. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-30 | [AetherCortex/Llama-X](https://github.com/AetherCortex/Llama-X) | ![AetherCortex/Llama-X Stars](https://img.shields.io/github/stars/AetherCortex/Llama-X.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹(TD)`,`è®­ç»ƒ` | Open Academic Research on Improving LLaMA to SOTA LLM |
| 2023-03-30 | [mayuelala/FollowYourPose](https://github.com/mayuelala/FollowYourPose) | ![mayuelala/FollowYourPose Stars](https://img.shields.io/github/stars/mayuelala/FollowYourPose.svg?label=&style=flat-square) | `è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-29 | [AGI-Edgerunners/LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters) | ![AGI-Edgerunners/LLM-Adapters Stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models |
| 2023-03-27 | [OptimalScale/LMFlow](https://github.com/OptimalScale/LMFlow) | ![OptimalScale/LMFlow Stars](https://img.shields.io/github/stars/OptimalScale/LMFlow.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¼ºåŒ–` | An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All. |
| 2023-03-25 | [h2oai/h2ogpt](https://github.com/h2oai/h2ogpt) | ![h2oai/h2ogpt Stars](https://img.shields.io/github/stars/h2oai/h2ogpt.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0 |
| 2023-03-24 | [junshutang/Make-It-3D](https://github.com/junshutang/Make-It-3D) | ![junshutang/Make-It-3D Stars](https://img.shields.io/github/stars/junshutang/Make-It-3D.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)`,`3D` | Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior |
| 2023-03-23 | [Facico/Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | ![Facico/Chinese-Vicuna Stars](https://img.shields.io/github/stars/Facico/Chinese-Vicuna.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | ![Lightning-AI/lit-llama Stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`å‹ç¼©`,`å¯å•†ç”¨` | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-22 | [johannakarras/DreamPose](https://github.com/johannakarras/DreamPose) | ![johannakarras/DreamPose Stars](https://img.shields.io/github/stars/johannakarras/DreamPose.svg?label=&style=flat-square) | `è§†é¢‘`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-21 | [LC1332/Luotuo-Chinese-LLM](https://github.com/LC1332/Luotuo-Chinese-LLM) | ![LC1332/Luotuo-Chinese-LLM Stars](https://img.shields.io/github/stars/LC1332/Luotuo-Chinese-LLM.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`ä¸­æ–‡` | éª†é©¼(Luotuo): Open Sourced Chinese Language Models. Developed by é™ˆå¯æº @ åä¸­å¸ˆèŒƒå¤§å­¦ & æé²é² @ å•†æ±¤ç§‘æŠ€ & å†·å­æ˜‚ @ å•†æ±¤ç§‘æŠ€ |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | ![CVI-SZU/Linly Stars](https://img.shields.io/github/stars/CVI-SZU/Linly.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ`,`å¼ºåŒ–(TD)`,`å‹ç¼©`,`æ¨ç†`,`å¯å•†ç”¨`,`ä¸­æ–‡` | Chinese-LLaMAåŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-21 | [Picsart-AI-Research/Text2Video-Zero](https://github.com/Picsart-AI-Research/Text2Video-Zero) | ![Picsart-AI-Research/Text2Video-Zero Stars](https://img.shields.io/github/stars/Picsart-AI-Research/Text2Video-Zero.svg?label=&style=flat-square) | `è§†é¢‘`,`é€šç”¨æ¨¡å‹` | Text-to-Image Diffusion Models are Zero-Shot Video Generators |
| 2023-03-21 | [lukasHoel/text2room](https://github.com/lukasHoel/text2room) | ![lukasHoel/text2room Stars](https://img.shields.io/github/stars/lukasHoel/text2room.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`3D` | Text2Room generates textured 3D meshes from a given text prompt using 2D text-to-image models. |
| 2023-03-19 | [lm-sys/FastChat](https://github.com/lm-sys/FastChat) | ![lm-sys/FastChat Stars](https://img.shields.io/github/stars/lm-sys/FastChat.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å¯å•†ç”¨` | An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and FastChat-T5. |
| 2023-03-19 | [ZrrSkywalker/LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter) | ![ZrrSkywalker/LLaMA-Adapter Stars](https://img.shields.io/github/stars/ZrrSkywalker/LLaMA-Adapter.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters |
| 2023-03-18 | [Beomi/KoAlpaca](https://github.com/Beomi/KoAlpaca) | ![Beomi/KoAlpaca Stars](https://img.shields.io/github/stars/Beomi/KoAlpaca.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | KoAlpaca: Korean Alpaca Model based on Stanford Alpaca (feat. LLAMA and Polyglot-ko) |
| 2023-03-17 | [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE) | ![LianjiaTech/BELLE Stars](https://img.shields.io/github/stars/LianjiaTech/BELLE.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ |
| 2023-03-17 | [ChenyangQiQi/FateZero](https://github.com/ChenyangQiQi/FateZero) | ![ChenyangQiQi/FateZero Stars](https://img.shields.io/github/stars/ChenyangQiQi/FateZero.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è§†é¢‘`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Pytorch Implementation for "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-16 | [AIGC-Audio/AudioGPT](https://github.com/AIGC-Audio/AudioGPT) | ![AIGC-Audio/AudioGPT Stars](https://img.shields.io/github/stars/AIGC-Audio/AudioGPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`è¯­éŸ³`,`é€šç”¨æ¨¡å‹` | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head |
| 2023-03-15 | [lllyasviel/ControlNet-v1-1-nightly](https://github.com/lllyasviel/ControlNet-v1-1-nightly) | ![lllyasviel/ControlNet-v1-1-nightly Stars](https://img.shields.io/github/stars/lllyasviel/ControlNet-v1-1-nightly.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` | Nightly release of ControlNet 1.1 |
| 2023-03-15 | [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) | ![voicepaw/so-vits-svc-fork Stars](https://img.shields.io/github/stars/voicepaw/so-vits-svc-fork.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | so-vits-svc fork with realtime support, improved interface and more features. |
| 2023-03-14 | [tloen/alpaca-lora](https://github.com/tloen/alpaca-lora) | ![tloen/alpaca-lora Stars](https://img.shields.io/github/stars/tloen/alpaca-lora.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Instruct-tune LLaMA on consumer hardware |
| 2023-03-13 | [THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | ![THUDM/ChatGLM-6B Stars](https://img.shields.io/github/stars/THUDM/ChatGLM-6B.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©`,`ä¸­æ–‡` | ChatGLM-6B: An Open Bilingual Dialogue Language Model \| å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹ |
| 2023-03-13 | [KU-CVLAB/3DFuse](https://github.com/KU-CVLAB/3DFuse) | ![KU-CVLAB/3DFuse Stars](https://img.shields.io/github/stars/KU-CVLAB/3DFuse.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`3D` | Official implementation of "Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation" |
| 2023-03-11 | [tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca) | ![tatsu-lab/stanford_alpaca Stars](https://img.shields.io/github/stars/tatsu-lab/stanford_alpaca.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Code and documentation to train Stanford's Alpaca models, and generate the data. |
| 2023-03-10 | [svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc) | ![svc-develop-team/so-vits-svc Stars](https://img.shields.io/github/stars/svc-develop-team/so-vits-svc.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | SoftVC VITS Singing Voice Conversion |
| 2023-03-10 | [thu-ml/unidiffuser](https://github.com/thu-ml/unidiffuser) | ![thu-ml/unidiffuser Stars](https://img.shields.io/github/stars/thu-ml/unidiffuser.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` | Code and models for the paper "One Transformer Fits All Distributions in Multi-Modal Diffusion" |
| 2023-03-09 | [IDEA-Research/GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) | ![IDEA-Research/GroundingDINO Stars](https://img.shields.io/github/stars/IDEA-Research/GroundingDINO.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` | The official implementation of "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection" |
| 2023-03-05 | [yxlllc/DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) | ![yxlllc/DDSP-SVC Stars](https://img.shields.io/github/stars/yxlllc/DDSP-SVC.svg?label=&style=flat-square) | `è¯­éŸ³`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | ![togethercomputer/OpenChatKit Stars](https://img.shields.io/github/stars/togethercomputer/OpenChatKit.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` |  |
| 2023-02-27 | [openai/consistency_models](https://github.com/openai/consistency_models) | ![openai/consistency_models Stars](https://img.shields.io/github/stars/openai/consistency_models.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©` | Official repo for consistency models. |
| 2023-02-14 | [facebookresearch/llama](https://github.com/facebookresearch/llama) | ![facebookresearch/llama Stars](https://img.shields.io/github/stars/facebookresearch/llama.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | Inference code for LLaMA models |
| 2023-02-01 | [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) | ![lllyasviel/ControlNet Stars](https://img.shields.io/github/stars/lllyasviel/ControlNet.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Let us control diffusion models! |
| 2023-01-27 | [lucidrains/musiclm-pytorch](https://github.com/lucidrains/musiclm-pytorch) | ![lucidrains/musiclm-pytorch Stars](https://img.shields.io/github/stars/lucidrains/musiclm-pytorch.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ`,`å‹ç¼©` | Implementation of MusicLM, Google's new SOTA model for music generation using attention networks, in Pytorch |
| 2023-01-21 | [deep-floyd/IF](https://github.com/deep-floyd/IF) | ![deep-floyd/IF Stars](https://img.shields.io/github/stars/deep-floyd/IF.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` |  |
| 2023-01-13 | [BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV) | ![BlinkDL/ChatRWKV Stars](https://img.shields.io/github/stars/BlinkDL/ChatRWKV.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source. |
| 2023-01-09 | [timothybrooks/instruct-pix2pix](https://github.com/timothybrooks/instruct-pix2pix) | ![timothybrooks/instruct-pix2pix Stars](https://img.shields.io/github/stars/timothybrooks/instruct-pix2pix.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | PyTorch implementation of InstructPix2Pix, an instruction-based image editing model |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | ![karpathy/nanoGPT Stars](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?label=&style=flat-square) | `æ–‡æœ¬`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-12-25 | [showlab/Tune-A-Video](https://github.com/showlab/Tune-A-Video) | ![showlab/Tune-A-Video Stars](https://img.shields.io/github/stars/showlab/Tune-A-Video.svg?label=&style=flat-square) | `è§†é¢‘`,`é€šç”¨æ¨¡å‹` | Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation |
| 2022-12-07 | [openai/point-e](https://github.com/openai/point-e) | ![openai/point-e Stars](https://img.shields.io/github/stars/openai/point-e.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`3D` | Point cloud diffusion for 3D model synthesis |
| 2022-11-24 | [Stability-AI/stablediffusion](https://github.com/Stability-AI/stablediffusion) | ![Stability-AI/stablediffusion Stars](https://img.shields.io/github/stars/Stability-AI/stablediffusion.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | High-Resolution Image Synthesis with Latent Diffusion Models |
| 2022-11-23 | [OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker) | ![OpenTalker/SadTalker Stars](https://img.shields.io/github/stars/OpenTalker/SadTalker.svg?label=&style=flat-square) | `å›¾åƒ`,`è¯­éŸ³`,`è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ(TD)` | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-10-22 | [prophesier/diff-svc](https://github.com/prophesier/diff-svc) | ![prophesier/diff-svc Stars](https://img.shields.io/github/stars/prophesier/diff-svc.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | Singing Voice Conversion via diffusion model |
| 2022-10-20 | [mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo) | ![mlfoundations/open_flamingo Stars](https://img.shields.io/github/stars/mlfoundations/open_flamingo.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`è§†é¢‘(TD)`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | An open-source framework for training large multimodal models. |
| 2022-10-19 | [runwayml/stable-diffusion](https://github.com/runwayml/stable-diffusion) | ![runwayml/stable-diffusion Stars](https://img.shields.io/github/stars/runwayml/stable-diffusion.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹` | Latent Text-to-Image Diffusion |
| 2022-10-06 | [ashawkey/stable-dreamfusion](https://github.com/ashawkey/stable-dreamfusion) | ![ashawkey/stable-dreamfusion Stars](https://img.shields.io/github/stars/ashawkey/stable-dreamfusion.svg?label=&style=flat-square) | `å›¾åƒ`,`é€šç”¨æ¨¡å‹`,`3D` | Text-to-3D & Image-to-3D & Mesh Exportation with NeRF + Diffusion. |
| 2022-09-29 | [GuyTevet/motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | ![GuyTevet/motion-diffusion-model Stars](https://img.shields.io/github/stars/GuyTevet/motion-diffusion-model.svg?label=&style=flat-square) | `è§†é¢‘`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-26 | [ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp) | ![ggerganov/whisper.cpp Stars](https://img.shields.io/github/stars/ggerganov/whisper.cpp.svg?label=&style=flat-square) | `è¯­éŸ³`,`é€šç”¨æ¨¡å‹`,`å‹ç¼©` | Port of OpenAI's Whisper model in C/C++ |
| 2022-09-09 | [williamyang1991/VToonify](https://github.com/williamyang1991/VToonify) | ![williamyang1991/VToonify Stars](https://img.shields.io/github/stars/williamyang1991/VToonify.svg?label=&style=flat-square) | `è§†é¢‘`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | ![salesforce/LAVIS Stars](https://img.shields.io/github/stars/salesforce/LAVIS.svg?label=&style=flat-square) | `æ–‡æœ¬`,`å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`é¢„è®­ç»ƒ`,`è®­ç»ƒ` | LAVIS - A One-stop Library for Language-Vision Intelligence |
| 2022-08-10 | [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion) | ![CompVis/stable-diffusion Stars](https://img.shields.io/github/stars/CompVis/stable-diffusion.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹` | A latent text-to-image diffusion model |
| 2022-08-04 | [THUDM/GLM-130B](https://github.com/THUDM/GLM-130B) | ![THUDM/GLM-130B Stars](https://img.shields.io/github/stars/THUDM/GLM-130B.svg?label=&style=flat-square) | `æ–‡æœ¬`,`é€šç”¨æ¨¡å‹` | GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023) |
| 2022-08-03 | [rinongal/textual_inversion](https://github.com/rinongal/textual_inversion) | ![rinongal/textual_inversion Stars](https://img.shields.io/github/stars/rinongal/textual_inversion.svg?label=&style=flat-square) | `å›¾åƒ`,`æ•°æ®`,`é€šç”¨æ¨¡å‹`,`è®­ç»ƒ` |  |
