| Date | Repository | Stars | tags | Language |  Description  |
|------------|---------|-------|-------------|-------------|-------------|
| 2023-07-21 | [Alpha-VLLM/LLaMA2-Accessory](https://github.com/Alpha-VLLM/LLaMA2-Accessory) | 1357 | ğŸ” ğŸ–¼ï¸â›½1ï¸âƒ£2ï¸âƒ£ğŸ”¨ |  Python | An Open-source Toolkit for LLM Development |
| 2023-07-19 | [michael-wzhu/Chinese-LlaMA2](https://github.com/michael-wzhu/Chinese-LlaMA2) | 683 | ğŸ” `ğŸšŒ``ğŸš•``1ï¸âƒ£``2ï¸âƒ£`ğŸ’°ğŸ€„ |   | Repo for adapting Meta LlaMA2 in Chinese! METAæœ€æ–°å‘å¸ƒçš„LlaMA2çš„æ±‰åŒ–ç‰ˆï¼ ï¼ˆå®Œå…¨å¼€æºå¯å•†ç”¨ï¼‰ |
| 2023-07-19 | [yangjianxin1/Firefly-LLaMA2-Chinese](https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese) | 106 | ğŸ” `ğŸšŒ``ğŸš•``1ï¸âƒ£``2ï¸âƒ£`ğŸ€„ |   | ä¸­æ–‡LLaMA-2å¤§æ¨¡å‹ï¼Œå…¼å®¹å¯¹ä¸­æ–‡å¤§æ¨¡å‹è¿›è¡Œå¢é‡é¢„è®­ç»ƒ |
| 2023-07-18 | [longyuewangdcu/Chinese-Llama-2](https://github.com/longyuewangdcu/Chinese-Llama-2) | 265 | ğŸ” ğŸšŒ`1ï¸âƒ£`2ï¸âƒ£ |   | Chinese-Llama-2 is a project that aims to expand the impressive capabilities of the Llama-2 language model to the Chinese language. |
| 2023-07-18 | [ymcui/Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 2447 | ğŸ” `ğŸšŒ``1ï¸âƒ£``2ï¸âƒ£`ğŸ’°ğŸ€„ |   | ä¸­æ–‡ LLaMA-2 & Alpaca-2 å¤§æ¨¡å‹äºŒæœŸé¡¹ç›® + æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½²  (Chinese LLaMA-2 & Alpaca-2 LLMs) |
| 2023-06-02 | [shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT) | 1296 | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ğŸ€„ |   | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚ |
| 2023-05-28 | [hiyouga/LLaMA-Efficient-Tuning](https://github.com/hiyouga/LLaMA-Efficient-Tuning) | 3054 | ğŸ” 1ï¸âƒ£2ï¸âƒ£3ï¸âƒ£ |   | Easy-to-use LLM fine-tuning framework (LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, ChatGLM2) |
| 2023-05-18 | [OFA-Sys/ONE-PEACE](https://github.com/OFA-Sys/ONE-PEACE) | 565 | ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | A general representation model across vision, audio, language modalities. Paper: ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities |
| 2023-05-12 | [TigerResearch/TigerBot](https://github.com/TigerResearch/TigerBot) | 1700 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | TigerBot: A multi-language multi-task LLM |
| 2023-05-10 | [Neutralzz/BiLLa](https://github.com/Neutralzz/BiLLa) | 398 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ğŸ€„ |   | BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability |
| 2023-05-06 | [DAMO-NLP-SG/Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1469 | ğŸ” ğŸ¥ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-04 | [Lightning-AI/lit-gpt](https://github.com/Lightning-AI/lit-gpt) | 2390 | ğŸ” ğŸ–¼ï¸ğŸšŒ`1ï¸âƒ£`2ï¸âƒ£ |   | Hackable implementation of state-of-the-art open-source LLMs based on nanoGPT. Supports flash attention, 4-bit and 8-bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-04-20 | [pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 5087 | ğŸ” â›½ğŸš•1ï¸âƒ£2ï¸âƒ£ |   |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ |
| 2023-04-17 | [haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA) | 4540 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities. |
| 2023-04-15 | [Vision-CAIR/MiniGPT-4](https://github.com/Vision-CAIR/MiniGPT-4) | 22160 | ğŸ” ğŸ–¼ï¸ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models |
| 2023-03-22 | [Lightning-AI/lit-llama](https://github.com/Lightning-AI/lit-llama) | 5075 | ğŸ” ğŸšŒ1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’° |   | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. |
| 2023-03-21 | [CVI-SZU/Linly](https://github.com/CVI-SZU/Linly) | 2643 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£`3ï¸âƒ£`âœ‚ï¸ğŸ’¡ğŸ’°ğŸ€„ |   | Chinese-LLaMA 1&2ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† |
| 2023-03-15 | [ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 14027 | ğŸ” 1ï¸âƒ£2ï¸âƒ£âœ‚ï¸ğŸ’¡ğŸ€„ |   | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) |
| 2023-03-03 | [togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit) | 8845 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   |  |
| 2022-12-28 | [karpathy/nanoGPT](https://github.com/karpathy/nanoGPT) | 24128 | ğŸ” â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | The simplest, fastest repository for training/finetuning medium-sized GPTs. |
| 2022-08-24 | [salesforce/LAVIS](https://github.com/salesforce/LAVIS) | 6386 | ğŸ” ğŸ–¼ï¸â›½ğŸšŒ1ï¸âƒ£2ï¸âƒ£ |   | LAVIS - A One-stop Library for Language-Vision Intelligence |
