| Date | Repository | Stars | tags |  Description  |
|------------|---------|-------|-------------|-------------|
| 2023-08-15 | [CoDeF](https://github.com/qiuyu96/CoDeF) | 3356 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | Official PyTorch implementation of CoDeF: Content Deformation Fields for Temporally Consistent Video Processing |
| 2023-08-14 | [WanJuan1.0](https://github.com/opendatalab/WanJuan1.0) | 252 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ â›½  | ä¸‡å·1.0å¤šæ¨¡æ€è¯­æ–™ |
| 2023-08-01 | [VisionCrafter](https://github.com/diStyApps/VisionCrafter) | 87 | ğŸ¥ ğŸ”¨ `Python`  | Craft your visions |
| 2023-07-26 | [DWPose](https://github.com/IDEA-Research/DWPose) | 986 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | "Effective Whole-body Pose Estimation with Two-stages Distillation" (ICCV 2023, CV4Metaverse Workshop) |
| 2023-07-20 | [TokenFlow](https://github.com/omerbt/TokenFlow) | 591 | ğŸ¥ 2ï¸âƒ£  | Official Pytorch Implementation for "TokenFlow: Consistent Diffusion Features for Consistent Video Editing" presenting "TokenFlow" |
| 2023-07-17 | [ER-NeRF](https://github.com/Fictionarry/ER-NeRF) | 147 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | [ICCV'23] Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis |
| 2023-07-04 | [text2cinemagraph](https://github.com/text2cinemagraph/text2cinemagraph) | 253 | ğŸ”  ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Official Pytorch implementation of Text2Cinemagraph: Synthesizing Artistic Cinemagraphs from Text |
| 2023-06-27 | [ShortGPT](https://github.com/RayVentura/ShortGPT) | 3504 | ğŸ”  ğŸ¥ ğŸ”¨ `Python`  | ğŸš€ğŸ¬ ShortGPT - Experimental AI framework for automated short/video content creation. |
| 2023-06-20 | [MotionGPT](https://github.com/OpenMotionLab/MotionGPT) | 636 | ğŸ”  ğŸ¥ ğŸ“  | MotionGPT: Human Motion as a Foreign Language, a unified motion-language generation model using LLMs |
| 2023-06-17 | [AnimateDiff](https://github.com/guoyww/AnimateDiff) | 2956 | ğŸ”  ğŸ¥ ğŸšŒ  | Official implementation of AnimateDiff. |
| 2023-06-03 | [DisCo](https://github.com/Wangt-CN/DisCo) | 563 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | DisCo: Referring Human Dance Generation in Real World |
| 2023-06-01 | [videocomposer](https://github.com/damo-vilab/videocomposer) | 590 | ğŸ”  ğŸ¥ ğŸšŒ  | Official repo for VideoComposer: Compositional Video Synthesis with Motion Controllability |
| 2023-05-31 | [refacer](https://github.com/xaviviro/refacer) | 329 | ğŸ¥ ğŸšŒ  | Refacer: One-Click Deepfake Multi-Face Swap Tool |
| 2023-05-28 | [roop](https://github.com/s0md3v/roop) | 20040 | ğŸ¥ ğŸ”¨ `Python`  | one-click face swap |
| 2023-05-22 | [ControlVideo](https://github.com/YBYBZhang/ControlVideo) | 542 | ğŸ¥ ğŸ”¨ `Python`  | [Arxiv 2023] Official pytorch implementation of "ControlVideo: Training-free Controllable Text-to-Video Generation" |
| 2023-05-22 | [VideoLLM](https://github.com/cg1177/VideoLLM) | 116 | ğŸ¥ ğŸ“  | VideoLLM: Modeling Video Sequence with Large Language Models |
| 2023-05-18 | [Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT) | 478 | ğŸ”  ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | "Video-ChatGPT" is a video conversation model capable of generating meaningful conversation about videos. It combines the capabilities of LLMs with a pretrained visual encoder adapted for spatiotemporal video representation. We also introduce a rigorous 'Quantitative Evaluation Benchmarking' for video-based conversational models. |
| 2023-05-17 | [awesome-ai-tools-for-game-dev](https://github.com/simoninithomas/awesome-ai-tools-for-game-dev) | 265 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | A curated list of awesome AI tools for game developers |
| 2023-05-13 | [Make-A-Protagonist](https://github.com/HeliosZhao/Make-A-Protagonist) | 267 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Make-A-Protagonist: Generic Video Editing with An Ensemble of Experts |
| 2023-05-06 | [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 1485 | ğŸ”  ğŸ¥ ğŸšŒ 1ï¸âƒ£ 2ï¸âƒ£  | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding |
| 2023-05-05 | [open-chat-video-editor](https://github.com/SCUTlihaoyu/open-chat-video-editor) | 2280 | ğŸ¥ ğŸ”¨ `Python`  | Open source short video automatic generation tool |
| 2023-05-02 | [dolphin](https://github.com/kaleido-lab/dolphin) | 233 | ğŸ¥ ğŸ”¨ `Python`  | General video interaction platform based on LLMs, including Video ChatGPT |
| 2023-04-20 | [VLog](https://github.com/showlab/VLog) | 397 | ğŸ”  ğŸ¥ ğŸ”¨ `Python`  | Transform Video as a Document with ChatGPT, CLIP, BLIP2, GRIT, Whisper, LangChain. |
| 2023-04-19 | [Ask-Anything](https://github.com/OpenGVLab/Ask-Anything) | 2105 | ğŸ”  ğŸ¥ ğŸ”¨ `Python`  | [VideoChatGPT] ChatGPT with video understanding! And many more supported LMs such as miniGPT4, StableLM, and MOSS. |
| 2023-04-17 | [Awesome-Video-Diffusion](https://github.com/showlab/Awesome-Video-Diffusion) | 883 | ğŸ¥ ğŸ“  | A curated list of recent diffusion models for video generation, editing, restoration, understanding, etc. |
| 2023-04-09 | [Inpaint-Anything](https://github.com/geekyutao/Inpaint-Anything) | 3986 | ğŸ–¼ï¸ ğŸ¥ ğŸšŒ ğŸ§Š  | Inpaint anything using Segment Anything and inpainting models. |
| 2023-04-03 | [VideoCrafter](https://github.com/VideoCrafter/VideoCrafter) | 1986 | ğŸ”  ğŸ¥ ğŸšŒ 2ï¸âƒ£  | A Toolkit for Text-to-Video Generation and Editing |
| 2023-03-30 | [FollowYourPose](https://github.com/mayuelala/FollowYourPose) | 654 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | Follow-Your-Pose: This repo is the official implementation of "Follow-Your-Pose : Pose-Guided Text-to-Video Generation using Pose-Free Videos"    |
| 2023-03-22 | [subvert](https://github.com/aschmelyun/subvert) | 602 | ğŸ”  ğŸ¥ ğŸ”¨ `PHP`  | Generate subtitles, summaries, and chapters from videos in seconds |
| 2023-03-21 | [DreamPose](https://github.com/johannakarras/DreamPose) | 664 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | Official implementation of "DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion" |
| 2023-03-21 | [Text2Video-Zero](https://github.com/Picsart-AI-Research/Text2Video-Zero) | 3241 | ğŸ¥ ğŸšŒ  | [ICCV 2023 Oral] Text-to-Image Diffusion Models are Zero-Shot Video Generators |
| 2023-03-19 | [sd-webui-text2video](https://github.com/kabachuha/sd-webui-text2video) | 1056 | ğŸ–¼ï¸ ğŸ¥ ğŸ”Œ  | Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies |
| 2023-03-19 | [text-to-video-synthesis-colab](https://github.com/camenduru/text-to-video-synthesis-colab) | 1177 | ğŸ”  ğŸ¥ ğŸ”¨ `Jupyter`  | Text To Video Synthesis Colab |
| 2023-03-16 | [FateZero](https://github.com/ChenyangQiQi/FateZero) | 840 | ğŸ”  ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | [ICCV 2023 Oral] "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing" |
| 2023-03-15 | [MM-REACT](https://github.com/microsoft/MM-REACT) | 766 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ ğŸ”¨ `Python`  | Official repo for MM-REACT |
| 2023-02-26 | [BibiGPT](https://github.com/JimmyLv/BibiGPT) | 4040 | ğŸ”  ğŸµ ğŸ¥ ğŸ”¨ `TypeScript`  | BibiGPT v1 Â· one-Click AI Summary for Audio/Video & Chat with Learning Content: Bilibili \| YouTube \| Tweetä¸¨TikTokä¸¨Local files \| Websitesä¸¨Podcasts \| Meetings \| Lectures, etc. éŸ³è§†é¢‘å†…å®¹ AI ä¸€é”®æ€»ç»“ & å¯¹è¯ï¼šå“”å“©å“”å“©ä¸¨YouTubeä¸¨æ¨ç‰¹ä¸¨å°çº¢ä¹¦ä¸¨æŠ–éŸ³ä¸¨ç½‘é¡µä¸¨æ’­å®¢ä¸¨ä¼šè®®ä¸¨æœ¬åœ°æ–‡ä»¶ç­‰ (åŸ BiliGPT çœæµç¥å™¨ & è¯¾ä»£è¡¨) |
| 2023-01-08 | [ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) | 4624 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | ğŸ”¥Highlighting the top ML papers every week. |
| 2022-12-25 | [Tune-A-Video](https://github.com/showlab/Tune-A-Video) | 3569 | ğŸ¥ ğŸšŒ  | [ICCV 2023] Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation |
| 2022-11-23 | [SadTalker](https://github.com/OpenTalker/SadTalker) | 6260 | ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [CVPR 2023] SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |
| 2022-10-28 | [autocut](https://github.com/mli/autocut) | 5275 | ğŸ¥ ğŸ”¨ `Python`  | ç”¨æ–‡æœ¬ç¼–è¾‘å™¨å‰ªè§†é¢‘ |
| 2022-10-20 | [open_flamingo](https://github.com/mlfoundations/open_flamingo) | 2791 | ğŸ”  ğŸ–¼ï¸ ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | An open-source framework for training large multimodal models. |
| 2022-10-17 | [Mubert-Text-to-Music](https://github.com/MubertAI/Mubert-Text-to-Music) | 2662 | ğŸ”  ğŸµ ğŸ¥ ğŸ“  | A simple notebook demonstrating prompt-based music generation via Mubert API |
| 2022-09-29 | [motion-diffusion-model](https://github.com/GuyTevet/motion-diffusion-model) | 2368 | ğŸ¥ â›½ ğŸšŒ 2ï¸âƒ£  | The official PyTorch implementation of the paper "Human Motion Diffusion Model" |
| 2022-09-09 | [VToonify](https://github.com/williamyang1991/VToonify) | 3274 | ğŸ¥ ğŸšŒ 2ï¸âƒ£  | [SIGGRAPH Asia 2022] VToonify: Controllable High-Resolution Portrait Video Style Transfer |
| 2022-09-06 | [stable-diffusion-videos](https://github.com/nateraw/stable-diffusion-videos) | 3491 | ğŸ¥ ğŸ”¨ `Python`  | Create ğŸ”¥ videos with Stable Diffusion by exploring the latent space and morphing between text prompts |
| 2022-09-04 | [ai-notes](https://github.com/swyxio/ai-notes) | 3693 | ğŸ”  ğŸ–¼ï¸ ğŸµ ğŸ¥ ğŸ“  | notes for software engineers getting up to speed on new AI developments. Serves as datastore for https://latent.space writing, and product brainstorming, but has cleaned up canonical references under the /Resources folder. |
